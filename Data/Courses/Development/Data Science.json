[
  {
    "title": "Convolutional Neural Networks for Medicine",
    "price": "Current priceE£399.99",
    "description": "Before starting this course you must at least have an intermediate level of python, basic understanding of convolutional neural networks, and basic knowledge of Tensorflow. By the end of this course you will learn how to train very accurate convolutional neural networks to predict test images for binary class. You know enough to where if you want to go off on your own and use your own methods how to do that. Also appropriate parameters to use as well as data augmentation methods. It is explained in this course how to train multiclass as well.  Not to mention you will learn how to use CV2 when predicting an image after training the convolutional neural network. You will also learn how to train a multi class Convolutional Neural Network and predict as well. Then learn to use a Keras Load Model Function for both binary and multi class predictions. Although the videos are short they are thoroughly and simply explained. You will also learn to deal with some of the challenges in deep learning as well when it comes to small dataset size. All the datasets featured in this video are found on Kaggle, except one that I provide to you directly. I will explain why in that video. Do not worry about the quizzes if you pay attention you will easily do great. But most importantly be ready to learn. This is not is challenging as it seems. I show you how to prevent overfitting and reduce bias severely with these methods in these videos.",
    "instructor": "Marshall Trumbull",
    "requirements": [
      "Intermediate Python Knowledge",
      "Basic Tensorflow Knowledge",
      "Either have an Google Colab. Or if using Jupyter Notebook Tensorflow and Keras already installed in the virtual environment",
      "Have a basic idea of convolutional neural networks"
    ],
    "whatYouWillLearn": [
      "Convolutional Neural Networks",
      "Data Augmentation",
      "Tensorflow",
      "Binary Class Predictions with percentages of each class",
      "Keras",
      "Maxpooling",
      "CV2",
      "AI uses for Medical Imagery",
      "Creating a Train and Validation Set when the original dataset only has one folder",
      "Dealing with Overfitting",
      "Dealing with a very Small Dataset"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview05:50",
          "Quiz 11 question",
          "Pneumonia PredictionPreview04:50",
          "Quiz 21 question"
        ]
      },
      {
        "title": "Section 2",
        "subsections": [
          "Malaria Detection04:23",
          "Mosquito bite or Tick bite prediction01:05",
          "Brain Tumor Detection03:38",
          "Quiz 31 question",
          "Quiz 41 question",
          "Quiz 51 question",
          "Quiz 61 question",
          "Quiz 72 questions"
        ]
      },
      {
        "title": "Multi Class use cases in agriculture and Keras Load Model Function",
        "subsections": [
          "Multiclass Potato Leaf  Disease Prediction04:04",
          "How to use a Keras Load Model Function for a saved Model to predict Multiclass03:10",
          "Quiz 81 question",
          "Quiz 91 question",
          "In case you were wondering how to use a Keras Load Model function for binary03:37",
          "Quiz 101 question"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/4369088_cd1f.jpg"
  },
  {
    "title": "Mastering SVM: A Comprehensive Guide with Code in Python",
    "price": "Current priceE£399.99",
    "description": "Unleashing the Power of Support Vector MachineWhat is Support Vector Machine?SVM is a supervised machine learning algorithm that classifies data by creating a hyperplane in a high-dimensional space. It is widely used for both regression and classification tasks. SVM excels at handling complex datasets, making it a go-to choice for various applications, including image classification, text analysis, and anomaly detection.The Working Principle of SVMAt its core, SVM aims to find an optimal hyperplane that maximally separates data points into distinct classes. By transforming the input data into a higher-dimensional feature space, SVM facilitates effective separation, even when the data is not linearly separable. The algorithm achieves this by finding support vectors, which are the data points closest to the hyperplane.Key Advantages of Support Vector MachineFlexibility: SVM offers versatile kernel functions that allow nonlinear decision boundaries, giving it an edge over other algorithms.Robustness: SVM effectively handles datasets with outliers and noise, thanks to its ability to focus on the support vectors rather than considering the entire dataset.Generalization: SVM demonstrates excellent generalization capabilities, enabling accurate predictions on unseen data.Memory Efficiency: Unlike some other machine learning algorithms, SVM only requires a subset of training samples for decision-making, making it memory-efficient.The Importance of Maximum MarginBy maximizing the margin, SVM promotes better generalization and robustness of the classification model. A larger margin allows for better separation between classes, reducing the risk of misclassification and improving the model's ability to handle unseen data. The concept of maximum margin classification is rooted in the idea of finding the decision boundary with the highest confidence.Use Cases of SVMSVM finds its applications in a wide range of domains, including:Image Recognition: SVM's ability to classify images based on complex features makes it invaluable in computer vision tasks, such as facial recognition and object detection.Text Classification: SVM can classify text documents, making it ideal for sentiment analysis, spam detection, and topic categorization.Bioinformatics: SVM aids in protein structure prediction, gene expression analysis, and disease classification, contributing significantly to the field of bioinformatics.Finance: SVM assists in credit scoring, stock market forecasting, and fraud detection, helping financial institutions make informed decisions.Best Practices for SVM ImplementationTo maximize the effectiveness of SVM in your projects, consider the following best practices:Data Preprocessing: Ensure your data is properly preprocessed by performing tasks such as feature scaling, handling missing values, and encoding categorical variables.Hyperparameter Tuning: Experiment with different kernel functions, regularization parameters, and other hyperparameters to optimize the performance of your SVM model.Feature Selection: Select relevant features to improve SVM's efficiency and avoid overfitting.Cross-Validation: Utilize cross-validation techniques to validate your SVM model and assess its generalization capabilities.Kernel TrickThe SVM algorithm utilizes the \"kernel trick\" technique to transform the input data into a higher-dimensional feature space. This transformation allows nonlinear decision boundaries to be defined in the original input space. The kernel function plays a vital role in this process, as it measures the similarity between pairs of data points. Commonly used kernel functions include the linear kernel, polynomial kernel, and radial basis function (RBF) kernel.Margin and Support VectorsIn SVM, the margin refers to the region between the decision boundary (hyperplane) and the nearest data points from each class. The goal is to find the hyperplane that maximizes this margin. The data points that lie on the margin or within a certain distance from it are known as support vectors. These support vectors are critical in defining the hyperplane and determining the classification boundaries.C-Parameter and RegularizationThe C-parameter, often called the regularization parameter, is a crucial parameter in SVM. It controls the trade-off between maximizing the margin and minimizing the classification errors. A higher value of C places more emphasis on classifying data points correctly, potentially leading to a narrower margin. On the other hand, a lower value of C allows for a wider margin but may result in more misclassifications. Proper tuning of the C-parameter is essential to achieve the desired balance between model simplicity and accuracy.Nonlinear Classification with SVMOne of the major strengths of SVM is its ability to handle nonlinear classification problems. The kernel trick allows SVM to map the input data into a higher-dimensional space where linear separation is possible. This enables SVM to solve complex classification tasks that cannot be accurately separated by a linear hyperplane in the original feature space.SVM Training and OptimizationThe training of an SVM model involves finding the optimal hyperplane that maximizes the margin and separates the classes. This optimization problem can be formulated as a quadratic programming task. Various optimization algorithms, such as Sequential Minimal Optimization (SMO), are commonly used to solve this problem efficiently.ConclusionSupport Vector Machine is a versatile and robust algorithm that empowers data scientists to tackle complex classification and regression problems. By harness",
    "instructor": "Hoang Quy La",
    "requirements": [
      "Python knowledge and basic machine learning is required"
    ],
    "whatYouWillLearn": [
      "Maximum margin",
      "slack variables",
      "Data preprocessing",
      "Standardizing features",
      "Overfitting",
      "Train the model",
      "Kernel Trick",
      "C parameter in support vector machine",
      "Linear Classification in SVM",
      "Non-linear SVM implementation",
      "V-Support vector machine",
      "Support Vector Regression (SVR)",
      "Confusion matrix",
      "Splitting the datasets  into training and testing sets"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Course structurePreview01:30",
          "IMPORTANT VIDEOS PLEASE WATCHPreview01:00",
          "Some of important terminologies in SVMPreview06:03",
          "Introduction to SVMPreview10:33"
        ]
      },
      {
        "title": "Maximum margin classification with support vector machines",
        "subsections": [
          "Introduction to  Maximum margin05:03",
          "What is slack variables05:50",
          "Data preprocessing15:12",
          "Standardizing features16:43",
          "Introduction to Overfitting15:14",
          "Train the model16:16",
          "Introduction to Kernel Trick02:27",
          "Kernel trick implementation07:24"
        ]
      },
      {
        "title": "Some of the SVM algorithm",
        "subsections": [
          "Introduction to Linear Classification in SVM05:30",
          "What is C parameter in support vector machine03:19",
          "Implementation of Linear Classification in SVM10:06",
          "Non-linear SVM implementation08:19",
          "Non-linear SVM explaination01:48",
          "MNIST handwritten digit dataset06:43",
          "Introduction to V-Support vector machine06:14",
          "Implementation of V-support Vector Machine06:35",
          "Introduction to Support Vector Regression (SVR)04:15",
          "Implementation of SVR08:34"
        ]
      },
      {
        "title": "Project: Pima Indians Diabetes",
        "subsections": [
          "Introduction and implementation Part 111:55",
          "Introduction and implementation Part 204:13",
          "Other method of splitting the datasets  into training and testing sets13:23",
          "Confusion matrix Explanation07:26",
          "Confusion matrix Implementation14:34"
        ]
      },
      {
        "title": "Fertility diagnostic project",
        "subsections": [
          "Fertility Diagnostic Project Implementation8 questions"
        ]
      },
      {
        "title": "Thank you",
        "subsections": [
          "Thank you01:16"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5153394_bded_2.jpg"
  },
  {
    "title": "Data Science 400+ Scenario Questions for Job Success",
    "price": "Price not found",
    "description": "Embark on a comprehensive journey through the Data Science Project Life Cycle. From sourcing and refining data to crafting powerful models, learn to dissect patterns, optimize algorithms, and translate findings into actionable insights. Explore hands-on 400+ scenario Questions, master model evaluation, and drive impact through deployment and communication. Elevate your skills and navigate the intricate landscape of data science with confidence in this immersive courseTopics Covered:Data Collection and Preprocessing:Identify relevant data sources.Collect, clean, and preprocess the data.Exploratory Data Analysis (EDA):Understand the data's structure and relationships.Identify patterns, trends, and potential outliers.Feature Engineering:Create new features from existing data.Select and transform features for model input.Model Building:Choose appropriate algorithms for the problem.Train and validate models using the data.Model Evaluation:Assess model performance using metrics.Tune hyperparameters for optimization.Model Deployment:Integrate the model into the production environment.Monitoring and Maintenance:Continuously monitor model performance.Update and retrain the model as needed.Interpretation and Communication:Explain model predictions to stakeholders.Communicate insights and findings.Sample Questions:1- When selecting an algorithm for a problem, what is the first step you should take?1) Choose the most complex algorithm2) Use the algorithm you are most comfortable with3) Understand the problem's nature4) Pick the algorithm with the highest accuracyExplanation:The correct Answer is : Understand the problem's natureThe first step is to understand the nature of the problem, whether it's classification, regression, etc.2- When splitting data into training and validation sets, what is the general rule of thumb for the proportion of data allocated for training?1) 20% for training, 80% for validation2) 50% for training, 50% for validation3) 70% for training, 30% for validation4) 80% for training, 20% for validationExplanation:The correct Answer is : 70% for training, 30% for validationA common rule of thumb is to allocate around 70-80% of the data for training and the remaining for validation. 3- In the context of deploying machine learning models, what is the primary purpose of feature scaling and normalization?1) To prevent overfitting2) To speed up prediction times3) To reduce model complexity4) To ensure consistent data range for predictionsExplanation:The correct Answer is : 4)To ensure consistent data range for predictionsFeature scaling and normalization ensure that input data falls within a consistent range, preventing issues when making predictionsExplore 400 more such question to gain deeper understanding of data science Concepts and crack any interview.________________________________________________________________________________________Some of your Questions AnsweredCan I take the practice test more than once?You can take each practical test multiple times. After completing the practice test, your final result will be published.Do I have a time limit for practice tests?Each test has a time limit.What result is required?The required grade for each practice test is 70% correct answers.Are the questions multiple choice?In order to reflect the form of the interview as much as possible and to raise the level of difficulty, the questions are single and multiple choice.Can I see my answers?You can review all submitted responses and see which were correct and which were not.",
    "instructor": "DataVeta Academy",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/5541474_c3a3_2.jpg"
  },
  {
    "title": "Performing Crossed ANOVA Gage R&R Using Excel 365",
    "price": "Current priceE£399.99",
    "description": "The course presents 7 short videos with supporting downloadable Excel files to teach you the statistics, formulas, and concepts needed to understand how to perform and evaluate a Crossed ANOVA Gage R&R study which is required as part of the PPAP or many Quality Management System processes. What is Gage R&R?When to do Gage R&RWhen to Repeat Gage R&RTypes of Gage R&RMethods (Xbar – R vs. ANOVA)Sum Function (Σ)Population vs. SampleAverage/Mean (μ or x̅)Standard Deviation (σ or s)VarianceNormal DistributionGalton Board DemonstrationNormal Distribution Probability Density Function (PDF)Normal Distribution PDF Area Under the CurveNormal Distribution PDF Probability68–95–99.7 ruleF-Distribution IntroductionF-Distribution Probability Density Function (PDF)F-TestOne-Way ANOVANull HypothesisCalculate F-Statistic and P-ValueOne Way ANOVA Using ExcelTwo-Way ANOVA Gage R&R Study:1. Collect data with multiple parts, operators, and replicates (retests)2. Determine Alpha needed to ignore interaction term and Tolerance3. Calculate Sum of Squares (SS) and Degrees of Freedom (df) for each group4. Calculate Mean Squares for each group, (MS) = SS/df5. Calculate F-Statistics, and P-values then Evaluate Significance of interaction6. Calculate Variance Components, and Gage R&R Values7. How to use the built in Two-Way ANOVA data analysis tool.Interpreting Gage R&R Table:Variance Components% ContributionStdDev(SD)Study Var (6*SD)%Study Var (%SV)%Tol (SV/Tol)Number of Distinct Categories (ndc)Heat MapVarComp Bar ChartData by Parts Dot PlotRange ChartX-Bar ChartBoxplot by OperatorParts x Oper Line PlotHow to Improve Results",
    "instructor": "Joshua Day",
    "requirements": [
      "Will need some experience using Excel"
    ],
    "whatYouWillLearn": [
      "How to perform Crossed ANOVA Gage R&R using Excel",
      "How to interpret Crossed ANOVA Gage R&R results",
      "Understand the basic statistics involved with Gage R&R",
      "Learn about Standard Deviation, Normal Distribution, F-Distribution, F-Test, Mean Squares, Degrees of Freedom, and P-value"
    ],
    "content": [
      {
        "title": "Introduction and Basic Statistics",
        "subsections": [
          "Introduction to ANOVA Crossed Gage R&RPreview06:51",
          "Statistics Basics (Used in ANOVA Crossed Gage R&R)Preview08:06"
        ]
      },
      {
        "title": "More Advanced Statistics and ANOVA Concepts",
        "subsections": [
          "The Normal Distribution08:31",
          "F-Distribution & F-Test09:54",
          "One-Way ANOVA07:01"
        ]
      },
      {
        "title": "Performing and Interpreting Gage R&R",
        "subsections": [
          "Performing and ANOVA Crossed Gage R&R Study in Excel12:26",
          "Analyze ANOVA Gage R&R Results09:08"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5975054_4d1b.jpg"
  },
  {
    "title": "Data Analysis with SQL & RUST DataFusion",
    "price": "Current priceE£399.99",
    "description": "Unlock the potential of data analysis through a powerful combination of SQL and Rust's DataFusion library in this comprehensive course. Designed for data enthusiasts and professionals alike, this course provides a deep dive into effective data manipulation, transformation, and analysis techniques, culminating in the practical skill of converting Parquet dataframes into CSV files.Throughout this course, you'll begin with foundational SQL concepts, covering essential operations such as querying, filtering, aggregating, and joining datasets. By mastering SQL, you'll gain the ability to efficiently retrieve and manipulate data from various sources, forming a strong basis for advanced analysis.Next, you'll transition into the realm of Rust programming, specifically focusing on the DataFusion library. DataFusion offers a high-performance, in-memory query execution framework, enabling you to execute SQL queries on data stored in dataframes. You'll learn how to integrate DataFusion with Rust, harnessing its capabilities to perform complex data transformations and analyses with speed and efficiency.The course is structured around practical, hands-on exercises that reinforce theoretical concepts. You will work on real-world datasets, applying SQL queries and leveraging DataFusion to process and analyze data. As you progress, you'll gain proficiency in converting dataframes into CSV files, a crucial skill for data storage, sharing, and further processing.By the end of this course, you will have developed a robust understanding of SQL and DataFusion, and you'll be adept at transforming raw data into insightful, actionable information. You'll be equipped with the skills to handle diverse data analysis tasks, making you a valuable asset in any data-driven environment.Key Learning Outcomes:Master SQL for data querying, filtering, aggregation...Understand the fundamentals of Rust programming.Utilize the DataFusion library for high-performance data analysis.Perform complex data transformations and analyses with SQL.Convert dataframes into CSV files for storage and sharing.Apply theoretical knowledge through hands-on projects with real-world datasets.Enroll now to elevate your data analysis capabilities with SQL and Rust DataFusion, and become proficient in transforming data into valuable insights.",
    "instructor": "Borivoj Grujicic",
    "requirements": [
      "SQL - basics",
      "RUST - basics"
    ],
    "whatYouWillLearn": [
      "Learn how to work with In-Memory data Formats (parquet, csv...) with raw SQL",
      "Prepare Data Frames that can be used in different visualization tools",
      "Learn how to convert Data Frames to CSV files",
      "Build data Analysis project from the ground up"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview00:32"
        ]
      },
      {
        "title": "Apache Data Fusion",
        "subsections": [
          "Why and What is Apache DataFusionPreview01:13"
        ]
      },
      {
        "title": "Basic Data Analysis",
        "subsections": [
          "Project Setup05:47",
          "First Basic QueryPreview06:27",
          "Finnishing Basic QueriesPreview04:52"
        ]
      },
      {
        "title": "Complex Data Analysis",
        "subsections": [
          "First Complex Query07:34",
          "Finnishing Up With Complex Queries10:16"
        ]
      },
      {
        "title": "From DataFrames to CSV files",
        "subsections": [
          "Creating CSV Writter07:46"
        ]
      },
      {
        "title": "Outro",
        "subsections": [
          "What is next?Preview00:41"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6035678_e29e_2.jpg"
  },
  {
    "title": "Mastering GANs: Image Generation with Python and GauGAN",
    "price": "Current priceE£399.99",
    "description": "Welcome to \"Mastering GANs: Image Generation with Python and GauGAN,\" a comprehensive course designed to equip you with the knowledge and skills to master Generative Adversarial Networks (GANs) for creating high-quality images. Throughout this course, you will delve into the intricacies of GAN architectures, with a special focus on the GauGAN model, which excels in generating realistic images from semantic layouts.The course begins with an introduction to the fundamental concepts of GANs, followed by hands-on sessions where you'll implement and train your own GAN models using Python and Keras. You will learn how to leverage Google Colab for efficient model training, taking advantage of its powerful GPU acceleration to speed up your development process.A significant portion of the course is dedicated to understanding and implementing various loss functions, including Feature Matching Loss and VGG Feature Matching Loss, which are crucial for enhancing the quality of generated images. You will also explore techniques for optimizing GAN performance and generating visually stunning results.In addition to technical skills, the course emphasizes practical applications. You'll work on real-world projects, generating images from semantic layouts and evaluating the results. By the end of the course, you'll have a portfolio of impressive projects that showcase your expertise in advanced image generation techniques.This course is ideal for aspiring data scientists, machine learning engineers, and AI enthusiasts who are looking to deepen their understanding of GANs and their applications. Whether you're aiming to enhance your current skill set or transition into a new career in AI and deep learning, this course will provide you with the tools and knowledge to succeed.Upon successful completion, you'll be well-equipped to pursue advanced roles in the field of AI and deep learning. The hands-on experience and practical knowledge gained from this course will significantly improve your job prospects, making you a valuable asset to any organization looking to leverage cutting-edge image generation technologies.Enroll now and take the first step towards mastering GANs and advancing your career in the exciting world of AI and image generation!",
    "instructor": "Karthik Karunakaran, Ph.D.",
    "requirements": [
      "Computer with Internet Access",
      "Basic Python programming"
    ],
    "whatYouWillLearn": [
      "Develop the technical skills to build and train the GauGAN model.",
      "Learn techniques for preparing and managing image datasets for training GANs.",
      "Understand and apply techniques to optimize and fine-tune the performance of GAN models.",
      "Use various tools and methods to monitor and visualize the training process.",
      "Gain practical experience in deploying and using trained models for image generation tasks.",
      "Utilize Google Colab effectively for running and training deep learning models using GPU acceleration."
    ],
    "content": [
      {
        "title": "Fundamentals",
        "subsections": [
          "IntroductionPreview02:08",
          "About this ProjectPreview00:51",
          "ApplicationsPreview03:51",
          "Job OpportunitiesPreview05:22",
          "Why Python, Keras, and Google Colab?01:39"
        ]
      },
      {
        "title": "Model Development, Training and Inference",
        "subsections": [
          "Set up the working directory00:37",
          "What is inside facades_data?01:22",
          "What is inside code.ipynb?00:21",
          "Launch the code00:32",
          "Enable the GPU00:31",
          "Mount Google Drive01:18",
          "Installing Libraries01:41",
          "Configures environment01:44",
          "Importing libraries01:29",
          "Dataset Path and Data Split Ratio01:20",
          "List of Image Files and Shuffling01:14",
          "Splitting the dataset01:18",
          "Information about our dataset01:40",
          "Setting parameters02:36",
          "Comprehensive preprocessing02:40",
          "Loading and preparing both the training and validation datasets02:05",
          "Examining the shapes02:13",
          "Visualizing sample segmentation maps and real images02:59",
          "SPADE layer03:21",
          "Residual Block with SPADE layers02:43",
          "Implementation of the Gaussian Sampler02:20",
          "Creating a downsampling block03:00",
          "Creates an encoder model02:24",
          "Generator model02:35",
          "Discriminator model03:02",
          "Generator loss function01:32",
          "KL Divergence loss function01:52",
          "Define Feature Matching Loss02:14",
          "Define VGG Feature Matching Loss02:48",
          "Loss function for the discriminator01:48",
          "Custom Keras callback02:25",
          "Defines the GauGAN model05:03",
          "Instantiating and training the GauGAN model02:18",
          "Function to visualize the training progress01:35",
          "Visualize the training progress02:15",
          "Visual assessment03:13"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6069127_1a0e.jpg"
  },
  {
    "title": "ChatGPT API & Postman For Developers: Step by Step API Guide",
    "price": "Current priceE£399.99",
    "description": "Welcome to this course, ChatGPT API & Postman For Developers: Step-by-Step API Guide!Unleash the potential of artificial intelligence in your projects with our comprehensive course on the OpenAI API and ChatGPT API. Stay ahead of the AI curve and harness the latest tools with our step-by-step guide designed for both seasoned developers and beginners.In this course, you'll explore the dynamic world of AI-powered APIs, delving into OpenAI's suite of models, including GPT-3.5, GPT-4, DALL-E, and Whisper. Whether you're an experienced developer or just starting out, our user-friendly approach will help you seamlessly integrate AI into your projects.By enrolling in this course, you will:Build a solid foundation in API fundamentals and understand their crucial role in modern applications.Learn how to easily register for API access with OpenAI.Discover the distinctions between ChatGPT and OpenAI.Gain practical experience working with ChatGPT's AI models: GPT-3.5 and GPT-4.Familiarize yourself with essential tools like Postman and key concepts such as HTTP and JSON.Get hands-on with OpenAI models for tasks such as text completion, code generation, image creation, and speech recognition.Master prompt design and learn effective techniques to control model behavior, including adjusting temperature, setting stop sequences, and configuring for creativity.Understand tokens and pricing to optimize usage and manage costs efficiently.Through engaging examples and interactive exercises, you'll develop the skills to implement AI-driven features in your projects, creating innovative and intelligent solutions that set you apart from the competition.Don't miss out on this opportunity to elevate your development skills and unlock the full potential of AI. Enroll in this course today and take the first step toward a future powered by cutting-edge AI technology.Enroll now for this course, ChatGPT API & Postman For Developers: Step by Step API Guide!Enroll now!",
    "instructor": "Being Commerce",
    "requirements": [
      "Internet Connection",
      "Eager to Learn",
      "Very Basics of API"
    ],
    "whatYouWillLearn": [
      "Understand the fundamentals of OpenAI and ChatGPT APIs",
      "Register for an OpenAI account and get an API key",
      "Understand key concepts: prompts, models, & tokens",
      "Use the AI model behind ChatGPT",
      "Use Postman to work with the OpenAI API",
      "Navigate and utilize the OpenAI Playground effectively",
      "Learn how to manage API costs effectively",
      "Configure OpenAI models for creative output (temperature)",
      "Differentiate between GPT-3.5 models and their use cases",
      "Generate images with DALL-E (Image API)",
      "Transcribe speech using the Whisper API"
    ],
    "content": [
      {
        "title": "Introduction to ChatGPT API",
        "subsections": [
          "ChatGPT API & Postman For Developers: Step by Step API Guide (Promo)Preview01:23",
          "Introduction to Basic TermsPreview18:12",
          "Basic Prompt Engineering03:43"
        ]
      },
      {
        "title": "Setting Up Accounts",
        "subsections": [
          "Setting Up OpenAI Account01:29",
          "Setting Up Postman Account11:59"
        ]
      },
      {
        "title": "Getting Started with API & Postman",
        "subsections": [
          "Creating ChatGPT OpenAI API04:39",
          "Using ChatGPT OpenAI API09:57",
          "Startup ChatGPT OpenAI API11:52"
        ]
      },
      {
        "title": "Understanding APIs Important Terms",
        "subsections": [
          "HTTP13:18",
          "JSON19:34",
          "GPT06:21",
          "Difference03:09"
        ]
      },
      {
        "title": "OpenAI Models & Capabilities",
        "subsections": [
          "Section Overview02:28",
          "Completions Concept06:20",
          "Why Playground09:58"
        ]
      },
      {
        "title": "Working with Models & Capabilities",
        "subsections": [
          "Chat Completion with GPT 3.5 Turbo11:34",
          "Chat Completion with GPT 414:27",
          "Image Completion with Dalle-E14:04",
          "Transcription Completion with Whisper08:36"
        ]
      },
      {
        "title": "Customizing Prompt with Playground",
        "subsections": [
          "Prompt Designing04:52",
          "Temperature Adjustment05:59",
          "Pricing & Tokens of Models06:03",
          "Status of OpenAI02:13"
        ]
      },
      {
        "title": "GPT 3.5 Turbo - Using OpenAI API",
        "subsections": [
          "Basics of GPT 3.5 Turbo03:58",
          "GPT 3.5 Turbo with Examples19:21",
          "(Important) ChatGPT & AI Content Update11:29",
          "Bonus00:54"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5677772_1b5d.jpg"
  },
  {
    "title": "Associate Certified Analytics Professional (aCAP) Exams 2025",
    "price": "Price not found",
    "description": "Master the Associate Certified Analytics Professional (aCAP) Exams 2025 with Expert Practice Tests and Proven Strategies! Get ready to elevate your analytics career and confidently prepare for the Associate Certified Analytics Professional (aCAP) Exams 2025 with this comprehensive course. Designed specifically for the latest exam updates, this course offers expertly crafted practice exams and strategies to ensure you have the knowledge and skills necessary to excel in your certification journey.Why Enroll in This Course?Comprehensive Practice Question Bank: Access 600 carefully designed questions that cover all aspects of the aCAP exam blueprint, ensuring you are fully prepared for exam day.Realistic Exam Simulations: Practice with exams that mirror the actual aCAP exam format, consistently updated to reflect the latest trends and standards in the analytics field.Deepen Your Analytics Knowledge: Enhance your understanding of essential analytics concepts such as data exploration, model creation, and the communication of insights, helping you confidently tackle even the most complex questions.Proven Test-Taking Strategies: Learn expert techniques for managing time, analyzing questions, and developing a strategic approach to maximize your performance.Expert Instruction: Benefit from insights shared by experienced analytics professionals who provide real-world examples, practical advice, and in-depth knowledge to guide your success.Who Should Take This Course?This course is perfect for:aCAP Certification Candidates: Aspiring analytics professionals seeking to validate their foundational knowledge and earn the aCAP certification.Data Analysts and Entry-Level Professionals: Individuals looking to build a solid foundation in analytics and move forward in their careers.IT Professionals and Business Analysts: Those aiming to enhance their data analytics skills and apply analytics-driven solutions to real business problems.Analytics Enthusiasts: Anyone passionate about data and analytics who is eager to gain hands-on experience and practical knowledge.What Will You Achieve?By the end of this course, you will:Master the aCAP Exam Content: Gain a deep understanding of the exam structure, core analytics domains, and essential skills needed to succeed.Apply Analytics Best Practices: Learn to apply data analysis techniques, build models, and deliver actionable insights in real-world situations.Boost Your Confidence: Approach the aCAP exam with the preparation, confidence, and knowledge necessary to succeed on your first attempt.Advance Your Career: Achieve the aCAP certification and unlock exciting opportunities in the fast-growing field of data analytics.Course Features:Robust Practice Exams: Engage in full-length, challenging practice exams that replicate the aCAP exam, giving you a true-to-life testing experience.Detailed Explanations: Receive in-depth reviews and explanations for each question, ensuring you thoroughly understand key concepts and how to apply them.Focus on Core Analytics Domains: Master critical areas such as problem framing, data understanding, and model deployment—crucial for both exam success and real-world application.Strategic Exam Preparation: Learn proven techniques to manage exam day stress and optimize your performance with time-tested strategies.Course Structure:This aCAP exam preparation course is designed to provide an authentic exam experience:2025 Full-Length aCAP Exam - 1 (100 Questions – 180 min)2025 Full-Length aCAP Exam - 2 (100 Questions – 180 min)2025 Full-Length aCAP Exam - 3 (100 Questions – 180 min)2025 Full-Length aCAP Exam - 4 (100 Questions – 180 min)2025 Full-Length aCAP Exam - 5 (100 Questions – 180 min)2025 Full-Length aCAP Exam - 6 (100 Questions – 180 min)Stay Updated with the Latest ContentEnroll today and gain access to regularly updated materials that reflect the latest changes to the aCAP exam. This course equips you with everything you need to pass the exam and take the next step in your analytics career.Join Now and Prepare for Success in the Associate Certified Analytics Professional (aCAP) Exams 2025 !---Disclaimer: The Associate Certified Analytics Professional (aCAP) certification is an independent credential and is not affiliated with, endorsed by, or sponsored by any specific organization. All course content is independently created to support your exam preparation.",
    "instructor": "HASSINI Academy",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/6237481_cb9a.jpg"
  },
  {
    "title": "Introduction to Reinforcement Learning (RL)",
    "price": "Price not found",
    "description": "Unlock the world of Deep Reinforcement Learning (RL) with this comprehensive, hands-on course designed for beginners and enthusiasts eager to master RL techniques in PyTorch. Starting with no prerequisites, we’ll dive into foundational concepts—covering the essentials like value functions, action-value functions, and the Bellman equation—to ensure a solid theoretical base.From there, we’ll guide you through the most influential breakthroughs in RL:Playing Atari with Deep Reinforcement Learning – Discover how RL agents learn to master classic Atari games and understand the pioneering concepts behind the first wave of deep Q-learning.Human-level Control Through Deep Reinforcement Learning – Take a closer look at how Deep Q-Networks (DQNs) raised the bar, achieving human-like performance and reshaping the field of RL.Asynchronous Methods for Deep Reinforcement Learning – Explore Asynchronous Advantage Actor-Critic (A3C) methods that improved both stability and performance in RL, allowing agents to learn faster and more effectively.Proximal Policy Optimization (PPO) Algorithms – Master PPO, one of the most powerful and efficient algorithms used widely in cutting-edge RL research and applications.This course is rich in hands-on coding sessions, where you’ll implement each algorithm from scratch using PyTorch. By the end, you’ll have a portfolio of projects and a thorough understanding of both the theory and practice of deep RL.Who This Course is For:Ideal for learners interested in machine learning and AI, as well as professionals looking to add reinforcement learning with PyTorch to their skillset, this course ensures you gain the expertise needed to develop intelligent agents for real-world applications.",
    "instructor": "Maxime Vandegar",
    "requirements": [
      "Basic Machine Learning Knowledge"
    ],
    "whatYouWillLearn": [
      "Core Concepts of Reinforcement Learning",
      "Implementing RL Algorithms in PyTorch",
      "Building Agents to Play Atari Games",
      "Exploring Policy-Based and Value-Based Methods",
      "Mastering Exploration vs. Exploitation"
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/6275917_5a35_2.jpg"
  },
  {
    "title": "Streamlit Course - Create Python Web Apps Fast & Easy!",
    "price": "Current priceE£799.99",
    "description": "Do you want to build interactive web apps with Python without the hassle of learning complex web frameworks? Streamlit is the perfect solution! With Streamlit, you can create powerful, data-driven web applications with just a few lines of Python code—no need for HTML, CSS, or JavaScript.In this comprehensive, hands-on course, you'll go from a complete beginner to confidently building and deploying Streamlit apps. Whether you're a data scientist, Python developer, or analyst, this course will teach you everything you need to know about building interactive dashboards, visualizing data, and handling user inputs using Streamlit’s intuitive API.What You'll Learn:Introduction to Streamlit – Install, run, and understand the basics of Streamlit.Building Your First App – Create a \"Hello, World!\" app and work with text elements.Widgets & Inputs – Use buttons, checkboxes, dropdowns, sliders, and more.App Layout & Structure – Organize apps using sidebars, columns, containers, and tabs.Session State & Interactivity – Store user inputs and dynamically update the UI.Data Visualization – Create stunning charts with Matplotlib, Seaborn, Plotly, and Streamlit’s built-in tools.Forms & User Inputs – Build and process interactive forms.Advanced Components – Use notifications, alerts, progress bars, and spinners.By the end of this course, you’ll have the skills to build and deploy powerful web apps with Python—quickly and effortlessly!",
    "instructor": "Onur Baltacı",
    "requirements": [
      "Basic Python Programming Knowledge"
    ],
    "whatYouWillLearn": [
      "Learn how to build and deploy interactive web apps using Streamlit with Python, without needing HTML or JavaScript.",
      "Gain hands-on experience with Streamlit’s components like buttons, sliders, checkboxes, and forms to create dynamic user interfaces.",
      "Master data visualization by integrating libraries like Matplotlib, Seaborn, and Plotly for interactive charts and graphs.",
      "Understand advanced Streamlit features like session state management and custom layouts to create highly interactive and responsive apps."
    ],
    "content": [
      {
        "title": "Course Introduction",
        "subsections": [
          "IntroductionPreview00:34",
          "Course OutlinePreview02:41"
        ]
      },
      {
        "title": "Introduction to Streamlit",
        "subsections": [
          "What is Streamlit02:29",
          "Overview of Streamlit Page03:13",
          "Installing Streamlit and Running Your First Streamlit App05:46",
          "Basic Streamlit App Structure04:53"
        ]
      },
      {
        "title": "Streamlit Widgets and Inputs",
        "subsections": [
          "Title, Header and Subheader03:28",
          "Text Elements03:46",
          "ButtonsPreview05:08",
          "Checkboxes04:49",
          "Radio Buttons04:15",
          "Dropdown Selections04:51",
          "Slider and Number Input04:44",
          "Text Input and Text AreaPreview03:24",
          "Date Input and Time Input04:24"
        ]
      },
      {
        "title": "Streamlit Key Components and Advanced Features",
        "subsections": [
          "Layout and Structuring Apps08:43",
          "Adding Interactivity with Session State04:54",
          "Displaying Data and Visualizations09:36",
          "Forms06:04",
          "Advanced Streamlit Components07:50"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6541309_4f48.jpg"
  },
  {
    "title": "Foundations of A.I.: Actions Under Uncertainty",
    "price": "Current priceE£399.99",
    "description": "\"Real world often revolves around uncertainty. Humans have to consider a degree of uncertainty while taking decisions. The same principle applies to Artificial Intelligence too. Uncertainty in artificial intelligence refers to situations where the system lacks complete information or faces unpredictability in its environment. Dealing with uncertainty is a critical aspect of AI, as real-world scenarios are often complex, dynamic, and ambiguous. This course is a primer on designing programs and probabilistic graphical models for taking decisions under uncertainty. This course is all about Uncertainty, causes of uncertainty, representing and measuring Uncertainty and taking decisions in uncertain situations. Probability gives the measurement of uncertainty. We will go through a series of lectures in understanding the foundations of probability theorem. we will be visiting Bayes theorem, Bayesian networks that represent conditional independence. Bayesian Networks has found its place in some of the prominent areas like Aviation industry, Business Intelligence, Medical Diagnosis, public policy etc.In the second half of the course, we will look into the effects of time and uncertainty together on decision making. We will be working on Markov property and its applications. Representing uncertainty and developing computations models that solve uncertainty is a very important area in Artificial Intelligence\"",
    "instructor": "Prag Robotics",
    "requirements": [
      "Basic Understanding of Programming",
      "Python Fundamentals",
      "Probability Theorem"
    ],
    "whatYouWillLearn": [
      "Probability theorem",
      "Conditional Independence",
      "Bayesian Networks",
      "Probabilistic Graphical Models",
      "Markov Property"
    ],
    "content": [
      {
        "title": "About the Program",
        "subsections": [
          "Course IntroductionPreview02:59",
          "Course Outline01:35"
        ]
      },
      {
        "title": "Actions Under Uncertainty",
        "subsections": [
          "Actions Under UncertaintyPreview08:04",
          "Probability Notation14:36",
          "Independence and Conditional Independence11:11",
          "Action Under Uncertainty3 questions"
        ]
      },
      {
        "title": "Software Installation",
        "subsections": [
          "Installing Anaconda Distribution03:13",
          "Handling Jupyter Notebooks 102:53",
          "Handling Jupyter Notebooks 202:04",
          "Handling Jupyter Notebooks 303:19",
          "Handling Jupyter Notebooks 406:01",
          "Handling Jupyter Notebooks 503:32"
        ]
      },
      {
        "title": "Bayesian Networks",
        "subsections": [
          "Bayes Theorem12:29",
          "Bayesian Networks10:40",
          "Implementation of Bayesian Networks22:55",
          "Inference in Bayesian Networks09:10",
          "Applications of Bayesian Networks06:02",
          "Bayesian Networks5 questions"
        ]
      },
      {
        "title": "Time and Uncertainty",
        "subsections": [
          "Time and Uncertainty09:56",
          "Markov Chains12:52",
          "Implementation of Markov Chain10:52",
          "Hidden Markov models15:39",
          "Implementation of HMM in Python14:59",
          "Time and Uncertainty5 questions"
        ]
      },
      {
        "title": "About the Program",
        "subsections": [
          "Course Conclusion02:03"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5677062_2e98.jpg"
  },
  {
    "title": "25 Key Machine Learning Algorithms - Math, Intuition, Python",
    "price": "Current priceE£799.99",
    "description": "Do you want to understand machine learning algorithms and how artificial intelligence works but don’t know where to start? Or perhaps you already have some knowledge and want to deepen your understanding of AI-driven algorithms?- This course is exactly what you need!In this course, you’ll master 25 key machine learning algorithms:Simple Linear RegressionMultiple Linear RegressionLogistic RegressionDecision TreesK-meansModel EvaluationNaive BayesRidge RegressionBaggingRandom ForestBoostingLASSOKNNGradient BoostingPCA - Principal Component AnalysisXGBoostLDA - Linear discriminant analysisQDA - Quadratic discriminant analysisAgglomerative Hierarchical ClusteringHard-Margin SVMSVMDBSCANt-SNEIsolation ForestPerceptronEach lesson is designed to provide clear, structured learning with three essential components:Theory – A deep dive into the mathematical concepts behind each algorithmExamples – Simple scenarios to illustrate how each algorithm worksImplementation – Step-by-step Python coding to bring each algorithm to lifeWhy This Course Stands Out:No long videos – Just focused learning! This course is perfect for those who prefer reading over passive video watching.Math made simple – Algorithms are explained in an accessible way, with intuitive examples to help you understand their logic.Hands-on coding – You’ll implement every algorithm from scratch, ensuring you truly understand the process.Ready to start your journey in Machine Learning?",
    "instructor": "Mateusz Soczewka",
    "requirements": [
      "Course from the basics (for beginners)",
      "Basic mathematical knowledge",
      "Basic knowledge of Python (numpy)"
    ],
    "whatYouWillLearn": [
      "Master 25 most important ML algorithms from scratch",
      "Step-by-step examples with math calculations",
      "Implement each algorithm FROM SCRATCH!",
      "Master the essential theory – no interview will be a problem",
      "Mathematics behind ML algorithms",
      "Intuition behind mathematical formulas",
      "Regression, Classification, Clustering, Dimensionality Reduction, and Anomaly Detection",
      "Ready to build your own ML projects",
      "Enhance your programming skills in Python"
    ],
    "content": [
      {
        "title": "Getting Started with Google Colab",
        "subsections": [
          "How to start?01:04"
        ]
      },
      {
        "title": "1. Simple Linear Regression",
        "subsections": [
          "IntroPreview01:37",
          "Simple Linear RegressionPreview00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "2. Multiple Linear Regression",
        "subsections": [
          "IntroPreview01:09",
          "Multiple Linear Regression00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "3. Logistic Regression",
        "subsections": [
          "IntroPreview01:19",
          "Logistic Regression00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "4. Decision Trees",
        "subsections": [
          "IntroPreview01:10",
          "Decision Trees00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "5. K-means",
        "subsections": [
          "IntroPreview01:03",
          "K-means00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "6. Model Evaluation",
        "subsections": [
          "IntroPreview01:16",
          "Model Evaluation00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "7. Naive Bayes",
        "subsections": [
          "IntroPreview01:12",
          "Naive Bayes00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "8. Ridge Regression",
        "subsections": [
          "Intro01:48",
          "Ridge Regression00:04",
          "Test5 questions"
        ]
      },
      {
        "title": "9. Bagging",
        "subsections": [
          "Intro01:46",
          "Bagging00:04",
          "Test5 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6441831_d5a4_3.jpg"
  },
  {
    "title": "Shiny for Python Masterclass: Build Dashboards using Shiny",
    "price": "Current priceE£799.99",
    "description": "Shiny for Python: A Powerful Alternative to StreamlitShiny for Python is an excellent alternative to Streamlit, offering greater ease of customization in many ways. It enables you to create dashboards that stand out with beautiful aesthetics while maintaining functionality and performance. If you’re already familiar with Streamlit, I challenge you to explore Shiny for Python—it might become your new favorite tool.Build Interactive, Dynamic Web Applications with EaseDo you want to create interactive, dynamic web applications using Python without becoming a full-fledged web developer? Look no further! Shiny for Python simplifies the process of turning your data analysis workflows into professional-grade dashboards and web apps—all powered by Python.Master Shiny for Python in This CourseIn this course, you’ll gain expertise in Shiny for Python, a framework that brings interactivity to your data visualizations and analyses. From crafting simple applications to building complex, feature-rich dashboards, you’ll learn essential concepts, tools, and techniques step by step.Whether you’re a data scientist, analyst, or Python enthusiast, this course will equip you with the skills to build stunning, functional applications that provide actionable insights and engage users.What You’ll LearnShiny Basics:• Create your first “Hello World” Shiny app in Python.Advanced Features:• Leverage reactivity for real-time app updates.• Integrate popular libraries like Pandas and Plotly.User Experience Design:• Craft intuitive and visually appealing dashboards.• Optimize layouts for different screen sizes.Real-World Use Cases:• Build apps for data exploration, reporting, and real-time monitoring.Who This Course Is For• Data Scientists: Enhance your analyses beyond Jupyter notebooks by adding interactivity and seamlessly sharing insights.• Python Developers: Create powerful web apps without needing to learn JavaScript or HTML.• Business Analysts: Develop self-service dashboards for stakeholders.• Students & Enthusiasts: Master a high-demand skill in the growing data science field and unlock opportunities as a freelance consultant.Why Take This Course?• No prior web development experience required!• Hands-on coding exercises and real-world projects.• Practical examples tailored for data science, business analytics, and research applications.• Tips and tricks for creating polished, high-performance dashboards.By the end of this course, you’ll have the confidence to design and deploy Shiny-powered Python apps that bring your data to life. Let’s build something amazing together!",
    "instructor": "Olabode Alamu",
    "requirements": [
      "You should have Python installed on your computer and be able to run your python code in an IDE of your choice.",
      "A beginner level knowledge of python is adequate (i.e. you are comfortable with the common python objects such as lists, strings, tuples, dictionaries and python functions)."
    ],
    "whatYouWillLearn": [
      "Learn how to develop beautiful web apps and dashboards using the Shiny Library in Python.",
      "Learn how to create effective and compelling visuals using plotly express.",
      "Learn how to tackle any dashboard project given the dataset.",
      "Learn how to add reactivity and interactivity to your Shiny Dashboards."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Welcome to the coursePreview08:41",
          "Read this: Please watch videos at 1.25 speed.Preview00:32",
          "Install libraries00:23",
          "Install Libraries Video walkthrough (Optional)02:29",
          "The 7 steps to building any dashboard05:26",
          "Data Visualization 10107:32",
          "Brief intro to pandas05:35",
          "Hello world!Preview08:02",
          "Lets make the hello world app more beautiful with a Card element01:33",
          "How to set a theme in Shiny03:06",
          "EXERCISE: Make the dashboard look like thisPreview01:01",
          "Hint to exercise00:10",
          "Download Data Files here00:03"
        ]
      },
      {
        "title": "Basic Layout in Shiny",
        "subsections": [
          "Create sidebar layout in Shiny06:42",
          "Arrange your app layout with columns08:19"
        ]
      },
      {
        "title": "Quick Plotly Express Refresher (Optional Section)",
        "subsections": [
          "Data Viz 10102:53",
          "ScatterplotPreview05:19",
          "Pie Charts05:37",
          "Boxplot and Violin plot04:47",
          "Histogram04:35",
          "Bar Charts04:56",
          "Mapbox06:27",
          "Plotly Templates05:59"
        ]
      },
      {
        "title": "Gapminder Dashboard (Basic version)",
        "subsections": [
          "What we will build-- Gapminder Dashboard01:08",
          "Get the Data00:02",
          "Lets build the Gapminder dashboard using Shiny For Python14:34"
        ]
      },
      {
        "title": "Titanic Dashboard",
        "subsections": [
          "What we will build- Titanic DashboardPreview01:02",
          "Preprocess the data and Add dropdown widgets04:41",
          "Add Histograms to the dashboard05:48",
          "Part 308:46"
        ]
      },
      {
        "title": "US Cities Population Dashboard",
        "subsections": [
          "What we will build-- US Cities Dashboard using Shiny for PythonPreview02:19",
          "Get the Data00:02",
          "Add slider and dropdown widget Redo15:38",
          "Add mapbox chart Redo11:39"
        ]
      },
      {
        "title": "Iris Dashboard",
        "subsections": [
          "Introduction to what we will build - Iris DashboardPreview01:49",
          "Add Barchart10:24",
          "Get the Data00:02",
          "Build Iris Dashboard using SHiny Python _Part 1 Add sidebar and dropdown widget07:05",
          "Build the iris dashboard using Shiny Python Part 2 Add scatterplot11:02",
          "Build the Iris Dashboard using Shiny Python Part 3 - Add two histograms09:14",
          "Exercise- Add the Histograms to the layoutPreview00:51",
          "Solution to Exercise01:34",
          "Adjust the size parameter of the plot00:44",
          "Lets adjust the theme of the dashboard01:37"
        ]
      },
      {
        "title": "Spotify Dashboard built using Shiny for Python",
        "subsections": [
          "What we will build -- Spotify DashboardPreview01:20",
          "Get the Data00:02",
          "Data processing for the dashboard12:33",
          "Add the correlation heatmap and bar charts09:15",
          "Add the histograms for Track popularity and Track tempo for the different genres05:42",
          "EXERCISE: Add Histogram to the dashboard for track duration02:36",
          "SOLUTION02:59",
          "Code revision05:16"
        ]
      },
      {
        "title": "Reference: Widgets in Shiny",
        "subsections": [
          "Dropdown widget in Shiny (input_select)06:08",
          "Multiselect Dropdown in Shiny06:40",
          "Checkbox Group in Shiny08:45"
        ]
      },
      {
        "title": "Exploratory Data Analysis",
        "subsections": [
          "EDA Iris Dataset16:49"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6328699_f4aa_9.jpg"
  },
  {
    "title": "Optimization Principles (Pyomo, GAMS & Mosel)",
    "price": "Price not found",
    "description": "The course will equip you with forecasting skills using linear regression. Throughout this course, you'll gain practical insights by forecasting CO₂ emissions up to the year 2050, utilizing historical emissions data from WorldBank official databases! 2. Course Overview:Master the art of modelling and solving real-world optimization problems using three of the most widely used optimization and modelling languages: GAMS, Pyomo, and Mosel. These tools are essential in fields such as economics, finance, logistics, energy, and transport, enabling professionals to make data-driven decisions and optimize complex systems efficiently.Gain hands-on experience with Pyomo, GAMS, and Mosel—each highly regarded in academia, industry, and research. Pyomo integrates seamlessly with Python, making it an accessible choice for those familiar with the language, while GAMS and Mosel offer powerful capabilities for large-scale optimization problems.Strengthen your expertise through practical examples, real-world case studies, and industry-relevant projects. Develop the confidence to apply these tools effectively in professional and academic settings, solving complex optimization challenges with ease. By the end of this course, you’ll have a strong foundation to tackle real optimization problems and enhance decision-making in various industries.Strengthen your expertise through practical examples, real-world case studies, and industry-relevant projects. Develop the confidence to apply these tools effectively in professional and academic settings, solving complex optimization challenges with ease. By the end of this course, you’ll have a strong foundation to tackle real optimization problems and enhance decision-making in various industries.Strengthen your expertise through practical examples, real-world case studies, and industry-relevant projects. Develop the confidence to apply these tools effectively in professional and academic settings, solving complex optimization challenges with ease. By the end of this course, you’ll have a strong foundation to tackle real optimization problems and enhance decision-making in various industries.3. Join",
    "instructor": "Dr.S. Giannelos",
    "requirements": [
      "There are no prerequisites except basic knowledge of Python"
    ],
    "whatYouWillLearn": [
      "join the Q&A",
      "All the code, is available for you to download! Plus: publications and tutorials!",
      "YOU WILL LEARN the 3 most important languages (Pyomo, GAMS, and Mosel ) for building optimization models. Very useful for industry and academia.",
      "FAST HELP WITHIN HOURS: Have questions or need guidance? Send a message and get a response within hours!"
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/6350149_51ed_4.jpg"
  },
  {
    "title": "From Recipe to Chef: Become an LLM Engineer 100+ Projects",
    "price": "Current priceE£1,199.99",
    "description": "From Recipe to Chef: Become an LLM Engineer (Food Analogies) is a fun, beginner-friendly course that teaches you how to master Large Language Models (LLMs) without writing a single line of code. Whether you're curious about AI, looking to break into the world of language models, or want to become an LLM engineer, this course is your gateway to understanding and building with powerful tools like ChatGPT, Claude, Gemini, and LLaMA. We make technical concepts simple and relatable using clever food metaphors—so you can go from kitchen newbie to AI chef in no time.You'll explore how LLMs are built, trained, deployed, and evaluated through easy-to-understand analogies. Imagine tokenization as chopping vegetables, training as baking at scale, or prompt engineering as seasoning a dish just right. Each module is carefully crafted to introduce a new skill, from data preparation and fine-tuning to evaluation and deployment. By the end, you’ll be fluent in core LLM concepts like model architecture, pretraining, transfer learning, prompt optimization, model evaluation metrics like perplexity and BLEU score, and deploying your own LLM-powered applications using tools like FastAPI, Gradio, Hugging Face Spaces, and LangChain.This course is perfect for students, educators, creators, entrepreneurs, and professionals from non-technical backgrounds who want to learn AI fundamentals and build real-world applications powered by large language models. We take you step by step through the AI lifecycle—starting from \"What is a language model?\" all the way to deploying your own chatbot, summarizer, or recommender app. You'll learn to use no-code tools, experiment with real prompts, fine-tune existing models, evaluate outputs, and even explore career paths like prompt engineer, AI product manager, and LLM architect.No coding experience is required. You’ll learn how to communicate with LLMs using natural language, design smart and effective prompts, and understand what's happening behind the scenes—from data collection and tokenization to the model's prediction process and its computational needs using GPUs and TPUs. You’ll also cover bias detection, hallucinations, feedback loops, and strategies to monitor and improve your AI systems over time.By the end of the course, you’ll have a solid foundation in LLM theory, a portfolio of hands-on AI projects, and the confidence to step into the growing world of generative AI. Whether you're aiming to build your own AI product, join an AI startup, contribute to open-source projects, or simply impress your friends with your understanding of machine learning concepts, this course will get you there—with a full plate of knowledge and a side of fun.If you're ready to go from recipe reader to LLM chef, join us on this flavorful journey through the world of large language models, where every concept is explained with relatable metaphors and practical examples.",
    "instructor": "Vivian Aranha • 100.000+ Students",
    "requirements": [
      "No programming experience required – this course is designed for absolute beginners.",
      "Curiosity about AI and how language models work is more than enough to get started.",
      "Basic computer skills like using a browser, uploading files, and typing are helpful.",
      "A laptop or desktop with internet access – no fancy hardware needed.",
      "Optional: A free OpenAI API key (for hands-on projects using GPT).",
      "Optional: Interest in building chatbots, writing prompts, or exploring AI careers.",
      "All tools used (like Gradio, Google Colab, or LangChain templates) are free and beginner-friendly."
    ],
    "whatYouWillLearn": [
      "Understand what large language models (LLMs) are and how they work using real-world analogies",
      "Identify key ingredients that power LLMs, like training data, tokenization, and data quality.",
      "Explain how LLMs are trained using concepts like batches, epochs, and loss functions.",
      "Write better prompts using techniques like zero-shot, few-shot, and chain-of-thought.",
      "Customize models using fine-tuning and tools like Hugging Face and LoRA.",
      "Evaluate model performance using both quantitative and qualitative metrics.",
      "Deploy LLMs using APIs, FastAPI/Flask, and host them on platforms like Hugging Face Spaces.",
      "Build full LLM-powered applications using no-code tools and LangChain.",
      "Monitor and improve your AI models using logs, feedback loops, and A/B testing.",
      "Monitor and improve your AI models using logs, feedback loops, and A/B testing."
    ],
    "content": [
      {
        "title": "What’s Cooking? Intro to LLMs",
        "subsections": [
          "Introduction to \"What’s Cooking? Intro to LLMs\"Preview02:17",
          "What is a Language Model?Preview05:32",
          "The Evolution of LLMs – From typewriters to gourmet robotsPreview07:14",
          "How LLMs “predict the next word” (Autocomplete Sandwich Making)Preview05:13",
          "Differences Between LLMs and Traditional AI (Microwave vs Chef Cooking)Preview05:24",
          "Popular LLMs Overview: GPT, Claude, Gemini, LLaMA (Restaurant Tour)Preview06:47"
        ]
      },
      {
        "title": "Ingredients Matter – Understanding Data",
        "subsections": [
          "Introduction to \"Ingredients Matter – Understanding Data\"Preview02:40",
          "What is Training Data? (Pantry stocking)04:27",
          "Tokenization – Chopping Text into Bite-Sized Pieces05:01",
          "Datasets for LLMs: Wikipedia, Books, Web Text (Supermarket shopping list)05:57",
          "Garbage In = Garbage Out: Data Quality Matters04:56",
          "Bias in Data = Spicy for One, Bland for Another05:01"
        ]
      },
      {
        "title": "Cooking at Scale – Model Training Basics",
        "subsections": [
          "Introduction to \"Cooking at Scale – Model Training Basics\"Preview02:37",
          "What Happens During Model Training? (Mixing, baking, adjusting)04:24",
          "Epochs, Batches, and Loss – The Cooking Rounds04:33",
          "GPUs and TPUs – Industrial Ovens for Training04:30",
          "Pretraining vs Fine-tuning – Master Recipe vs Regional Twist05:22",
          "Cost of Training – The LLM Grocery Bill05:00"
        ]
      },
      {
        "title": "Prompt Engineering – Seasoning for the Perfect Output",
        "subsections": [
          "Introduction to \"Prompt Engineering – Seasoning for the Perfect Output\"Preview03:16",
          "Anatomy of a Prompt – The Secret Spice Blend05:00",
          "Prompt Styles: Zero-shot, Few-shot, Chain-of-Thought (Like salt, chili, herbs)05:26",
          "Roleplay Prompts – “Pretend You’re a Barista”04:31",
          "Prompt Optimization – From Raw to Well-Cooked04:31",
          "Prompt Evaluation – Taste Test for Prompts04:37"
        ]
      },
      {
        "title": "Fine-Tuning – Customizing the Recipe",
        "subsections": [
          "Introduction to \"Fine-Tuning – Customizing the Recipe\"Preview03:12",
          "What is Fine-tuning? – Grandma’s Touch to a Classic Recipe04:34",
          "Transfer Learning – Borrowing a Cake Base and Adding Frosting04:01",
          "Techniques: Full Fine-Tuning vs LoRA (Low-Rank Adaptation)04:28",
          "Fine-Tuning on Your Own Data (Your Kitchen, Your Rules)04:44",
          "Tools for Fine-Tuning: Hugging Face, Google Colab, PEFT05:45"
        ]
      },
      {
        "title": "Evaluating LLMs – Taste Testing",
        "subsections": [
          "Introduction to \"Evaluating LLMs – Taste Testing\"Preview03:19",
          "Why Evaluation Matters – The Chef’s Final Check04:03",
          "Quantitative Metrics: Perplexity, BLEU, ROUGE05:24",
          "Qualitative Metrics: Human Feedback, Usefulness, Relevance04:56",
          "Hallucinations and Model Errors – Unexpected Flavors04:47",
          "Bias Detection – Catering to Different Dietary Preferences04:48"
        ]
      },
      {
        "title": "Serving Your Dish – Deploying LLMs",
        "subsections": [
          "Introduction to \"Serving Your Dish – Deploying LLMs\"Preview03:15",
          "What is Deployment? – Opening a Pop-Up Restaurant04:49",
          "Creating APIs using FastAPI or Flask08:12",
          "Using Gradio/Streamlit for Demo UIs (Food Truck Presentation)05:14",
          "Hosting Options: Hugging Face Spaces, AWS, GCP05:29",
          "Scaling and Monitoring – Keeping the Buffet Running Smoothly04:52"
        ]
      },
      {
        "title": "Building LLM-powered Apps – Your Own Food Truck",
        "subsections": [
          "Introduction to \"Building LLM-powered Apps – Your Own Food Truck\"Preview03:14",
          "App Use Cases: Chatbots, Summarizers, Recommenders05:10",
          "No-Code Tools: LangChain Templates, GPT Builder, Voiceflow05:42",
          "LLM + Database: The Smart Menu05:03",
          "Chaining with LangChain – The AI Assembly Line05:24",
          "Project: Build a Fully Functional LLM App with a Custom Interface05:35"
        ]
      },
      {
        "title": "Keeping it Fresh – Monitoring and Improving",
        "subsections": [
          "Introduction to \"Keeping it Fresh – Monitoring and Improving\"Preview03:20",
          "Feedback Loops – Like Yelp Reviews for AI05:26",
          "Logging and Monitoring – Smart Kitchen Cameras05:14",
          "A/B Testing – Which Dessert Wins?05:33",
          "Model Drift – When Taste Changes Over Time05:00",
          "Updating Prompts, Datasets, and Deployments05:24"
        ]
      },
      {
        "title": "Becoming a Master Chef – Career in LLM Engineering",
        "subsections": [
          "Introduction to 'Becoming a Master Chef – Career in LLM Engineering\"Preview03:10",
          "Career Paths in LLM: Engineer, Architect, Prompt Specialist05:50",
          "Building Your Portfolio – Your AI Cookbook04:53",
          "Contributing to Open Source: Datasets, Models, Tools04:53",
          "Resume Tips, Interviews, and Technical Questions05:54",
          "Final Capstone Project: Create & Deploy Your Own LLM App05:34"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6561937_c4ca_3.jpg"
  },
  {
    "title": "Analysing Tweets using R",
    "price": "Current priceE£399.99",
    "description": "People around the globe make over 500 million tweets per day. So, one can only imagine the sheer volume of data available with Twitter. This data is a treasure trove of information. However, one needs to know how to gather this data and then conduct the needed analysis.This course provides all the information regardingHow to gather data from Twitter using R ProgrammingHow to conduct basic analysis of the data gathered from TwitterHow to extract the Emotion expressed in the Tweets gatheredThe course also discusses associated APIs required for analysing Twitter data like Google Maps API.To take full advantage of the course, it will be required to create a developer account with Twitter. All the necessary steps for getting a Twitter Developer Account is provided in the course. However, it must be noted that it is the discretion of Twitter whether they will grant a Twitter Developer account against an application. Nevertheless, all the contents of the course can be followed and understood without a Twitter Developer account. Only difference will be that the data extracted from Twitter will be restricted. With limited data, the analysis possible will be limited.We will use R Programming throughout this course. Thus, this course requires that the participants are conversant with R Programming.If you prefer any other programming language (like. Python, etc.), then you can use this course to learn all the nuances of analysing Twitter Data and apply the same in programming in your language of your preference.",
    "instructor": "Partha Majumdar",
    "requirements": [
      "Must have knowledge of Programming",
      "Must have knowledge of R Programming",
      "Must have knowledge of using RStudio"
    ],
    "whatYouWillLearn": [
      "Gathering Data from Twitter",
      "Using Twitter API",
      "Using Google Map API",
      "Analysing Twitter Data",
      "Lexicon based Emotion Analysis",
      "Use of many related R Libraries"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview02:40",
          "If you want to Learn R Programming or brush up on R Programming ...Preview01:45"
        ]
      },
      {
        "title": "Introduction to Twitter",
        "subsections": [
          "What is Twitter and Why it is used?Preview02:17"
        ]
      },
      {
        "title": "Programming around Twitter",
        "subsections": [
          "Twitter Developer AccountPreview07:15",
          "Fetching Tweets for Search String(s) and/or Hash Tag(s)Preview12:47",
          "Getting Google Maps API Key04:25",
          "Fetching Tweets for a Location13:42",
          "Data fetched from Twitter04:56",
          "Quiz: Fetching Tweets using R5 questions"
        ]
      },
      {
        "title": "Displaying Information about the fetched Tweets",
        "subsections": [
          "Displaying Fetched Tweets using DT19:45",
          "Creating Time Series Charts for the fetched Tweets13:26",
          "Basic Statistics - Introduction02:42",
          "Tweet Country Analysis09:52",
          "Tweet Place Analysis04:50",
          "Tweet Language Analysis06:24",
          "Tweet User Analysis11:10",
          "Tweet Source Analysis06:41",
          "Tweet Hash Tag Analysis10:13",
          "Quiz: Displaying Information about Tweets5 questions"
        ]
      },
      {
        "title": "Programming Maps",
        "subsections": [
          "Location Analysis with Maps09:52",
          "Interactive Maps with Leaflet06:00",
          "Quiz: Maps5 questions"
        ]
      },
      {
        "title": "Emotion Analysis",
        "subsections": [
          "Section Introduction03:35",
          "Extracting Words from fetched Tweets09:43",
          "Finding Most Prevalent Emotion15:50",
          "Quiz: Emotion Analysis5 questions"
        ]
      },
      {
        "title": "Course Closure",
        "subsections": [
          "Next Steps04:23",
          "About Me (Optional)07:32"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/2922202_84ad_6.jpg"
  },
  {
    "title": "Data Analyst Portfolio Creation to Build Practical Skills",
    "price": "Current priceE£699.99",
    "description": "Data Analyst Portfolio Creation Course - Enroll Now & Build Your Professional Portfolio!Showcase Your Data Analyst Skills & Stand Out to EmployersAre you an aspiring data analyst looking to demonstrate your skills and enhance your job prospects? This course provides a step-by-step guide to building a professional portfolio that highlights your data analysis abilities, helping you gain visibility among recruiters and potential clients.Why This Course Was CreatedMany aspiring data analysts face the challenge of proving their capabilities without prior work experience. A well-structured portfolio can effectively showcase your skills, increasing your chances of catching the attention of employers and freelance clients. This course is designed to equip you with the practical knowledge and tools needed to create an impactful data analyst portfolio.What You’ll Learn in This CourseDevelop a professional data analyst portfolio that highlights your skills. Structure and document real-world projects to showcase your expertise. Master data visualization techniques to enhance your presentations. Build and host your portfolio using platforms like GitHub, Notion, or Tableau Public. Optimize your LinkedIn and social media presence to increase visibility. Improve your confidence in presenting your work during interviews.Introducing Data Analyst Portfolio CreationA step-by-step, hands-on course designed to help you create a structured, well-documented portfolio that demonstrates your data analysis skills.Course Modules:Understanding the Value of a Portfolio Selecting and Executing Portfolio Projects Creating and Presenting Your Work Setting Up Your Portfolio Website Increasing Portfolio Visibility & Networking Showcasing Your Portfolio in Interviews & Freelancing Capstone Project: Complete & Publish Your PortfolioExclusive Resources to Enhance Your LearningData Analyst Portfolio Templates – Streamline your workflow. Insider Tips – Learn how to optimize your portfolio for recruiters.What Students Are Saying:This course gave me a clear roadmap to build my portfolio. Now I feel more confident showcasing my skills! – John D. The real-world project examples helped me demonstrate my abilities effectively. – Sarah K. After applying the LinkedIn strategies from this course, I started getting more recruiter interactions. – Michael B.Frequently Asked QuestionsQ: Is this course suitable for beginners?A: Yes! Even if you're just starting, this course will guide you through building a professional portfolio from scratch.Q: How much time will this course require?A: The course is self-paced, allowing you to complete it at your convenience with lifetime access.Get Started Today!Enroll now and take the first step toward creating a compelling data analyst portfolio that showcases your skills and expertise.ENROLL NOW",
    "instructor": "Lasisi Akeem",
    "requirements": [
      "Basic Understanding of Data Analysis",
      "Experience with Spreadsheet Tools (Excel/Google Sheets)",
      "Familiarity with Any Data Analysis Tool",
      "Access to a Computer with Internet Connection",
      "Willingness to Learn & Apply Knowledge – No prior portfolio-building experience is needed! If you're eager to learn, apply practical insights, and put in the work, you’ll walk away with a strong portfolio.",
      "No coding or web development experience required! The course provides beginner-friendly methods to create and showcase your portfolio without coding."
    ],
    "whatYouWillLearn": [
      "Understand the Purpose of a Data Analyst Portfolio – Recognize the value of a portfolio in showcasing skills and experience in data analysis.",
      "Curate Meaningful Projects – Learn how to select and present projects that highlight analytical and problem-solving skills.",
      "Develop Data Visualization and Storytelling Techniques – Use visual storytelling to present data-driven insights effectively.",
      "Gain Practical Experience with Portfolio Tools – Explore GitHub, Tableau Public, and personal websites as platforms to showcase projects.",
      "Apply a Structured Approach to Data Projects – Follow best practices for defining business problems, analyzing data, and drawing conclusions.",
      "Create a Professional Portfolio Website – Learn how to organize and present projects using platforms like GitHub Pages, Notion, or WordPress.",
      "Optimize Portfolio for Visibility – Understand how to present work professionally and make it accessible to industry professionals.",
      "Enhance Professional Profiles with a Portfolio – Learn strategies to integrate portfolio projects into LinkedIn and resumes to strengthen professional presence.",
      "Explore Methods to Share and Promote Work – Use social media, blogs, and networking to showcase projects and engage with industry professionals.",
      "Develop Confidence in Presenting Work – Learn techniques to effectively communicate portfolio projects in professional settings."
    ],
    "content": [
      {
        "title": "Foundations of a Data Analyst Portfolio",
        "subsections": [
          "Understanding the Importance of a Data Analyst PortfolioPreview07:14",
          "Identifying and Selecting Portfolio Projects06:43"
        ]
      },
      {
        "title": "Building and Presenting Your Portfolio Projects",
        "subsections": [
          "Creating and Showcasing Your ProjectsPreview07:03",
          "Setting Up Your Portfolio Platform07:24"
        ]
      },
      {
        "title": "Marketing and Leveraging Your Portfolio for Career Success",
        "subsections": [
          "Showcasing Your Portfolio for Maximum Visibility08:49",
          "Presenting Your Portfolio and Landing Opportunities07:18",
          "Reviewing Key Takeaways and Next Steps08:05"
        ]
      },
      {
        "title": "Final Capstone Project",
        "subsections": [
          "Data Analyst Portfolio Project00:00"
        ]
      },
      {
        "title": "Exclusive Resources to Enhance Your Learning",
        "subsections": [
          "Bonus pdf files00:01"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6524143_8fe3_2.jpg"
  },
  {
    "title": "Visualization for Data Science using Python",
    "price": "Current priceE£399.99",
    "description": "VISUALIZATION FOR DATA SCIENCE USING PYTHON IS SET UP TO MAKE LEARNING FUN AND EASYThis 60+ lesson course includes 15 hours of high-quality video and text explanations of everything under Statistics and Visualization. Topic is organized into the following sections:Data Type - Random variable, discrete, continuous, categorical, numerical, nominal, ordinal, qualitative and quantitative data types.Visualizing data, including bar graphs, pie charts, histograms, and box plotsAnalyzing data, including mean, median, and mode, IQR and box-and-whisker plotsData distributions, including standard deviation, variance, coefficient of variation, Covariance and Normal distributions and z-scoresChi Square distribution and Goodness of FitScatter plots - One, Two and Three dimensionalPair plotsBox plotsViolin plotsEnd to end Exploratory Data Analysis of Iris datasetEnd to end Exploratory Data Analysis of Haberman datasetPrinciple Component Analysis and MNIST dataset.AND HERE'S WHAT YOU GET INSIDE OF EVERY SECTION:We will start with basics and understand the intuition behind each topicVideo lecture explaining the concept with many real life examples so that the concept is drilled inWalkthrough of worked out examples to see different ways of asking question and solving themLogically connected concepts which slowly builds up Enroll today ! Can't wait to see you guys on the other side and go through this carefully crafted course which will be fun and easy.YOU'LL ALSO GET:Lifetime access to the courseFriendly support in the Q&A sectionUdemy Certificate of Completion available for download30-day money back guarantee",
    "instructor": "Newton Academy",
    "requirements": [
      "Basic understanding of python commands",
      "Foundational Mathematics"
    ],
    "whatYouWillLearn": [
      "Visualizing data, including bar graphs, pie charts, histograms.",
      "Data distributions, including mean, variance, and standard deviation, and normal distributions and z-scores",
      "Analyzing data, including mean, median, and mode, plus range and IQR and box plots",
      "Univariate and Multivariate data visualization",
      "Code based implementation of different plots like scatter plot, pair plots, box plots, violin plots",
      "Matplotlib and seaborn visualization packages"
    ],
    "content": [
      {
        "title": "Basics of Statistics",
        "subsections": [
          "Quick IntroductionPreview25:18",
          "What is a random variablePreview13:13",
          "Nominal and Ordinal DataPreview23:51",
          "Central tendency - IntroductionPreview24:26",
          "Central tendency - ExamplesPreview12:28",
          "Data VisualizationPreview20:50",
          "Types of Quartile, Inter Quartile RangePreview10:16",
          "Types of Quartile, Inter Quartile Range - ExamplePreview16:05",
          "Standard Deviation & VariancePreview17:35",
          "Sample Standard DeviationPreview22:36",
          "Co VariancePreview09:33",
          "Normal DistributionPreview23:40",
          "Chi Square DistributionPreview23:05",
          "Chi Square Goodness of FitPreview21:10",
          "Association between Categorical variablesPreview11:39",
          "CorrelationPreview26:02"
        ]
      },
      {
        "title": "Visualization of Iris Dataset using Seaborn and Matplotlib",
        "subsections": [
          "Introduction to EDAPreview13:49",
          "Iris DatasetPreview08:33",
          "Scatter Plot11:12",
          "Two dimensional Scatter plot21:39",
          "Three dimensional scatter plot04:11",
          "Pair plots10:55",
          "One dimensional scatter plot03:41",
          "Histogram, PDF, CDF15:17",
          "Kde plots06:07",
          "Kde plot - Intuition06:32",
          "PDF and its properties09:28",
          "CDF - Code snippet01:29",
          "Mean, Median, Standard deviation, MAD - Code snippet09:16",
          "Box plots05:10",
          "Violin plot02:41"
        ]
      },
      {
        "title": "Visualization of Haberman dataset",
        "subsections": [
          "Haeberman Data - Introduction06:47",
          "Data Overview08:44",
          "Univariate Analysis15:28",
          "Bivariate Analysis08:44"
        ]
      },
      {
        "title": "Linear Algebra",
        "subsections": [
          "Introduction to Linear Equations13:36",
          "Application of Linear Algebra07:41",
          "What is a scaler09:38",
          "What is a point and distance between 2 points15:40",
          "What is a vector09:15",
          "Row and Column Vector21:28",
          "Transpose of a Matrix02:35",
          "Unit Vector09:48",
          "Vector Addition and Subtraction10:56",
          "Inverse of a vector02:54",
          "Dot Product between two vectors11:00",
          "Multiplication of a vector with a scaler02:29",
          "Angle between 2 vectors - Part 102:26",
          "Angle between 2 vectors - Part 204:27",
          "Orthogonal Vectors01:42",
          "Orthonormal vectors02:50",
          "Equation of a line - Part 111:04",
          "Equation of a line - Part 205:33",
          "Equation of a line - Part 306:28",
          "Equation of a line - Part 415:57",
          "Projection of a point on a line05:42",
          "Distance of a point from a line24:04",
          "How to determine point on the negative and positive side of a line13:28",
          "Matrix Introduction05:30",
          "Matrix Operations15:07",
          "Symmetric, Square, Identity and Diagonal Matrix09:09",
          "Orthogonal Matrix09:14",
          "Minor, Cofactor and Determinant of a Matrix (Optional)12:04",
          "Inverse of a matrix (Optional)15:22"
        ]
      },
      {
        "title": "Principal Component Analysis",
        "subsections": [
          "Preface for Dimensionality Reduction - Part 1Preview13:18",
          "Preface for Dimensionality Reduction - Part 211:43",
          "Preface for Dimensionality Reduction - Part 312:27",
          "Preface for Dimensionality Reduction - Part 417:56",
          "Preface for Dimensionality Reduction - Part 509:48",
          "Gometric Intuition of PCA09:51",
          "Mathematical formulation of PCA - Part 116:58",
          "Mathematical formulation of PCA - Part 207:22",
          "Mathematical formulation of PCA - Part 324:34",
          "Failure cases of PCA04:01",
          "Connecting Colab to Gdrive06:16",
          "Understanding MNIST dataset12:41",
          "Visualizing MNIST single digit05:27",
          "MNIST Visualization - Method 117:14",
          "MNIST Visualization - Method 202:41"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5127094_22eb.jpg"
  },
  {
    "title": "Advanced course- Data Science, Machine Learning, Java",
    "price": "Price not found",
    "description": "Java Server Pages (JSP) is a server-side programming technology that enables the creation of dynamic, platform-independent method for building Web-based applications. JSP have access to the entire family of Java APIs, including the JDBC API to access enterprise databases. This tutorial will teach you how to use Java Server Pages to develop your web applications in simple and easy steps.Why to Learn JSP?JavaServer Pages often serve the same purpose as programs implemented using the Common Gateway Interface (CGI). But JSP offers several advantages in comparison with the CGI.Performance is significantly better because JSP allows embedding Dynamic Elements in HTML Pages itself instead of having separate CGI files.JSP are always compiled before they are processed by the server unlike CGI/Perl which requires the server to load an interpreter and the target script each time the page is requested.JavaServer Pages are built on top of the Java Servlets API, so like Servlets, JSP also has access to all the powerful Enterprise Java APIs, including JDBC, JNDI, EJB, JAXP, etc.JSP pages can be used in combination with servlets that handle the business logic, the model supported by Java servlet template engines.Finally, JSP is an integral part of Java EE, a complete platform for enterprise class applications. This means that JSP can play a part in the simplest applications to the most complex and demanding.AudienceThis tutorial has been prepared for the beginners to help them understand basic functionality of Java Server Pages (JSP) to develop your web applications. After completing this tutorial you will find yourself at a moderate level of expertise in using JSP from where you can take yourself to next levels.",
    "instructor": "Arun M",
    "requirements": [
      "Learn everything you need to know"
    ],
    "whatYouWillLearn": [
      "Learn Machine Learning",
      "Learn Data Science",
      "Learn Java",
      "Learn Artificial Intelligence"
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/4547354_5dea_3.jpg"
  },
  {
    "title": "Python | Python Projects & Quizzes for Python Data Science",
    "price": "Current priceE£399.99",
    "description": "Welcome to my \" Python | Python Projects & Quizzes for Python Data Science \" course.Python | Python Programming Language with hands-on Python projects & quizzes, Python for Data Science & Machine Learning Python is a computer programming language often used to build websites and software, automate tasks, and conduct data analysis. Python is a general-purpose language, meaning it can be used to create a variety of different programs and isn't specialized for any specific problems.Python instructors at OAK Academy specialize in everything from software development to data analysis and are known for their effective, friendly instruction for students of all levels.Whether you work in machine learning or finance or are pursuing a career in web development or data science, Python is one of the most important skills you can learn.Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed upon the premise that there should be only one way (and preferably one obvious way) to do things, a philosophy that has resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing a variety of different tools for programmers suited for many different tasks.Do you want to learn one of the employer’s most requested skills? If you think so, you are at the right place. Python, Python for data siene, machine learning, python data science, Django, python programming, machine learning python, python programming language, coding, data science, data analysis, programming languages.We've designed for you \"Python | Python Projects & Quizzes for Python Data Science” a straightforward course for the Python programming language.In the course, you will have down-to-earth way explanations of hands-on projects. With my course, you will learn Python Programming step-by-step. I made Python 3 programming simple and easy with exercises, challenges, and lots of real-life examples.This Python course is for everyone!My \"Python: Learn Python with Real Python Hands-On Examples\" is for everyone! If you don’t have any previous experience, not a problem! This course is expertly designed to teach everyone from complete beginners, right through to professionals ( as a refresher).Why Python?Python is a general-purpose, high-level, and multi-purpose programming language. The best thing about Python is, that it supports a lot of today’s technology including vast libraries for Twitter, data mining, scientific calculations, designing, back-end server for websites, engineering simulations, artificial learning, augmented reality and what not! Also, it supports all kinds of App development.No prior knowledge is needed!Python doesn't need any prior knowledge to learn it and the Ptyhon code is easy to understand for beginners.What you will learn?In this course, we will start from the very beginning and go all the way to programming with hands-on examples . We will first learn how to set up a lab and install needed software on your machine. Then during the course, you will learn the fundamentals of Python development likeInstalling Anaconda Distribution for WindowsInstalling Anaconda Distribution for MacOsInstalling Anaconda Distribution for LinuxReviewing The Jupyter NotebookReviewing The Jupyter LabPython IntroductionFirst Step to CodingUsing Quotation Marks in Python CodingHow Should the Coding Form and Style Be (Pep8)Introduction to Basic Data Structures in PythonPerforming Assignment to VariablesPerforming Complex Assignment to VariablesType ConversionArithmetic Operations in PythonExamining the Print Function in DepthEscape Sequence OperationsBoolean Logic ExpressionsOrder Of Operations In Boolean OperatorsPractice with PythonExamining Strings SpecificallyAccessing Length Information (Len Method)Search Method In Strings Startswith(), Endswith()Character Change Method In Strings Replace()Spelling Substitution Methods in StringCharacter Clipping Methods in StringIndexing and Slicing Character StringComplex Indexing and Slicing OperationsString Formatting with Arithmetic OperationsString Formatting With % OperatorString Formatting With String.Format MethodString Formatting With f-string MethodCreation of ListReaching List Elements – Indexing and SlicingAdding & Modifying & Deleting Elements of ListAdding and Deleting by MethodsAdding and Deleting by IndexOther List MethodsCreation of TupleReaching Tuple Elements Indexing And SlicingCreation of DictionaryReaching Dictionary ElementsAdding & Changing & Deleting Elements in DictionaryDictionary MethodsCreation of SetAdding & Removing Elements Methods in SetsDifference Operation Methods In SetsIntersection & Union Methods In SetsAsking Questions to Sets with MethodsComparison OperatorsStructure of “if” StatementsStructure of “if-else” StatementsStructure of “if-elif-else” StatementsStructure of Nested “if-elif-else” StatementsCoordinated Programming with “IF” and “INPUT”Ternary ConditionFor Loop in PythonFor Loop in Python(Reinforcing the Topic)Using Conditional Expressions and For Loop TogetherContinue CommandBreak CommandList ComprehensionWhile Loop in PythonWhile Loops in Python Reinforcing the TopicGetting know to the FunctionsHow to Write FunctionReturn Expression in FunctionsWriting Functions with Multiple ArgumentWriting Docstring in FunctionsUsing Functions and Conditional Expressions TogetherArguments and ParametersHigh Level Operations with Argumentsall(), any() Functionsmap() Functionfilter() Functionzip() Functionenumerate() Functionmax(), min() Functionssum() Functionround() FunctionLambda FunctionLocal and Global VariablesFeatures of ClassInstantiation of ClassAttribute of InstantiationWrite Function in the ClassInheritance StructureHands-on Real Python Projects With my up-to-date course, you will have a chance to keep yourself up-to-date and equip yourself with a range of Python programming skills. I am also happy to tell you that I will be constantly available to support your learning and answer questions.Do not forget ! Python for beginners has the second largest number of job postings relative to all other languages. So it will earn you a lot of money and will bring a great change in your resume.What is python?Machine learning python is a general-purpose, object-oriented, high-level programming language. Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python bootcamp is one of the most important skills you can learn. Python's simple syntax is especially suited for desktop, web, and business applications. Python's design philosophy emphasizes readability and usability. Python was developed on the premise that there should be only one way (and preferably, one obvious way) to do things, a philosophy that resulted in a strict level of code standardization. The core programming language is quite small and the standard library is also large. In fact, Python's large library is one of its greatest benefits, providing different tools for programmers suited for a variety of tasks.Python vs. R: What is the Difference?Python and R are two of today's most popular programming tools. When deciding between Python and R in data science , you need to think about your specific needs. On one hand, Python is relatively easy for beginners to learn, is applicable across many disciplines, has a strict syntax that will help you become a better coder, and is fast to process large datasets. On the other hand, R has over 10,000 packages for data manipulation, is capable of easily making publication-quality graphics, boasts superior capability for statistical modeling, and is more widely used in academia, healthcare, and finance.What does it mean that Python is object-oriented?Python is a multi-paradigm language, which means that it supports many data analysis programming approaches. Along with procedural and functional programming styles, Python also supports the object-oriented style of programming. In object-oriented programming, a developer completes a programming project by creating Python objects in code that represent objects in the actual world. These objects can contain both the data and functionality of the real-world object. To generate an object in Python you need a class. You can think of a class as a template. You create the template once, and then use the template to create as many objects as you need. Python classes have attributes to represent data and methods that add functionality. A class representing a car may have attributes like color, speed, and seats and methods like driving, steering, and stopping.What are the limitations of Python?Python is a widely used, general-purpose programming language, but it has some limitations. Because Python in machine learning is an interpreted, dynamically typed language, it is slow compared to a compiled, statically typed language like C. Therefore, Python is useful when speed is not that important. Python's dynamic type system also makes it use more memory than some other programming languages, so it is not suited to memory-intensive applications. The Python virtual engine that runs Python code runs single-threaded, making concurrency another limitation of the programming language. Though Python is popular for some types of game development, its higher memory and CPU usage limits its usage for high-quality 3D game development. That being said, computer hardware is getting better and better, and the speed and memory limitations of Python are getting less and less relevant.How is Python used?Python is a general programming language used widely across many industries and platforms. One common use of Python is scripting, which means automating tasks in the background. Many of the scripts that ship with Linux operating systems are Python scripts. Python is also a popular language for machine learning, data analytics, data visualization, and data science because its simple syntax makes it easy to quickly build real applications. You can use Python to create desktop applications. Many developers use it to write Linux desktop applications, and it is also an excellent choice for web and game development. Python web frameworks like Flask and Django are a popular choice for developing web applications. Recently, Python is also being used as a language for mobile development via the Kivy third-party library.What jobs use Python?Python is a popular language that is used across many industries and in many programming disciplines. DevOps engineers use Python to script website and server deployments. Web developers use Python to build web applications, usually with one of Python's popular web frameworks like Flask or Django. Data scientists and data analysts use Python to build machine learning models, generate data visualizations, and analyze big data. Financial advisors and quants (quantitative analysts) use Python to predict the market and manage money. Data journalists use Python to sort through information and create stories. Machine learning engineers use Python to develop neural networks and artificial intelligent systems.How do I learn Python on my own?Python has a simple syntax that makes it an excellent programming language for a beginner to learn. To learn Python on your own, you first must become familiar with the syntax. But you only need to know a little bit about Python syntax to get started writing real code; you will pick up the rest as you go. Depending on the purpose of using it, you can then find a good Python tutorial, book, or course that will teach you the programming language by building a complete application that fits your goals. If you want to develop games, then learn Python game development. If you're going to build web applications, you can find many courses that can teach you that, too. Udemy’s online courses are a great place to start if you want to learn Python on your own.Why would you want to take this course?Our answer is simple: The quality of teaching.OAK Academy based in London is an online education company. OAK Academy gives education in the field of IT, Software, Design, development in English, Portuguese, Spanish, Turkish, and a lot of different languages on the Udemy platform where it has over 2000 hours of video education lessons. OAK Academy both increases its education series number by publishing new courses, and it makes students aware of all the innovations of already published courses by upgrading.When you enroll, you will feel the OAK Academy`s seasoned developers' expertise. Questions sent by students to our instructors are answered by our instructors within 48 hours at the latest.Video and Audio Production QualityAll our videos are created/produced as high-quality video and audio to provide you the best learning experience.You will be,Seeing clearlyHearing clearlyMoving through the course without distractionsYou'll also get:Lifetime Access to The CourseFast & Friendly Support in the Q&A sectionUdemy Certificate of Completion Ready for DownloadDive in now!We offer full support, answering any questions.See you in the \" Python | Python Projects & Quizzes for Python Data Science \" course.Python | Python Programming Language with hands-on Python projects & quizzes, Python for Data Science & Machine Learning",
    "instructor": "Oak Academy",
    "requirements": [
      "A working computer (Windows, Mac, or Linux)",
      "No prior knowledge of Python for beginners is required",
      "Motivation to learn the the second largest number of job postings relative program language among all others",
      "Desire to learn machine learning python",
      "Curiosity for python programming",
      "Desire to learn python programming, pycharm, python pycharm",
      "Nothing else! It’s just you, your computer and your ambition to get started today"
    ],
    "whatYouWillLearn": [
      "Python is a computer programming language often used to build websites and software, automate tasks, and conduct data analysis.",
      "Python is a general-purpose language, meaning it can be used to create a variety of different programs and isn't specialized for any specific problems.",
      "Whether you work in artificial intelligence or finance or are pursuing a career in web development or data science, Python is one of the most important skills",
      "Its simple syntax and readability makes Python perfect for Flask, Django, data science, and machine learning.",
      "Installing Anaconda Distribution for Windows",
      "Installing Anaconda Distribution for MacOs",
      "Installing Anaconda Distribution for Linux",
      "Reviewing The Jupyter Notebook",
      "Reviewing The Jupyter Lab",
      "Python Introduction",
      "First Step to Coding",
      "Using Quotation Marks in Python Coding",
      "How Should the Coding Form and Style Be (Pep8)",
      "Introduction to Basic Data Structures in Python",
      "Performing Assignment to Variables",
      "Performing Complex Assignment to Variables",
      "Type Conversion",
      "Arithmetic Operations in Python",
      "Examining the Print Function in Depth",
      "Escape Sequence Operations",
      "Boolean Logic Expressions",
      "Order Of Operations In Boolean Operators",
      "Practice with Python",
      "Examining Strings Specifically",
      "Accessing Length Information (Len Method)",
      "Search Method In Strings Startswith(), Endswith()",
      "Character Change Method In Strings Replace()",
      "Spelling Substitution Methods in String",
      "Character Clipping Methods in String",
      "Indexing and Slicing Character String",
      "Complex Indexing and Slicing Operations",
      "String Formatting with Arithmetic Operations",
      "String Formatting With % Operator",
      "String Formatting With String Format Method",
      "String Formatting With f-string Method",
      "Creation of List",
      "Reaching List Elements – Indexing and Slicing",
      "Adding & Modifying & Deleting Elements of List",
      "Adding and Deleting by Methods",
      "Adding and Deleting by Index",
      "Other List Methods",
      "Creation of Tuple",
      "Reaching Tuple Elements Indexing And Slicing",
      "Creation of Dictionary",
      "Reaching Dictionary Elements",
      "Adding & Changing & Deleting Elements in Dictionary",
      "Dictionary Methods",
      "Creation of Set",
      "Adding & Removing Elements Methods in Sets",
      "Difference Operation Methods In Sets",
      "Asking Questions to Sets with Methods",
      "Comparison OperatorsIntersection & Union Methods In Sets",
      "Structure of “if” Statements",
      "Structure of “if-else” Statements",
      "Structure of “if-elif-else” Statements",
      "Structure of Nested “if-elif-else” Statements",
      "Coordinated Programming with “IF” and “INPUT”",
      "Ternary Condition",
      "For Loop in Python",
      "For Loop in Python(Reinforcing the Topic)",
      "Using Conditional Expressions and For Loop Together",
      "Continue Command",
      "Break Command",
      "List Comprehension",
      "While Loop in Python",
      "While Loops in Python Reinforcing the Topic",
      "Getting know to the Functions",
      "How to Write Function",
      "Return Expression in Functions",
      "Writing Functions with Multiple Argument",
      "Writing Docstring in Functions",
      "Using Functions and Conditional Expressions Together",
      "Arguments and Parameters",
      "High Level Operations with Arguments",
      "all(), any() Functions",
      "map() Function",
      "filter() Function",
      "zip() Function",
      "enumerate() Function",
      "sum() Function",
      "max(), min() Functions",
      "round() Function",
      "Lambda Function",
      "Local and Global Variables",
      "Features of Class",
      "Instantiation of Class",
      "Attribute of Instantiation",
      "Write Function in the Class",
      "Inheritance Structure",
      "If you are new to Python, data science or have no idea about what data scientist does no problem, you will learn anything you need to start to Python data scien",
      "If you are a software developer or familiar to other programming language and you want to start a new world, you are also in the right place.",
      "You will encounter many businesses that use Python and its libraries for data science.",
      "In this course you need no previous Knowledge about Python, data science.",
      "What does it mean that Python is object-oriented? Python is a multi-paradigm language, which means that it supports many programming approaches.",
      "That’s why Udemy features a host of top-rated OOP courses tailored for specific languages, like Java, C#, and Python.",
      "Most programmers will choose to learn the object oriented programming paradigm in a specific language."
    ],
    "content": [
      {
        "title": "Installations",
        "subsections": [
          "Installing Anaconda Distribution for WindowsPreview10:35",
          "Installing Anaconda Distribution for MacOs06:17",
          "Installing Anaconda Distribution for Linux14:43",
          "Reviewing The Jupyter NotebookPreview12:54",
          "Reviewing The Jupyter Lab11:36",
          "Installing PyCharm IDE for Windows04:19",
          "Installing PyCharm IDE for Mac05:45"
        ]
      },
      {
        "title": "First Step to Coding",
        "subsections": [
          "Python IntroductionPreview05:31",
          "Project Files00:00",
          "FAQ regarding Python04:05",
          "First Step to Coding07:05",
          "Using Quotation Marks in Python Coding08:20",
          "How Should the Coding Form and Style Be (Pep8)09:50",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Basic Operations with Python",
        "subsections": [
          "Introduction to Basic Data Structures in Python08:16",
          "Performing Assignment to Variables10:10",
          "Performing Complex Assignment to Variables04:56",
          "Type Conversion09:03",
          "Arithmetic Operations in Python09:53",
          "Examining the Print Function in Depth07:29",
          "Escape Sequence Operations08:25",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Boolean Data Type in Python Programming Language",
        "subsections": [
          "Boolean Logic Expressions05:03",
          "Order Of Operations In Boolean Operators01:12",
          "Practice with Python11:56",
          "Quiz3 questions"
        ]
      },
      {
        "title": "String Data Type in Python Programming Language",
        "subsections": [
          "Examining Strings Specifically08:31",
          "Accessing Length Information (Len Method)02:41",
          "Search Method In Strings Startswith(), Endswith()11:24",
          "Character Change Method In Strings Replace()05:06",
          "Spelling Substitution Methods in String05:07",
          "Character Clipping Methods in String06:35",
          "Indexing and Slicing Character String08:02",
          "Complex Indexing and Slicing Operations10:48",
          "String Formatting with Arithmetic Operations06:22",
          "String Formatting With % Operator10:24",
          "String Formatting With String.Format Method08:17",
          "String Formatting With f-string Method05:51",
          "Quiz3 questions"
        ]
      },
      {
        "title": "List Data Structure in Python Programming Language",
        "subsections": [
          "Creation of List11:06",
          "Reaching List Elements – Indexing and Slicing08:07",
          "Adding & Modifying & Deleting Elements of List07:46",
          "Adding and Deleting by Methods05:31",
          "Adding and Deleting by Index04:59",
          "Other List Methods06:07",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Tuple Data Structure in Python Programming Language",
        "subsections": [
          "Creation of Tuple09:52",
          "Reaching Tuple Elements Indexing And Slicing04:24",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Dictionary Data Structure in Python Programming Language",
        "subsections": [
          "Creation of Dictionary06:02",
          "Reaching Dictionary Elements08:00",
          "Adding & Changing & Deleting Elements in Dictionary03:40",
          "Dictionary Methods07:46",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Set Data Structure in Python Programming Language",
        "subsections": [
          "Creation of Set08:08",
          "Adding & Removing Elements Methods in Sets04:44",
          "Difference Operation Methods In Sets05:18",
          "Intersection & Union Methods In Sets02:33",
          "Asking Questions to Sets with Methods06:06",
          "Quiz3 questions"
        ]
      },
      {
        "title": "Conditional Expressions in Python Programming Language",
        "subsections": [
          "Comparison Operators06:17",
          "Structure of “if” Statements08:30",
          "Structure of “if-else” Statements04:36",
          "Structure of “if-elif-else” Statements09:21",
          "Structure of Nested “if-elif-else” Statements10:01",
          "Coordinated Programming with “IF” and “INPUT”07:29",
          "Ternary Condition05:14",
          "Quiz3 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5289386_0335.jpg"
  },
  {
    "title": "Master Classification with Pandas and Python [2025]",
    "price": "Current priceE£799.99",
    "description": "Welcome to the course Master Classification with Pandas and Python!This three-in-one master class video course will teach you to master Classification, Python 3, Pandas 2 + 3, and advanced Data Handling.You will learn to master Classification with a number of advanced Classification techniques such as the XGBoost Classifier. You will learn to handle advanced model structures such as feedforward artificial neural networks for classification tasks.Python 3 is one of the most popular and useful programming languages in the world, and Pandas 2 and future version 3 is the most powerful, efficient, and useful Data Handling library in existence.You will learn to master Python's native building blocks and powerful object-oriented programming. You will design your own advanced constructions of Python’s building blocks and execute detailed Data Handling tasks with Python.You will learn to master the Pandas library and to use its powerful Data Handling techniques for advanced Data Science and Machine Learning Data Handling tasks. The Pandas library is a fast, powerful, flexible, and easy-to-use open-source data analysis and data manipulation tool, which is directly usable with the Python programming language.You will learn to:Master Classification both in theory and practiceMaster Classification models from Logistic Regression, and XGBoost Classifier to the Gaussian Naïve Bayes Classifier modelUse practical classification hands-on theory and learn to execute advanced Classification tasks with easeUse advanced Decision Tree, Random Forest, and Voting Classifier modelsUse Feedforward Multilayer Networks and Advanced Classifier model StructuresUse effective decision surfaces and other tools to judge Classifier performanceUse the Scikit-learn library for Classification supported by Matplotlib, Seaborn, Pandas, and PythonMaster Python 3 programming with Python’s native data structures, data transformers, functions, object orientation, and logicUse and design advanced Python constructions and execute detailed Data Handling tasks with Python incl. File HandlingUse Python’s advanced object-oriented programming and make your own custom objects, functions and how to generalize functionsManipulate data and use advanced multi-dimensional uneven data structuresMaster the Pandas 2 and 3 library for Advanced Data HandlingUse the language and fundamental concepts of the Pandas library and to handle all aspects of creating, changing, modifying, and selecting Data from a Pandas DataFrame objectUse file handling with Pandas and how to combine Pandas DataFrames with Pandas concat, join, and merge functions/methodsPerform advanced data preparation including advanced model-based imputation of missing data and the scaling and standardizing of dataMake advanced data descriptions and statistics with Pandas. Rank, sort, cross-tabulate, pivot, melt, transpose, and group dataMake advanced Data Visualizations with Pandas, Matplotlib, and SeabornCloud computing: Use the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook). Learn to use Cloud computing resources.Option: To use the Anaconda Distribution (for Windows, Mac, Linux)Option: Use Python environment fundamentals with the Conda package management system and command line installing/updating of libraries and packages – golden nuggets to improve your quality of work life.And much more…This course is an excellent way to learn to master Classification, Python, Pandas and Data Handling!Classification and Supervised Learning are one of the most important and common tasks Data Science, Machine Learning, modeling, and AI. Data Handling is the process of making data useful and usable for inter alia classification and data analysis.Most Data Scientists and Machine Learning Engineers spends about 80% of their working efforts and time on Data Handling tasks. Being good at Python, Pandas, and Data Handling are extremely useful and time-saving skills that functions as a force multiplier for productivity.This course is designed for everyone who wants tolearn to master Classificationlearn to Master Python 3 from scratch or the beginner levellearn to Master Python 3 and knows another programming languagereach the Master - intermediate Python programmer level as required by many advanced Udemy courses in Python, Data Science, or Machine Learninglearn to Master the Pandas librarylearn Data Handling skills that work as a force multiplier and that they will have use of in their entire careerlearn advanced Data Handling and improve their capabilities and productivityRequirements:Everyday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommendedAccess to a computer with an internet connectionProgramming experience is not needed and you will be taught everything you needThe course only uses costless softwareWalk-you-through installation and setup videos for Cloud computing and Windows 10/11 is includedThis course is the course we ourselves would want to be able to enroll in if we could time-travel and become new students. In our opinion, this course is the best course to learn to Classification, Python, Pandas, and Data Handling.Enroll now to receive 25+ hours of video tutorials with manually edited English captions, and a certificate of completion after completing the course!",
    "instructor": "Henrik Johansson",
    "requirements": [
      "Everyday experience using a computer with either Windows, MacOS, iOS, Android, ChromeOS, or Linux is recommended",
      "Access to a computer with an internet connection",
      "Programming experience is not needed and you will be taught everything you need",
      "The course only uses costless software",
      "Walk-you-through installation and setup videos for Cloud computing and Windows 10/11 is included"
    ],
    "whatYouWillLearn": [
      "Master Classification both in theory and practice",
      "Master Classification models from Logistic Regression, and XGBoost Classifier to the Gaussian Naïve Bayes Classifier model",
      "Use practical classification hands-on theory and learn to execute advanced Classification tasks with ease",
      "Use advanced Decision Tree, Random Forest, and Voting Classifier models",
      "Use Feedforward Multilayer Networks and Advanced Classifier model Structures",
      "Use effective decision surfaces graphs and other tools to judge Classifier performance",
      "Use the Scikit-learn library for Classification supported by Matplotlib, Seaborn, Pandas, and Python",
      "Master Python 3 programming with Python’s native data structures, data transformers, functions, object orientation, and logic",
      "Use and design advanced Python constructions and execute detailed Data Handling tasks with Python incl. File Handling",
      "Use Python’s advanced object-oriented programming and make your own custom objects, functions and how to generalize functions",
      "Manipulate data and use advanced multi-dimensional uneven data structures",
      "Master the Pandas 2 and 3 library for Advanced Data Handling",
      "Use the language and fundamental concepts of the Pandas library and to handle all aspects of creating, changing, and selecting Data from a Pandas DataFrame",
      "Use file handling with Pandas and how to combine Pandas DataFrames with Pandas concat, join, and merge functions/methods",
      "Perform advanced data preparation including advanced model-based imputation of missing data and the scaling and standardizing of data",
      "Make advanced data descriptions and statistics with Pandas. Rank, sort, cross-tabulate, pivot, melt, transpose, and group data",
      "Make advanced Data Visualizations with Pandas, Matplotlib, and Seaborn",
      "Cloud computing: Use the Anaconda Cloud Notebook (Cloud-based Jupyter Notebook). Learn to use Cloud computing resources",
      "Option: To use the Anaconda Distribution (for Windows, Mac, Linux)"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview16:48",
          "Setup of the Anaconda Cloud Notebook16:42",
          "Download and installation of the Anaconda Distribution (optional)20:39",
          "The Conda Package Management System (optional)42:38"
        ]
      },
      {
        "title": "Master Python for Data Handling",
        "subsections": [
          "Overview of Python for Data Handling28:25",
          "Python Integers26:10",
          "Python Floats50:14",
          "Python Strings25:17",
          "Python String Methods37:37",
          "Python Strings and DateTime Objects01:06:33",
          "Python Data Storage Overview04:07",
          "Python Set28:46",
          "Python Tuple30:04",
          "Python Dictionary46:00",
          "Python List49:51",
          "Data Transformers and Functions Overview04:30",
          "Python While-loop45:03",
          "Python For-loop17:02",
          "Python Logic Operators and conditional code branching31:00",
          "Python Functions I: Some theory03:20",
          "Python Functions II: create your own functions33:53",
          "Python Object Oriented Programming I: Some theory14:10",
          "Python Object Oriented Programming II: create your own custom objects39:20",
          "Python Object Oriented Programming III: Files and Tables27:17",
          "Python Object Oriented Programming IV: Recap and More58:21"
        ]
      },
      {
        "title": "Master Pandas for Data Handling",
        "subsections": [
          "Master Pandas for Data Handling: Overview11:21",
          "Pandas theory and terminology11:13",
          "Creating a Pandas DataFrame from scratch30:47",
          "Pandas File Handling: Overview02:51",
          "Pandas File Handling: The .csv file format18:48",
          "Pandas File Handling: The .xlsx file format23:20",
          "Pandas File Handling: SQL-database files and Pandas DataFrame15:08",
          "Pandas Operations & Techniques: Overview03:11",
          "Pandas Operations & Techniques: Object Inspection19:34",
          "Pandas Operations & Techniques: DataFrame Inspection18:53",
          "Pandas Operations & Techniques: Column Selections21:04",
          "Pandas Operations & Techniques: Row Selections21:11",
          "Pandas Operations & Techniques: Conditional Selections21:27",
          "Pandas Operations & Techniques: Scalers and Standardization23:08",
          "Pandas Operations & Techniques: Concatenate DataFrames29:21",
          "Pandas Operations & Techniques: Joining DataFrames19:30",
          "Pandas Operations & Techniques: Merging DataFrames30:48",
          "Pandas Operations & Techniques: Transpose & Pivot Functions34:31",
          "Pandas Data Preparation I: Overview & workflow05:23",
          "Pandas Data Preparation II: Edit DataFrame labels20:16",
          "Pandas Data Preparation III: Duplicates22:23",
          "Pandas Data Preparation IV: Missing Data & Imputation54:35",
          "Pandas Data Preparation V: Data Binnings [Extra Video]46:32",
          "Pandas Data Preparation VI: Indicator Features [Extra Video]33:01",
          "Pandas Data Description I: Overview02:35",
          "Pandas Data Description II: Sorting and Ranking26:51",
          "Pandas Data Description III: Descriptive Statistics31:40",
          "Pandas Data Description IV: Crosstabulations & Groupings30:06",
          "Pandas Data Visualization I: Overview03:35",
          "Pandas Data Visualization II: Histograms42:34",
          "Pandas Data Visualization III: Boxplots33:00",
          "Pandas Data Visualization IV: ScatterplotsPreview40:00",
          "Pandas Data Visualization V: Pie Charts45:40",
          "Pandas Data Visualization VI: Line plots50:24"
        ]
      },
      {
        "title": "Master Classification and Supervised Learning",
        "subsections": [
          "Classification and Supervised Learning, overview17:31",
          "Logistic Regression Classifier01:00:00",
          "The Naive Bayes Classifier48:13",
          "K-Nearest Neighbor Classifier (KNN) [Extra Video]48:38",
          "The Decision Tree Classifier01:06:40",
          "The Random Forest Classifier50:05",
          "Linear Discriminant Analysis (LDA) [Extra Video]54:30",
          "The Voting Classifier46:39"
        ]
      },
      {
        "title": "Advanced Machine Learning Models and Tasks",
        "subsections": [
          "Section Overview03:04",
          "Artificial Neural Networks, Feedforward Networks, and the Multi-Layer Perceptron19:10",
          "Feedforward Multi-Layer Perceptrons for Classification tasks20:03"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6049539_4ee8.jpg"
  },
  {
    "title": "PyTorch: Deep Learning Through Object Detection",
    "price": "Current priceE£399.99",
    "description": "Empower Your Deep Learning Journey: Become a Self-Sufficient DL Programmer with the Ability to Read and Implement Research PapersNote: These prerequisites will ensure a solid foundation for understanding and implementing the concepts covered in the course.Basic proficiency in PythonBasic PyTorch skillsFamiliarity with NumPy for efficient data manipulationIn this course, you will:Learn PyTorch thoroughly, including dataset objects, data loaders, transfer learning, and different gradient modes.Acquire the ability to represent data effectively for solving complex problems.Gain hands-on experience in coding custom loss functions.Develop proficiency in training large models.Join us to unlock the full potential of PyTorch and gain the practical skills necessary to excel in deep learning.Take the Next Leap in Deep Learning: Enroll Now!Don't miss out on this opportunity to elevate your skills in PyTorch and master the art of deep learning. Join our course today and:Unlock the full potential of PyTorch.Unleash the power of PyTorch and NumPy to solve complex data representation problems with a practical example.Develop essential skills for solving complex problems.Gain hands-on experience with custom loss functions.Train and optimize large-scale models.Elevate your skills, conquer challenges, and revolutionize your data expertise today!",
    "instructor": "Emanuel Riquelme",
    "requirements": [
      "Basic proficiency in Python",
      "Basic PyTorch skills",
      "Familiarity with NumPy for efficient data manipulation"
    ],
    "whatYouWillLearn": [
      "Unlock the full potential of PyTorch.",
      "Use PyTorch and NumPy to solve complex Data Representation problems.",
      "Have a strong theoretical foundation regarding the use of Neural Networks for Object Detection",
      "Train and optimize large-scale Models",
      "Learn how to train deep learning models like a pro. With industry-standard tools"
    ],
    "content": [
      {
        "title": "Introduction to the Course",
        "subsections": [
          "Introduction to the coursePreview02:30"
        ]
      },
      {
        "title": "Introduction to object detection and YOLO",
        "subsections": [
          "Introduction to object detection and YOLOPreview10:14"
        ]
      },
      {
        "title": "Generating Labels for the Dataset.",
        "subsections": [
          "Generating Labels54:46"
        ]
      },
      {
        "title": "Building the Dataset object.",
        "subsections": [
          "Building a PyTorch's Dataset object23:55"
        ]
      },
      {
        "title": "Building a custom Loss Function on PyTorch to train the YOLO model.",
        "subsections": [
          "Building a Custom Loss Function on PyTorch28:45"
        ]
      },
      {
        "title": "Building A PyTorch Model Object and implementing Transfer Learning",
        "subsections": [
          "Building a PyTorch Model07:54"
        ]
      },
      {
        "title": "Training YOLO",
        "subsections": [
          "Training YOLO and overview to useful training tools29:59"
        ]
      },
      {
        "title": "Model prediction and a few suggestions.",
        "subsections": [
          "Draw Model predictions and suggested reading material.37:42"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5142566_2da3_2.jpg"
  },
  {
    "title": "Quantizing LLMs with PyTorch and Hugging Face",
    "price": "Current priceE£799.99",
    "description": "As large language models (LLMs) continue to transform industries, the challenge of deploying these computationally intensive models efficiently has become paramount. This course, Quantizing LLMs with PyTorch and Hugging Face, equips you with the tools and techniques to harness quantization, an essential optimization method, to reduce memory usage and improve inference speed without significant loss of model accuracy.In this hands-on course, you’ll start by mastering the fundamentals of quantization. Through intuitive explanations, you will demystify concepts like linear quantization, different data types and their memory requirements, and how to manually quantize values for practical understanding.Next, delve into advanced quantization techniques, including symmetric and asymmetric quantization, and their applications. Gain practical experience with per-channel and per-group quantization methods, and learn how to compute and mitigate quantization errors. Through real-world examples, you'll see these methods come to life and understand their impact on model performance.The final section focuses on cutting-edge topics such as 2-bit and 4-bit quantization. You’ll learn how bit packing and unpacking work, implement these techniques step-by-step, and apply them to real Hugging Face models. By the end of the course, you’ll be adept at using tools like PyTorch and Bits and Bytes to quantize models to varying precisions, enabling you to optimize both small-scale and enterprise-level LLM deployments.Whether you are a machine learning practitioner, a data scientist exploring optimization techniques, or a systems engineer focused on efficient model deployment, this course provides a comprehensive guide to quantization. With a blend of theory and practical coding exercises, you’ll gain the expertise needed to reduce costs and improve computational efficiency in modern AI applications.",
    "instructor": "Tensor Teach",
    "requirements": [
      "Python programming experience",
      "Experience working with Hugging Face Transformers",
      "Intermediate Math skills"
    ],
    "whatYouWillLearn": [
      "Gain an intuitive understanding of linear quantization",
      "Learn different linear quantization techniques",
      "Learn from a high-level how 2 & 4-bit quantization works",
      "Learn how to quantize LLMs from Hugging Face"
    ],
    "content": [
      {
        "title": "Introduction to Quantization",
        "subsections": [
          "Intro to QuantizationPreview03:09",
          "Please Read: Instructor Note For The Following Lecture (#2)00:10",
          "Data Types, Memory Requirements, and Bit RepresentationsPreview08:30",
          "Linear Quantization: Building Intuition06:46",
          "Linear Quantization Formula06:41",
          "Quantizing an Array of Values11:42",
          "Section Notebook00:02"
        ]
      },
      {
        "title": "Quantization Techniques",
        "subsections": [
          "Quantizing & Dequantizing Tensors08:12",
          "Computing Quantization Error02:25",
          "Symmetric Quantization08:08",
          "Implementing Symmetric Quantization Algorithm07:18",
          "Quantization Per Channel07:12",
          "Quantization Per Group10:24",
          "Inference w/ Quantized Weights07:18",
          "Section Notebook00:01"
        ]
      },
      {
        "title": "Lower Bit Quantization & Quantizing Models from Hugging Face",
        "subsections": [
          "2 & 4-bit Quantization Via Packing & Un-Packing09:18",
          "Bit Packing & Unpacking Implementation14:33",
          "4-bit Quantization Notebook00:02",
          "Quantizing Hugging Face Models to 8-bit Precision03:50",
          "4-bit Quantization Using BitsnBtyes02:39",
          "Quantizing HF Models Notebook00:01"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6287745_9734_3.jpg"
  },
  {
    "title": "No More Lucky Models: The Art & Science of Model Validation",
    "price": "Current priceE£799.99",
    "description": "No More Lucky Models: The Art & Science of Model ValidationStop relying on luck. Start building models that survive first contact with reality.Ever celebrated impressive validation metrics only to watch your model crumble in production? You're not alone. The gap between academic performance and real-world success isn't bridged with better algorithms or more data—it's mastered through rigorous validation.In this revolutionary course series, you'll uncover the validation principles that tech giants like Google, Zillow, and IBM learned through billion-dollar failures. Instead of repeating their costly mistakes, you'll master the four critical pillars of validation that transform hopeful models into reliable solutions:Population Representativeness: Build models that work for your actual users, not just your convenient sampleIndependence Between Sets: Eliminate the hidden data leakage that creates falsely optimistic performanceSize and Statistical Significance: Distinguish between genuine patterns and random fluctuationsStructure Preservation: Maintain critical data relationships that standard validation approaches destroyThrough hands-on exercises, real-world case studies, and practical code implementations, you'll evolve from basic train-test splits to sophisticated validation strategies that address time-series challenges, imbalanced data, and complex production environments.This isn't about getting lucky with a good split. It's about creating validation systems that consistently separate genuine performance from statistical flukes.By the end of this journey, you'll:Instantly recognize validation red flags before they derail your projectsImplement advanced cross-validation techniques customized to your specific data structureDevelop an intuition for when seemingly impressive results are actually too good to be trueBuild robust validation pipelines that continuously monitor models in productionJoin the elite ranks of data professionals who never confuse luck with skillWhether you're detecting fraud, predicting customer behavior, or forecasting time series data, systematic validation is what separates repeatable success from random chance.No More Lucky Models. No more hoping. No more crossing fingers during deployment.Join thousands of data scientists who have transformed their approach from \"it worked on my validation set\" to \"I understand exactly when and why this model will succeed or fail.\"In the real world, lucky models eventually run out of luck. Build something better.",
    "instructor": "Maxwell Sarmento de Carvalho",
    "requirements": [
      "Basic Python programming skills (ability to work with libraries and understand code examples)",
      "Experience building at least one ML model from start to finish",
      "Understanding of basic statistics (mean, variance, distributions)",
      "Basic knowledge of common ML metrics (accuracy, precision, recall, RMSE, etc.)",
      "Familiarity with pandas for data manipulation and scikit-learn for model building",
      "Foundational understanding of machine learning concepts (supervised learning, basic model types)"
    ],
    "whatYouWillLearn": [
      "Master the fundamentals of model validation and understand why traditional approaches often fail in real-world applications.",
      "Apply the four core validation principles: population representativeness, independence between sets, statistical significance, and structure preservation.",
      "Develop expertise in cross-validation techniques from basic to advanced, selecting the right approach for different data types.",
      "Recognize real-world validation failures through case studies (Google Flu Trends, Zillow, IBM Watson and others) and how to detect them before deployment.",
      "Implement proper validation for special data structures including time series, geographic data, hierarchical data, and imbalanced datasets.",
      "Design robust validation pipelines that accurately predict model performance in production environments.",
      "Identify and correct common validation issues like data leakage, temporal mixing, and broken data relationships in your ML workflows.",
      "Apply stratified, group-based, and time-aware validation techniques to ensure fair and realistic performance estimates.",
      "Detect when validation results are too optimistic and implement statistical tests to verify performance differences between models.",
      "Assess whether test sets are truly representative of the target population and make corrections when they aren't.",
      "Create validation strategies that properly preserve important data structures like time order, groupings, and hierarchies.",
      "Build comprehensive validation frameworks that transition smoothly from development to production, including drift detection."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Course structure and teachingPreview07:35",
          "The Feedback System01:16",
          "Why Most Machine Learning Models Fail: Essential Validation TechniquesPreview05:10",
          "Four Pillars of Machine Learning Validation: A Framework for Data ScientistsPreview05:57",
          "Machine Learning Model Validation Fundamentals4 questions",
          "How to get the most of this course03:16",
          "Model Validation: The Foundation of Trustworthy Machine Learning06:35",
          "Model Validation Cheat Sheet03:39",
          "Section 1 Feedback Survey00:46"
        ]
      },
      {
        "title": "Quick Wins & Foundation",
        "subsections": [
          "Setting Up Your Environment06:39",
          "Codes and supporting material01:28",
          "The Google Flu Trends Story08:03",
          "Guided Notebook - Validation Challenge09:42",
          "The Google Flu Trends Podcast EpisodePreview15:42",
          "The Google Flu Trends Case Study01:22",
          "Foundations of Model Validation33:02",
          "Foundation & Quick Wins Cheat Sheet04:53",
          "The Four Pillars of Model Validation00:49",
          "Foundation Concepts2 questions",
          "AI Tutor Resource Material02:25"
        ]
      },
      {
        "title": "Population Representativeness",
        "subsections": [
          "Understanding and Preventing Population Bias in Machine Learning Models14:50",
          "Zillow's $500 Million Mistake: When Models Meet Reality11:36",
          "The Zillow's Housing Model Collapse Podcast15:42",
          "The Real World AI Test - Why Flawed Data Means Flawed Results06:47",
          "Population Representativeness Cheat Sheet08:28",
          "Population Representativeness Supporting Material06:19",
          "Zillow iBuying Model Collapse03:07",
          "Population Representativeness5 questions"
        ]
      },
      {
        "title": "Independence Between Sets",
        "subsections": [
          "The Medical AI Dilemma: Cross-Contamination in Healthcare ML07:56",
          "Data Leakage Detection: Safeguarding Your Model ValidationPreview10:22",
          "Independence Between Sets Cheat Sheet08:46",
          "Watson's Oncology Dream - The Rise and Fall of AI in Cancer Care17:57",
          "IBM Watson for Oncology Case Study03:22",
          "Stanford's Hospital Fingerprints - When AI Learns The Wrong COVID's Lesson06:27",
          "The Stanford COVID-19 Prediction Model Case Study03:54",
          "Training on Illusions - The Hidden Perils of Data Dependence in Machine Learning09:11"
        ]
      },
      {
        "title": "Size and Statistical Significance",
        "subsections": [
          "Statistical Power in ML: Learning from Instagram's Testing Framework08:13",
          "Optimal Test Set Design in Data Science: Beyond Simple Train-Test Splits08:39",
          "Guided Notebook: Sample Size & Statistical Power03:45",
          "Size and Statistical Significance Cheat Sheet09:33",
          "Instagram's Secret Lab: How They Test Every Tap, Scroll, and Like08:44",
          "Instagram Feature Testing Case Study03:37",
          "Decoding AI Confidence - How Much Data Does We Really Need14:07",
          "Size and Statistical Significance Supporting Material18:17",
          "Size and Statistical Significance Referencen Material01:53"
        ]
      },
      {
        "title": "Data Structure Preservation",
        "subsections": [
          "Spotify's Recommendation Challenge: When Machine Learning Models Miss Context12:39",
          "Preserving Critical Data Relationships in Model ValidationPreview09:53",
          "Structure Preservation in Action: Guided Implementation03:03",
          "Data Structure Preservation Cheat Sheet13:29",
          "Inside Spotify's Playlist Recommendation Engine16:34",
          "Unlocking Reliable AI: The Hidden Power of Structure Preservation in Reliable AI08:49",
          "The Spotify's Recommendation Challenge Case Study03:08",
          "Structure Preservation in Machine Learning Validation01:12"
        ]
      },
      {
        "title": "The Illusion of Performance",
        "subsections": [
          "The Dangerous Game of Single Splits12:02",
          "Stacking the Odds with Multiple Splits - Strategies for Robust Model Validation06:55",
          "The Illusion of Performance Interactive Notebook02:36",
          "The Illusion of Performance Cheat Sheet11:06",
          "AI's False Promises - Unmasking the Illusion of Machine Learning PerformancePreview11:35",
          "The Illusion of Performance Supporting Material25:35",
          "The Illusions of Performance in Machine Learning Validation01:31"
        ]
      },
      {
        "title": "Fundamentals of Cross-Validation",
        "subsections": [
          "Basic Cross-Validation Techniques06:55",
          "Basic Cross Validation Guided NotebookPreview03:29",
          "Stratified Cross Validation11:19",
          "Stratified Cross Validation Guided Notebook02:28",
          "Selecting the Optimal Cross-Validation Strategy for Your Data14:53",
          "Fundamentals of Cross Validation Cheat Sheet13:34",
          "Decoding Cross-Validation: Your Secret Weapon Against ML Overfitting14:07",
          "Basic Cross Validation Supporting Material13:02",
          "Fundamentals of Cross Validation Guide01:43"
        ]
      },
      {
        "title": "No More Lucky Models",
        "subsections": [
          "Bias vs. Variance in Cross-Validation02:30",
          "Nested CV - No More Lucky Models02:41",
          "Multi-Metric EvaluationPreview03:22",
          "Advanced Cross Validations Techniques Cheat Sheet17:10",
          "Advanced Cross-Validation: Techniques for Professional Data Scientists12:20",
          "Advanced Cross Validation Supporting Material40:46",
          "Advanced Cross Validation Techniques in Machine Learning02:13"
        ]
      },
      {
        "title": "Course Wrap-Up & Continued Learning",
        "subsections": [
          "The Comprehensive Validation Challenge03:59",
          "Validation in Practice: Healthcare/Medical Diagnosis00:58",
          "Validation in Practice: Fraud Detection01:00",
          "Validation in Practice: E-Commerce00:59",
          "Course Conclusion02:13"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6504223_71d7.jpg"
  },
  {
    "title": "Data Wrangling with Python: Ultimate Practice/Learning Test",
    "price": "Current priceE£399.99",
    "description": "Given that the course is a practice test on Udemy, here’s a revised title, subtitle, description, and course URL idea:Title:Data Wrangling with Python: Ultimate Practice TestSubtitle:Test Your Skills on Data Cleaning, Merging, Error Handling, and MoreDescription:Are you ready to put your data-wrangling skills to the test? This comprehensive practice test is designed to help you assess and reinforce your understanding of key data-wrangling techniques using Python. Whether you’re preparing for a job interview or certification, or just want to ensure you’ve mastered the concepts, this practice test will challenge your knowledge across a wide range of topics.The test covers essential areas such as handling missing values, detecting and managing outliers, merging and joining datasets, and implementing robust error-handling practices. With detailed explanations provided for each question, you’ll not only know the correct answers but also understand the reasoning behind them.It will also be helpful if you want to get knowledge of data wrangling as the best way to do anything is to do it. Here, you'll get practical questions, their detailed descriptions, and answers with detailed explanations which can enhance your knowledge to an unbelievable extentWhat You’ll Learn:Assess your ability to clean and prepare data for analysisEvaluate your proficiency in handling missing values and outliersTest your skills in merging and joining datasets using PythonReview common errors and debugging techniques in data wranglingGet detailed explanations for every question to deepen your understanding",
    "instructor": "Muhammad Awais",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [
      {
        "title": "Practice Tests",
        "subsections": [
          "Introduction to Data Wrangling7 questions",
          "Tools and Technologies for Data Wrangling7 questions",
          "Data Cleaning Techniques10 questions",
          "Merging and Joining Datasets10 questions",
          "Error Handling and Debugging7 questions",
          "Conclusion and Next Steps8 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6116639_8445_2.jpg"
  },
  {
    "title": "Machine Learning Masterclass",
    "price": "Current priceE£799.99",
    "description": "Master Machine Learning: A Complete Guide from Fundamentals to Advanced TechniquesMachine Learning (ML) is rapidly transforming industries, making it one of the most in-demand skills in the modern workforce. Whether you are a beginner looking to enter the field or an experienced professional seeking to deepen your understanding, this course offers a structured, in-depth approach to Machine Learning, covering both theoretical concepts and practical implementation.This course is designed to help you master Machine Learning step by step, providing a clear roadmap from fundamental concepts to advanced applications. We start with the basics, covering the foundations of ML, including data preprocessing, mathematical principles, and the core algorithms used in supervised and unsupervised learning. As the course progresses, we dive into more advanced topics, including deep learning, reinforcement learning, and explainable AI.What You Will LearnThe fundamental principles of Machine Learning, including its history, key concepts, and real-world applicationsEssential mathematical foundations, such as vectors, linear algebra, probability theory, optimization, and gradient descentHow to use Python and key libraries like NumPy, Pandas, Matplotlib, Scikit-learn, TensorFlow, and PyTorch for building ML modelsData preprocessing techniques, including handling missing values, feature scaling, and feature engineeringSupervised learning algorithms, such as Linear Regression, Logistic Regression, Decision Trees, Support Vector Machines, and Naive BayesUnsupervised learning techniques, including Clustering (K-Means, Hierarchical, DBSCAN) and Dimensionality Reduction (PCA, LDA)How to measure model accuracy using various performance metrics, such as precision, recall, F1-score, ROC-AUC, and log lossTechniques for model selection and hyperparameter tuning, including Grid Search, Random Search, and Cross-ValidationRegularization methods such as Ridge, Lasso, and Elastic Net to prevent overfittingIntroduction to Neural Networks and Deep Learning, including architectures like CNNs, RNNs, LSTMs, GANs, and TransformersAdvanced topics such as Bayesian Inference, Markov Decision Processes, Monte Carlo Methods, and Reinforcement LearningThe principles of Explainable AI (XAI), including SHAP and LIME for model interpretabilityAn overview of AutoML and MLOps for deploying and managing machine learning models in productionWhy Take This Course?This course stands out by offering a balanced mix of theory and hands-on coding. Many courses either focus too much on theoretical concepts without practical implementation or dive straight into coding without explaining the underlying principles. Here, we ensure that you understand both the \"why\" and the \"how\" behind each concept.Beginner-Friendly Yet Comprehensive: No prior ML experience required, but the course covers everything from the basics to advanced conceptsHands-On Approach: Practical coding exercises using real-world datasets to reinforce learningClear, Intuitive Explanations: Every concept is explained step by step with logical reasoningTaught by an Experienced Instructor: Guidance from a professional with expertise in Machine Learning, AI, and OptimizationBy the end of this course, you will have the knowledge and skills to confidently build, evaluate, and optimize machine learning models for various applications.If you are looking for a structured, well-organized course that takes you from the fundamentals to advanced topics, this is the right course for you. Enroll today and take the first step toward mastering Machine Learning.",
    "instructor": "Advancedor Academy",
    "requirements": [
      "No prior knowledge of Machine Learning is required. The course covers everything from the basics.",
      "Basic Python programming knowledge is helpful but not mandatory. A Python introduction section is included.",
      "A computer with internet access and the ability to install Python-related libraries.",
      "Enthusiasm to learn and apply Machine Learning concepts in real-world scenarios."
    ],
    "whatYouWillLearn": [
      "Understand the fundamentals of Machine Learning and its real-world applications.",
      "Implement ML models using Python, TensorFlow, PyTorch, and Scikit-learn.",
      "Preprocess data, perform feature engineering, and optimize models effectively.",
      "Build, evaluate, and deploy ML models for classification, regression, and clustering."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview02:56",
          "Course GuidePreview06:23"
        ]
      },
      {
        "title": "Introduction to Machine Learning",
        "subsections": [
          "Introduction to Machine LearningPreview07:42",
          "History and Evolution of Machine Learning25:25",
          "Applications of Machine Learning15:57",
          "Types of Machine Learning: Supervised, Unsupervised, and Reinforcement LearningPreview06:59",
          "Machine Learning PipelinePreview13:02",
          "Overview of Python Libraries for Machine Learning08:24"
        ]
      },
      {
        "title": "Mathematical Foundations for Machine Learning",
        "subsections": [
          "Introduction to Vectors and Vector Operations - Visual Explanation05:20",
          "Introduction to Vectors and Vector OperationsPreview18:00",
          "Eigenvalues and Eigenvectors20:50",
          "Functions and Their Properties15:37",
          "Derivatives and Differentiation Rules16:39",
          "Probability Theory35:09",
          "Probability Distributions30:28",
          "Bayes’ Theorem21:29",
          "Hypothesis Testing21:42",
          "Gradient Descent15:57",
          "RMSprop14:03",
          "AdaGrad13:01",
          "AdaGrad with Python04:48"
        ]
      },
      {
        "title": "Python Programming (Optional)",
        "subsections": [
          "What is Python?Preview09:33",
          "Anaconda & Jupyter & Visual Studio CodePreview06:27",
          "Google Colab10:25",
          "Environment Setup05:45",
          "Python Syntax & Basic Operations28:30",
          "Data Structures: Lists, Tuples, Sets24:01",
          "Control Structures & Looping20:12",
          "Functions & Basic Functional Programming19:23",
          "Intermediate Functions14:31",
          "Dictionaries and Advanced Data Structures19:41",
          "Modules, Packages & Importing Libraries20:30",
          "File Handling12:37",
          "Exception Handling & Robust Code22:12",
          "OOP21:29",
          "Advanced List Operations & Comprehensions13:02"
        ]
      },
      {
        "title": "Data Preprocessing (Optional)",
        "subsections": [
          "Data Quality06:56",
          "Data Cleaning Techniques28:09",
          "Handling Missing Values18:51",
          "Handling Outliers15:06",
          "Feature Scaling and Normalization23:35",
          "Standardization19:35",
          "Encoding Categorical Data27:36",
          "Feature Engineering24:59",
          "Dimensionality Reduction33:07"
        ]
      },
      {
        "title": "Exploratory Data Analysis (EDA)",
        "subsections": [
          "Descriptive Statistics19:59",
          "Data Visualization: Matplotlib and Seaborn27:17",
          "Multivariate Analysis18:08"
        ]
      },
      {
        "title": "Introduction Concepts and Notation",
        "subsections": [
          "ML Introduction Concepts - 111:17",
          "ML Introduction Concepts - 208:21",
          "ML Introduction Concepts - 304:42",
          "ML Introduction Concepts - 410:04",
          "Notation10:05"
        ]
      },
      {
        "title": "Learning",
        "subsections": [
          "What is Learning?17:19",
          "Why Do We Predict f?03:22",
          "Curse of Dimensionality09:42",
          "How Do We Predict f?09:09",
          "Prediction Accuracy or Model Simplicity?07:40",
          "Regression vs Classification05:10"
        ]
      },
      {
        "title": "Measuring Model Accuracy",
        "subsections": [
          "Measuring Prediction Quality05:23",
          "Bias-Variance Trade-Off03:35",
          "Classification Setup06:40",
          "KNN Example02:19"
        ]
      },
      {
        "title": "Simple Linear Regression",
        "subsections": [
          "Mathematical Basis of Regression07:01",
          "Regression - Visual Explanation03:06"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6109791_d839.jpg"
  },
  {
    "title": "Business Analytics with R: A Comprehensive Guide",
    "price": "Current priceE£799.99",
    "description": "Course IntroductionThis course is designed to teach students how to harness the power of R programming for business analytics. Whether you're an aspiring data scientist or a business professional, this course will guide you through every step—from understanding basic data concepts to implementing complex statistical models and machine learning techniques. You'll work with practical examples, data manipulation, visualization, and forecasting, giving you a solid foundation to analyze business data and drive decisions using R.Section-Wise WriteupSection 1: Introduction to Business Analytics and RThe course begins by introducing the concept of business analytics and its evolution in modern business. We start with a discussion on discriminant analysis and move into an introduction to R and its application in business analytics. This section also covers fundamental business examples, such as hotel data, to illustrate how analytics can be applied in real-world scenarios. You will learn about different types of data used in analytics, including ordinal data, and explore decision models used to solve business problems.Section 2: Business Analytics Life CycleThis section dives into the Business Analytics Life Cycle, providing insights into how analytics processes are structured. You'll learn about model deployment, which is critical for turning your models into actionable business strategies. We also explore the steps in the problem-solving process, introduce software commonly used in business analytics, and guide you through setting up R and R Studio for effective use in your analytics projects.Section 3: Understanding R ProgrammingR is the core tool used in this course, and here you'll get a comprehensive introduction to it. The section covers basic R functions, data types, and key concepts such as recycling rules, special numerical values, and logical conjunctions. You will also learn about arrays, matrices, and factors in R, along with how to work with repositories and install packages. The practical aspects of working with data, importing, and aggregating data will be demonstrated.Section 4: Data Manipulation & Statistics BasicsIn this section, you'll focus on data manipulation techniques like merging and data creation, followed by an introduction to basic statistics. You will learn how to compute variance, covariance, and cumulative frequency, while also getting hands-on experience with functions in R like head() and scatterplot(). The section also explores control flow, which helps in making decisions based on data.Section 5: Statistics, Probability & DistributionThis section covers core concepts of statistics and probability necessary for business analytics. You'll learn about random variables, discrete and continuous distributions, and how to calculate expected values. The section also explores binomial distributions and uniform random variables, alongside examples such as gambling and decision-making games like \"Deal or No Deal.\"Section 6: Business Analytics Using RFocusing on advanced business analytics, this section delves into statistical concepts like Normal and t-distributions, along with tools for hypothesis testing. You'll work with real-world examples, such as SAT scores and birth weights, to understand estimation, confidence intervals, and central limit theorem. The section culminates in building confidence intervals and learning about kurtosis, all while gaining practical experience using R.Section 7: Examples, Testing & ForecastingThis section emphasizes hypothesis generation and testing using R. You will work with sample differences, calculate Z values, and perform one-sided P-value tests. Additionally, you will learn about forecasting, time-series analysis, and methods such as ARIMA and double exponential smoothing. These tools are essential for predicting future trends and making informed decisions in business.Section 8: Understanding VisualizationsData visualization is a powerful tool for business analytics, and in this section, you will master how to create effective visual representations of data in R. You'll learn why and how to visualize data, overlay plots, and use advanced graphs such as bubble charts. The section also covers the concept of ANOVA (Analysis of Variance) and regression modeling, providing you with the skills to build and interpret statistical models.ConclusionBy the end of this course, you will have a strong understanding of business analytics concepts and the practical skills to implement them using R. From basic data manipulation and statistical analysis to advanced forecasting and visualizations, this course will prepare you to tackle complex business problems with confidence. You'll be equipped to use R for data-driven decision-making and analysis, giving you the tools to succeed in any business analytics role.",
    "instructor": "EDUCBA Bridging the Gap",
    "requirements": [
      "Basic knowledge of statistics and business concepts is helpful. No prior programming experience is required, though familiarity with basic programming concepts will be beneficial. A willingness to learn R and apply it to real-world business analytics problems."
    ],
    "whatYouWillLearn": [
      "How to use R for business analytics, including data manipulation and statistical analysis.",
      "The business analytics life cycle and how to deploy analytics models.",
      "The fundamentals of statistics, probability, and distributions, including hypothesis testing.",
      "Advanced forecasting techniques like ARIMA and time-series analysis.",
      "How to create compelling data visualizations to communicate insights."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Course IntroductionPreview11:39",
          "Course CurriculumPreview10:04",
          "Discriminant Analysis06:05",
          "Introduction to R & AnalyticsPreview07:34",
          "Evolution of Business Analytics11:56",
          "Business Example- Hotel11:06",
          "Data for Business Analytics06:45",
          "Ordinal Data08:11",
          "Decision Model Example06:02",
          "Descriptive Decision Models08:32"
        ]
      },
      {
        "title": "Business Analytics Life Cycle",
        "subsections": [
          "Business Analytics Life Cycle08:04",
          "Model deployment06:04",
          "Steps in Problem Solving Process06:49",
          "Software used in Business Analytics07:22",
          "Getting Started with R06:02",
          "Installing R Studio09:08"
        ]
      },
      {
        "title": "Understanding R",
        "subsections": [
          "Basics of R11:47",
          "Basic R Functions11:47",
          "Data Types11:34",
          "Recycling Rule08:48",
          "Special Numerical Values09:48",
          "Parallel Summary Functions05:07",
          "Logical Conjunctions11:35",
          "Pasting Strings together07:34",
          "Type Coercion11:33",
          "Array & Matrix05:41",
          "Factor07:16",
          "Repository & Packages02:42",
          "Installing a Package09:57",
          "Importing Data05:46",
          "Importing Data SPSS06:53",
          "Working with Data11:54",
          "Data Aggregation04:07"
        ]
      },
      {
        "title": "Data Manipulation & Statistics Basics",
        "subsections": [
          "Data Manipulation & Statistics Basics08:50",
          "Merging09:22",
          "Data Creation06:13",
          "Merge Example08:23",
          "What is Statistics09:19",
          "Variables11:02",
          "Quantiles05:02",
          "Calculating Variance07:50",
          "Calculating Covariance07:45",
          "Cumulative Frequency11:31",
          "Library (mass)09:55",
          "Head (faithful)04:46",
          "Scatter Plot07:10",
          "Control Flow07:34"
        ]
      },
      {
        "title": "Statistics, Probability & Distribution",
        "subsections": [
          "Statistics, Probability & Distribution04:44",
          "Random Variable13:14",
          "Random Example07:57",
          "Discrete Example07:48",
          "Practice problem06:54",
          "Continuous Case06:33",
          "Exponential Distribution Practice Problem07:22",
          "Expected Value06:53",
          "Gambling Example05:57",
          "Deal or no deal10:50",
          "Distribution details07:30",
          "Binomial Distribution continued06:40",
          "Expected Value from Binomial08:59",
          "Uniform Random Variables11:59",
          "Probability distributions examples06:38",
          "Probability distributions examples continued09:19"
        ]
      },
      {
        "title": "Business Analytics using R",
        "subsections": [
          "Business Analytics using R07:23",
          "Normal PDF07:11",
          "What is Normal, Not Normal09:37",
          "SAT Example11:56",
          "Example- Birth Weights06:09",
          "dNorm, pNorm, qNorm12:25",
          "Understanding Estimation06:32",
          "Properties of Good Estimators08:54",
          "Central Limit Theorem11:43",
          "Kurtosis11:55",
          "Constructing Central Limit Theorem09:42",
          "Confidence Intervals for the Mean10:12",
          "Confidence Intervals Examples05:12",
          "Computer Lab Example08:15",
          "t-distribution08:03",
          "t-distribution continued07:41"
        ]
      },
      {
        "title": "Examples, Testing & Forecasting",
        "subsections": [
          "R Examples08:33",
          "Standard error of the mean06:40",
          "Downloading the Package08:33",
          "Sample Differences09:41",
          "Hypothesis Generation & Testing09:54",
          "Hypothesis Testing09:49",
          "One sided P Value10:25",
          "Power & Sample Size07:11",
          "Testing Hypothesis using R07:39",
          "Calculating the Z value05:57",
          "Lower Tail proportion of population proportion07:41",
          "Forecasting10:20",
          "Time Series Analysis Applications08:01",
          "Approaches to Forecasting08:34",
          "Observation Components08:19",
          "Traditional Approaches09:22",
          "Double Exponential Smoothing10:58",
          "ARIMA Steps05:13",
          "Forecasting Performance07:18",
          "Univariate ARIMA07:18"
        ]
      },
      {
        "title": "Understanding Visualizations",
        "subsections": [
          "R Visualization11:42",
          "Why Visualize09:25",
          "Overlaying Plots09:01",
          "Graphs representation of Data05:50",
          "Graphs representation of Data continued10:17",
          "Advanced Graphs08:24",
          "Bubble Charts08:07",
          "Anova10:37",
          "Concept of effect10:42",
          "Estimate of Treatment effect07:00",
          "Factorial Anova08:02",
          "Regression11:36",
          "Regression Model11:34",
          "Linear Relationship06:51",
          "Output of Regression Model06:55"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6333851_421a.jpg"
  },
  {
    "title": "Salesforce Certified AI Specialist - Mock Exams",
    "price": "Current priceE£799.99",
    "description": "Salesforce Certified AI SpecialistThis course is meticulously designed to help aspiring AI professionals and Salesforce experts gain the necessary skills and confidence to succeed in the Salesforce Certified AI Specialist exam. This course includes six comprehensive mock exams, each structured to mirror the real exam's format, question types, and level of difficulty. Covering a wide range of topics, these practice exams delve into critical areas such as data processing, AI model integration within Salesforce, ethical considerations, and practical applications of Salesforce’s AI-powered solutions like Einstein.Each question is crafted to test your understanding of Salesforce's AI functionality, including its architecture, capabilities, and the ways AI-driven insights can enhance customer engagement and drive business decisions. Additionally, every answer in the mock exams is paired with an in-depth explanation, guiding learners through the reasoning behind correct responses. This approach helps reinforce key concepts and ensures a solid grasp of Salesforce AI’s technical aspects.By working through these mock exams, you'll gain practical knowledge and critical insights that are essential for real-world applications. The course provides a comprehensive learning experience, ideal for professionals aiming to master Salesforce’s AI offerings and showcase their expertise as a Certified AI Specialist.Can I retake the practice tests?Yes, you can attempt each practice test as many times as you like. After completing a test, you'll see your final score. Each time you retake the test, the questions and answer choices will be shuffled for a fresh experience.Is there a time limit for the practice tests?Yes, each test includes a time limit of 120 seconds per question.What score do I need to pass?You need to score at least 72% on each practice test to pass.Are explanations provided for the questions?Yes, every question comes with a detailed explanation.Can I review my answers after the test?Absolutely. You’ll be able to review all your submitted answers and see which ones were correct or incorrect.Are the questions updated frequently?Yes, the questions are regularly updated to provide the best and most relevant learning experience.Additional Note: It’s highly recommended that you take the practice exams multiple times until you're consistently scoring 90% or higher. Don’t hesitate—start your preparation today. Good luck!",
    "instructor": "Paweł Krakowiak",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [
      {
        "title": "Practice Tests",
        "subsections": [
          "Exam #140 questions",
          "Exam #240 questions",
          "Exam #340 questions",
          "Exam #440 questions",
          "Exam #540 questions",
          "Exam #640 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6267199_edce_3.jpg"
  },
  {
    "title": "500+ NumPY Interview Questions Practice Test",
    "price": "Current priceE£399.99",
    "description": "NumPY Interview Questions and Answers Preparation Practice Test | Freshers to Experienced Master NumPy: Ultimate Interview Questions and Practice Tests Are you preparing for a data science or machine learning interview and feeling daunted by the vastness of NumPy? Look no further! Our NumPy Interview Questions Practice Test course on Udemy is meticulously designed to cover all essential aspects of NumPy through carefully crafted practice questions that will help you excel in your interviews. This course is structured into six comprehensive sections, each diving into critical subtopics to ensure you have a solid grasp of NumPy.NumPy, the fundamental package for numerical computing in Python, is a cornerstone for any data scientist or machine learning engineer. Mastery of NumPy is crucial for efficient data manipulation, performing complex mathematical operations, and optimizing performance. Our course offers a thorough practice test experience, preparing you to answer interview questions confidently and accurately. By the end of this course, you will have not only honed your NumPy skills but also gained insights into how to tackle practical problems you might face in real-world scenarios.Section 1: Basic Concepts and OperationsIntroduction to NumPy: Understand the core principles of NumPy, including its advantages over traditional Python lists and arrays.Array Creation: Learn different methods to create NumPy arrays using various functions like np.array(), np.zeros(), np.ones(), and more.Array Indexing and Slicing: Master techniques to access and modify array elements, slices, and use boolean indexing.Array Manipulation: Explore reshaping, flattening, and transposing arrays, and learn how to manipulate array shapes effectively.Basic Array Operations: Perform element-wise operations, array aggregations, and arithmetic operations with NumPy arrays.Broadcasting: Understand the concept of broadcasting and how it facilitates arithmetic operations on arrays of different shapes.Section 2: Advanced OperationsArray Broadcasting: Delve deeper into broadcasting rules and advanced applications of broadcasting.Universal Functions (ufuncs): Learn about ufuncs, which are functions that operate element-wise on arrays, and how to use them for efficient computations.Array Shape Manipulation: Gain proficiency in reshaping arrays, using reshape(), resize(), and understanding array views versus copies.Linear Algebra with NumPy: Explore NumPy’s linear algebra capabilities, including matrix multiplication, determinants, eigenvalues, and more.Statistical Operations: Perform statistical computations like mean, median, standard deviation, and correlations on NumPy arrays.Random Number Generation: Generate random numbers and create random samples using NumPy's random module.Section 3: Performance and OptimizationVectorization: Learn how to use NumPy’s vectorized operations to replace Python loops for better performance.Memory Layout: Understand how NumPy stores data in memory, including concepts of C-contiguous and F-contiguous arrays.Array Broadcasting vs. Loops: Compare the efficiency of using broadcasting over traditional loops and understand performance implications.Optimizing NumPy Code: Discover strategies to optimize your NumPy code for better performance.NumPy Performance Tips: Get practical tips to enhance the performance of your NumPy-based computations.NumPy Benchmarks: Learn to benchmark your NumPy code and compare it with other libraries or techniques.Section 4: Working with NumPy ArraysMultidimensional Arrays: Work with 2D and higher-dimensional arrays, and understand how to manipulate them.Structured Arrays: Use structured arrays to handle complex data types and work with heterogeneous data.Masked Arrays: Handle missing data and perform computations on arrays with masked values.Iterating Over Arrays: Learn efficient ways to iterate over arrays using NumPy’s built-in functions.Fancy Indexing: Utilize advanced indexing techniques to access and modify array elements.Combining and Splitting Arrays: Master techniques to concatenate, stack, split, and tile arrays for flexible data manipulation.Section 5: Integration and InteroperabilityIntegration with other Libraries: Learn how to integrate NumPy with other popular Python libraries such as Pandas and SciPy.Integration with C/C++ and Fortran: Explore how to use NumPy with C/C++ and Fortran for high-performance computing.NumPy and GPU Computing: Understand how to leverage GPU computing with NumPy using libraries like CuPy.File I/O Operations: Learn to read and write data to/from files using NumPy’s file I/O functions.Working with NumPy in Python Scripts: Incorporate NumPy in your Python scripts for efficient data processing.NumPy and Cython Integration: Enhance the performance of NumPy operations by integrating with Cython.Section 6: NumPy Best Practices and TipsMemory Management: Optimize memory usage when working with large NumPy arrays.Error Handling: Learn best practices for handling errors and exceptions in NumPy.Code Readability: Write clean and readable NumPy code that is easy to maintain.Testing NumPy Code: Implement effective testing strategies for your NumPy code.Documentation Best Practices: Document your NumPy code effectively for better collaboration and maintainability.NumPy Community and Resources: Stay updated with the latest developments in NumPy and leverage community resources.By enrolling in our NumPy Interview Questions Practice Test course, you will gain the confidence to tackle any NumPy-related interview questions with ease. Each section is designed to provide thorough coverage of key concepts, ensuring you are well-prepared. Whether you are a beginner looking to solidify your understanding or an experienced professional seeking to refresh your knowledge, this course is tailored to meet your needs. Start mastering NumPy today and take a significant step towards acing your data science or machine learning interview.Enroll Now and Start Practicing!",
    "instructor": "Interview Questions Tests",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [
      {
        "title": "Practice Tests",
        "subsections": [
          "Basic Concepts and Operations  Interview Questions Practice Test99 questions",
          "Advanced Operations  Interview Questions Practice Test105 questions",
          "Performance and Optimization Interview Questions Practice Test99 questions",
          "Working with NumPy Arrays Interview Questions Practice Test99 questions",
          "Integration and Interoperability  Interview Questions Practice Test90 questions",
          "NumPy Best Practices and Tips Interview Questions Practice Test102 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5995298_263c.jpg"
  },
  {
    "title": "Learn Self Driving Car , ML , Python, CV ,DL, in 1 course",
    "price": "Current priceE£399.99",
    "description": "In this course, we will start from the basics and will learn all concepts of machine learning, self-driving car, python, and computer vision. We will build multiple projects including self-driving car in this course. We will learn all these things by practically building projects .I hope you will enjoy course and will learn lot of things.our main topics will beComputer VisionSelf-driving CarsMachine LearninigPythonDeep LearningNeural NetworksOpenCVWho this course is for:Anyone interested in Self Driving Cars,Machine learning.Students who have at least high school knowledge in math and who want to start learning Machine Learning.Any intermediate level people who know the basics of machine learning, including the classical algorithms like linear regression or logistic regression, but who want to learn more about it and explore all the different fields of Machine Learning.Any people who are not that comfortable with coding but who are interested in Machine Learning and want to apply it easily on datasets.Any students in college who want to start a career in Data Science.Any data analysts who want to level up in Machine Learning.Any people who are not satisfied with their job and who want to become a Data Scientist.Any people who want to create added value to their business by using powerful Machine Learning tools.",
    "instructor": "Abhinav Bansal",
    "requirements": [
      "No programming experience required .We will teach python from start"
    ],
    "whatYouWillLearn": [
      "Will learn how to train self driving vehicles",
      "Will build different computer vision models",
      "Will learn different types of machine learning models",
      "Will learn deep learning also"
    ],
    "content": [
      {
        "title": "Machine Learning",
        "subsections": [
          "IntroductionPreview01:06",
          "AI VS ML VS DLPreview02:44",
          "Types of Machine LearningPreview04:12",
          "Workflow and ToolsPreview05:35",
          "How to download and use anaconda03:08",
          "Retrieve Data04:13"
        ]
      },
      {
        "title": "Python",
        "subsections": [
          "Variable and Data type05:26",
          "Operators06:45",
          "Keywords and Identifiers04:06",
          "Strings(Part-1)07:23",
          "Strings(Part - 2)04:36",
          "Decision Making Statements11:48",
          "Functions04:30",
          "Data Structures - Tuple07:00",
          "Lists08:03",
          "Dictionary06:31",
          "Sets05:34",
          "Introduction to Libraries02:16",
          "Numpy(Part -1)07:17",
          "Numpy(Part - 2)10:32",
          "Numpy(Part - 3)08:40",
          "Pandas(Part - 1)07:35",
          "Pandas(Part - 2)07:42",
          "Matplotlib14:34"
        ]
      },
      {
        "title": "Computer Vision",
        "subsections": [
          "IntroductionPreview02:23",
          "InstallationsPreview02:18",
          "Read Images,Vedio,VedioCam06:30",
          "Basic Functions05:57",
          "Crop and resize04:22",
          "Shapes and text06:20",
          "Warp perspective04:34",
          "Joining Images02:16",
          "Color detection11:26",
          "Contour/Shape detection09:41",
          "Face Detection05:35",
          "NumberPlate Detector04:20"
        ]
      },
      {
        "title": "Small Self Driving Car Project",
        "subsections": [
          "IntroPreview01:22",
          "Lane detection06:44",
          "Warping Lane08:20",
          "Finding Lane Curve04:10",
          "Hardware Implementation02:08"
        ]
      },
      {
        "title": "Data Preprocessing",
        "subsections": [
          "What is feature engineering03:18",
          "Outlier Detection using standard deviation06:47",
          "Outlier Detection using percentile method06:19",
          "Handle Missing Data07:53"
        ]
      },
      {
        "title": "Supervised Learning : Regression Models",
        "subsections": [
          "Linear regression single variable05:03",
          "Linear regression multiple variable03:50",
          "Predict function03:23",
          "Train Test Split Method03:48",
          "Logistic regression binary class classification07:03",
          "Logistic regression multiple class classification04:42",
          "Save and Load model04:10"
        ]
      },
      {
        "title": "Other models",
        "subsections": [
          "Decision Tree07:27",
          "Support Vector Machine05:43",
          "Random Forest06:45",
          "K-FOLD cross validation12:34",
          "Naves bayes 105:40",
          "Naves bayes 206:16",
          "Ensemble learning08:29",
          "L1  and L205:46"
        ]
      },
      {
        "title": "Unsupervised Learning",
        "subsections": [
          "K-Means Clustering08:57"
        ]
      },
      {
        "title": "Deep Learning",
        "subsections": [
          "Intro to Deep Learning01:30",
          "How to install Tensorflow01:58",
          "Matrix05:41",
          "Customer churn prediction13:12",
          "Precision,Recall and F1 score03:27"
        ]
      },
      {
        "title": "Project 1 - Real estate price prediction",
        "subsections": [
          "Data Cleaning20:03",
          "Apply the model09:17"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/4882000_89f5_2.jpg"
  },
  {
    "title": "Master Machine Learning with Practical Case Studies",
    "price": "Price not found",
    "description": "Dive into the world of machine learning with \"Master Machine Learning with Practical Case Studies.\" This comprehensive course is designed for those who want to move beyond theory and gain hands-on experience in applying machine learning algorithms to real-world problems. Throughout the course, you'll explore a variety of machine learning techniques and methodologies, learning how to effectively implement and fine-tune algorithms for diverse datasets. You'll work with case studies spanning multiple domains, including finance, healthcare, and e-commerce, providing a broad perspective on how machine learning can be leveraged across industries.Key features of the course include:Practical Case Studies: Analyze and solve real-world problems using detailed case studies, gaining insights into best practices and industry applications.Hands-On Projects: Engage in practical exercises that involve building, training, and evaluating machine learning models.Algorithm Deep Dive: Understand the theory and application of popular machine learning algorithms like Linear Regression, Logistic Regression, Decision Tree, Random Forest, Naive Bayes, K-means and Boosting AlogrithmsDiverse Datasets: Work with a variety of datasets to learn how to handle different types of data and preprocessing techniques.By the end of the course, you’ll have confidence to apply your skills to complex problems. Perfect for aspiring data scientists, analysts, and machine learning practitioners, this course will equip you with the tools and knowledge needed to excel in the evolving field of machine learning.",
    "instructor": "Spaark Hub",
    "requirements": [
      "No prior Programming Experience required."
    ],
    "whatYouWillLearn": [
      "How  to use Machine Learning Model for making Predictions for Real Life Problems",
      "Understand Machine Learning to Apply in Real Practical Scenarios",
      "Master Machine Learning techniques",
      "Develop Insights for Data Wrangling, Data Cleansing, Data Enrichment, Data Analytics using Machine Learning",
      "Build Linear Regression Model",
      "Build Logistic Regression Model",
      "Build Decision Tree Model",
      "Understand ARIMA",
      "Implement KMeans Clustering",
      "Implement Naive Bayes",
      "Understand Boosting Algorithms",
      "Build XGBRegressor Model"
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/6130505_439f_3.jpg"
  },
  {
    "title": "Interactive Map Visualization with Kepler GL and Streamlit",
    "price": "Current priceE£799.99",
    "description": "Through this course, you will learn how to visualize large-scale geospatial data using Kepler GL, and easily share interactive map visualizations using Streamlit.Kepler GL is an open-source tool developed by Uber to efficiently analyze and visualize complex geospatial data in real time.Streamlit is a Python framework that allows you to easily create interactive web applications, particularly useful when visualizing data or building dashboards.In this course, you will achieve the following goals:Mastering the Kepler Demo UI: Without writing code, you will directly interact with the Kepler GL interface and experience its various features, gaining a basic understanding of data visualization.Creating Map Visualizations with Kepler GL: Using Google Colab, you will write code to generate map visualizations with Kepler GL. You will learn how to extract visualization settings and use them to customize maps according to your needs.Sharing Map Visualizations with Streamlit: You will learn how to share interactive map visualizations with others using Streamlit, making it easy for users to view the maps and perform spatial analysis without any extra effort.Applying Custom Map Styles with Mapbox: You will overcome the limitations of the default map styles by applying custom map styles with Mapbox to represent geographical details more richly and accurately.",
    "instructor": "Kyla Kim",
    "requirements": [
      "Basic Python skills required: Familiarity with Python, pip for library installation, and basic GitHub usage will make it easier to follow this course."
    ],
    "whatYouWillLearn": [
      "Mastering Kepler GL UI: Use the Kepler GL demo to understand the basics of the UI and how to interact with it for map visualization tasks.",
      "Kepler GL Config Extraction: Visualize various data types (Basic Map, Boundary, Point, H3, Line), and extract their configurations.",
      "Sharing Map Visualizations with Streamlit: Use Streamlit to share maps with other users effectively.",
      "Customizing Map Styles with Mapbox: Apply custom map styles using Mapbox to create unique and personalized visualizations.",
      "H3 Data Generation: Learn how to convert point data into hexagon data, preparing for efficient spatial data visualization."
    ],
    "content": [
      {
        "title": "Course Introduction and Data Preparation",
        "subsections": [
          "Course IntroductionPreview02:46",
          "Data SourcesPreview02:47",
          "H3 Data Generation07:49",
          "Code and Data for this course00:03"
        ]
      },
      {
        "title": "Mastering the Kepler Demo UI",
        "subsections": [
          "Interacting with Kepler Demo UI without Code07:37"
        ]
      },
      {
        "title": "KeplerGL Map Visualizations and Config Extraction",
        "subsections": [
          "Why Experiment in Google Colab?Preview02:12",
          "Base Map and Config Extraction11:20",
          "Boundary Layer and Config Extraction11:30",
          "Point Layer and Config Extraction12:39",
          "H3 Layer and Config Extraction12:26",
          "Line Layer and Config Extraction21:09",
          "Organizing Extracted Config04:01"
        ]
      },
      {
        "title": "Sharing Map Visualizations with Streamlit",
        "subsections": [
          "Streamlit Basics06:21",
          "Displaying a Base Map in StreamlitPreview05:57",
          "Adding Boundary Layers to the Map09:45",
          "Adding Point Layers to the Map11:46",
          "Adding H3 Layers to the Map10:57",
          "Adding Line Layers to the Map11:03",
          "Setting the Layer Order05:40",
          "Deploying an App with Streamlit Cloud05:49"
        ]
      },
      {
        "title": "Applying Custom Map Styles with Mapbox",
        "subsections": [
          "Applying Custom Map Styles with Mapbox10:47",
          "Troubleshooting Mapbox Style Issues02:05"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6226707_4678_12.jpg"
  },
  {
    "title": "The Complete OpenAI and GPT Course in Python w/ Q&A Chatbot",
    "price": "Current priceE£3,099.99",
    "description": "Note: This course assumes that you have gotten the basics of Python and Pandas down. You don’t need to be an experienced Python and Pandas developer, but the ability to follow along and understand syntax is needed.Take your AI development skills to the next level with this course!In this course, you will learn how to build an AI assistant powered by OpenAI's GPT technology, HuggingFace, and Streamlit. In addition, you will learn the foundational concepts of GPT and generative AI, such as Large Language Models, Prompt Engineering, Semantic Search, Finetuning, and more. You will also understand how to use OpenAI’s APIs and their best practices, with real world code samples.Unlike other courses, you will learn by doing. You will start with a blank app, and add features one at a time. Before adding a new feature, you will learn just enough theory to confidently build your app.You will get all the code samples, including Google colab notebooks, and access to the Q&A forum if you get stuck. You don’t need a powerful PC or Mac that has GPUs to take this course. By the end of the course, you will be able to deploy and create your first app using OpenAI’s technology, and be confident about the theoretical knowledge behind this technology. So sign up today and start building your AI powered app!What you will learn:Creating an AI chatbot with StreamlitIntentClassifiers - what they are, how to build it.Prompt Engineering: different ways of crafting the perfect promptHow to evaluate and choose the best promptThe concept of word embeddingsHow to use word embeddings to quantify semantic similarityHow to use a vector database to store word embeddingsHow to create a search engine that searches based on word embeddingsHow to perform entity resolution for documentsSentiment extraction using GPTHow to clean a finance dataset for use in a semantic searchHow to embed finance documents and upload them to a vector databaseHow to use a language model to generate answers to questionsHow to use fine-tuning to ensure the language model does not hallucinateHow to deploy a Q&A bot and a custom action system.",
    "instructor": "Next Word AI Development & Training",
    "requirements": [
      "Prior exposure to Python and Pandas. You don’t need to be an experienced Python and Pandas developer, but the ability to follow along and understand syntax is needed.",
      "Github and Google accounts (free)"
    ],
    "whatYouWillLearn": [
      "The foundations of GPT and generative text - Large Language Models (LLM), Prompt Engineering",
      "Receiver Augmented Generation (RAG) for Question Answering - its use cases and challenges, and real world implementation",
      "Finetuning GPT models and their best practices, when and when not to fine tune.",
      "Best practice strategies for troubleshooting issues with OpenAI APIs",
      "Semantic Search - theory and Implementation",
      "Vector databases, Pinecone - how they work, code samples",
      "How to choose the right GPT model for completion and classification tasks",
      "Understand how to use OpenAI’s APIs and their production best practices",
      "Tackling the LLM hallucination problem - what the problem is, and specific strategies to mitigate it."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview02:20",
          "Course Logistics and Important AnnouncementsPreview02:57",
          "What We Are Building & Problem StatementPreview05:30",
          "FAQPreview01:15",
          "Important DisclaimersPreview00:25"
        ]
      },
      {
        "title": "Project 0: Create a ChatGPT Clone with Python and Streamlit",
        "subsections": [
          "Course SetupPreview07:06",
          "Course Project Solutions00:13",
          "Building a ChatGPT Clone in 50 lines of Code10:39",
          "Integrating OpenAI06:02"
        ]
      },
      {
        "title": "GPT3, Prompt Engineering, and LLMs",
        "subsections": [
          "ChatGPT, GPT3, InstructGPT - How They Work12:48",
          "Prompt Engineering and Advanced GPT Parameters14:53",
          "Why GPT Disrupted AI Industry08:32"
        ]
      },
      {
        "title": "Project 1: Intent Classifier",
        "subsections": [
          "IntentClassifier - What It is, Why It's Important04:29",
          "Prompts for Classification Problems (Notebook)12:48",
          "Evaluation GPT3.5 for Classification (Notebook)20:01",
          "Integrate Intent Classifier into the App10:54"
        ]
      },
      {
        "title": "Limits of GPT - What It Can't Do",
        "subsections": [
          "Limitations of GPT - Knowledge Cutoff, Data Gaps, Token Limits11:14",
          "Limits of GPT - Reasoning, Chain of Thought Prompting07:24"
        ]
      },
      {
        "title": "Project 2: Semantic Search and Retrievers",
        "subsections": [
          "Semantic Search Based Retrieval13:00",
          "Word and Sentence Embeddings (Notebook)13:15",
          "Semantic Search  (Notebook)12:57",
          "Vector Databases, Pinecone, Nearest Neighbor Search17:16",
          "Integrating News Article Retriever into App14:50"
        ]
      },
      {
        "title": "Project 3: Retriever Augmented Question Answering and Fine Tuninng",
        "subsections": [
          "Question Answering with GPT, and Finetuning GPT Models17:34",
          "Question Answering, Strategies for Handling Hallucinations (Notebook)14:42",
          "Question Answering and Finetuning GPT (Notebook)14:29",
          "Generative Labeling, Finetuning GPT, Model Evaluation (Notebook)10:25"
        ]
      },
      {
        "title": "Project 4: Summarization, External System Integration",
        "subsections": [
          "Document Summarization with GPT04:36",
          "Summarization with GPT (Notebook)18:59",
          "App Integration06:01",
          "Adding Real Time Financial Charts (Notebook)09:32",
          "Deployment02:29"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5147194_6558_3.jpg"
  },
  {
    "title": "Time Series Analysis:Hands-On Projects & Advanced Techniques",
    "price": "Current priceE£399.99",
    "description": "Time series analysis focuses on data collected over time, like stock prices, weather patterns, or sensor readings. It reveals hidden trends, patterns, and relationships within this data. By understanding these patterns, we can predict future values, make informed decisions, and gain insights into complex phenomena. Time series analysis is a powerful tool for various fields, including finance, economics, healthcare, and environmental science.This course will teach you how to use Python to analyze time series data. You will learn how to:Import and clean time series data.Calculate common time series statistics.Create time series visualizations.Build time series models.Forecast time series data.Accessing, Manipulating, Visualizing Data.Master Advanced Techniques. Build Projects.Whether you're new to Python or have some programming experience, this course welcomes you to the world of time series analysis. No prior knowledge is required, as we'll start from the basics and gradually introduce advanced techniques using Python.Who this course is for:Beginners and intermediate Python programmers.Data analysts.Data scientists.Business analysts.Anyone who wants to learn how to analyze time series data.AI Engineers.Financial Analysts.Requirements:No prior knowledge is required. So whether you're new to Python or have some programming experience.A computer with Python installed.Welling to learn advanced Techniques.",
    "instructor": "Temotec Learning Academy",
    "requirements": [
      "No prior knowledge is required. So whether you're new to Python or have some programming experience.",
      "Computer and internet.",
      "Everything else you need to learn Python Time Series Data Analysis is already in this course.",
      "Welling to learn advanced Techniques."
    ],
    "whatYouWillLearn": [
      "Import and clean time series data.",
      "Calculate common time series statistics.",
      "Create time series visualizations.",
      "Build time series models.",
      "Forecast time series data.",
      "Accessing, Manipulating, Visualizing Data.",
      "Build Projects."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview04:09",
          "Jupyter Shortcuts01:33",
          "Understanding Data Types and Structures in Python.Preview10:19",
          "Understanding Python Data Structure Wrap up.04:45"
        ]
      },
      {
        "title": "Python Refresher",
        "subsections": [
          "String Functions in Python Part 1Preview02:53",
          "String Functions in Python Part 2Preview01:38",
          "String Functions in Python Part 302:06",
          "String Functions in Python Part 401:18",
          "String Functions in Python Part 501:32",
          "Lists.04:21",
          "Tuples.02:29",
          "Sets.05:32",
          "Dictionaries.04:48",
          "Control Flow IF.04:13",
          "For Loop Part 1.02:44",
          "For Loop Part 2.05:01",
          "While Loop Part 1.05:14",
          "While Loop Part 2.03:34",
          "While Loop Best Practices.02:48",
          "Introduction to Functions in Python.02:18",
          "Functions in Python and Arguments.02:16",
          "Function Tips & Tricks: Recursion.Preview02:15",
          "Function Tips & Tricks: Functions Decorators and Higher Order Functions.02:24",
          "Functions Tips & Tricks: Lambda Functions.02:00",
          "Function Tips & Tricks: Functions Caching & Memoization.03:44",
          "Error Handling in Python.01:06",
          "Files and Modules in Python.06:52"
        ]
      },
      {
        "title": "Object Oriented Programming (OOP) In Python Refresher.",
        "subsections": [
          "Creating Simple Class.Preview06:26",
          "Overviewing Constructor.16:53",
          "Learning How to creating Dunder Methods?05:27",
          "Learning about Inheritance.06:43",
          "Knowing What is the Encapsulation?03:28",
          "Learning also about Multiple Inheritance.04:12",
          "Knowing What is the Overriding?05:04",
          "Learning about Decorators.05:02",
          "Learning How to use Build-in Decorators?05:44"
        ]
      },
      {
        "title": "Project 1: Python Pandas + PostgreSQL",
        "subsections": [
          "PostgreSQL Downloading &  Installing.03:07",
          "Create Database.01:09",
          "Restore Database.01:13",
          "Using CMD & Python pip.PyPi to Install Jupyter Lab & Pandas.01:56",
          "Create a CSV File Using PostgreSQL09:26",
          "Fetchmany and Fetchall03:00",
          "Runnig SQL Query Using Python Panadas Module.05:00",
          "Using Python Pandas Package to load PostgreSQL the Data Output file.09:26",
          "Data Analysis Process Overview.03:06",
          "Pandas Methods.05:16",
          "Pandas data visualization.09:01",
          "Pandas Data Analysis.04:03",
          "Sampling Error.04:00"
        ]
      },
      {
        "title": "Project 2: Scrape the Web & Saving Data to a Database.",
        "subsections": [
          "How to Scrape a website???13:23",
          "Scrape a Table inside a Webpage using Pandas and LXML Python Modules!05:00",
          "Visualization of the Scarped Data.06:00",
          "Save The Scraped Data to a Database.07:16"
        ]
      },
      {
        "title": "Project 3: Python Automation AFC (OS Python Module).",
        "subsections": [
          "Download & Install of Sublime Text Editor.02:02",
          "Project Walkthrough.03:00",
          "Project Arrange Folder Content.09:14"
        ]
      },
      {
        "title": "Project 4: Python Automation Project MPF (PyPDF2 Python Module).",
        "subsections": [
          "Project Walkthrough.02:00",
          "Project Solution.07:00"
        ]
      },
      {
        "title": "Project 5: Python Automation  Business Email List (smtplib Python Module).",
        "subsections": [
          "Part 103:00",
          "Part 216:15",
          "Part 322:00"
        ]
      },
      {
        "title": "Python Numpy Library.",
        "subsections": [
          "Numpy Intro.01:44",
          "Numpy.shape & Numpy.size10:12",
          "Creating Numpy nd arrays using Numpy functions.08:33",
          "Numpy.unique( ) & Array slicing.04:03",
          "Numpy Calculations and Operators.08:24",
          "Numpy Aggregations.06:03",
          "Numpy Reshape and Transposing.09:16",
          "Comparing Numpy Arrays.07:05",
          "Numpy Arrays Images Processing.05:32"
        ]
      },
      {
        "title": "Accessing, Manipulating & Filtering DataFrames.",
        "subsections": [
          "Data manipulation using DataFrames.06:17",
          "Accessing Data Using DataFrames.06:27",
          "Data aggregation and summarization.07:28",
          "Create New Columns, Drop Unnecessary Ones, and Perform Various Data Manipulation06:36",
          "Essential Techniques for Peeking at  &  Describing our Data in Python.06:59",
          "Filtering Data.07:16"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/4533422_7e00_2.jpg"
  },
  {
    "title": "The Complete Quantum Computing Course with Python [2025]",
    "price": "Current priceE£799.99",
    "description": "Master Quantum Computing with Python – From Fundamentals to Advanced AlgorithmsThis course is a comprehensive, hands-on guide to quantum computing, designed for both beginners and professionals. Whether you are a student, researcher, or software developer, this course will take you from the foundational principles of quantum mechanics to implementing real-world quantum algorithms using Python.What You Will LearnQuantum Mechanics Basics – Understanding superposition, entanglement, and quantum interferenceQubits and Quantum Gates – Explore Hadamard, Pauli, CNOT, Toffoli, and rotational gatesQuantum Circuit Design – Build and simulate quantum circuits using Cirq and QiskitQuantum Fourier Transform (QFT) and Grover’s Algorithm – Solve complex problems exponentially fasterQuantum Phase Estimation (QPE) – The foundation for Shor’s Algorithm and quantum cryptographyVariational Quantum Circuits (VQCs) – Hybrid quantum-classical machine learning applicationsQuantum Error Correction (QEC)  – Ensuring reliability in quantum computingQuantum Oracles and Amplitude Amplification – Core components for quantum search algorithmsHands-On Projects and ApplicationsSimulating quantum circuits with PythonImplementing Grover’s Search Algorithm for database searchesBuilding and running the Quantum Fourier Transform (QFT)Developing Quantum Phase Estimation (QPE) for real-world applicationsWho Should Take This Course?Python programmers interested in quantum computingComputer science and physics studentsMachine learning and AI professionals exploring Quantum AIDevelopers and researchers looking to transition into quantum computingWhy Learn Quantum Computing?With major companies and research institutions investing in quantum computing, acquiring quantum programming skills will open doors to cutting-edge technologies and future career opportunities.Enroll Today and Begin Your Quantum Computing Journey!",
    "instructor": "Hoang Quy La",
    "requirements": [
      "Basic knowledge of python is required"
    ],
    "whatYouWillLearn": [
      "Qubit",
      "Qubit State",
      "superposition state",
      "quantum gates",
      "quantum circuits",
      "quantum mechanics",
      "multi-qubit state",
      "Wave theory",
      "Qubit interference",
      "Quantum spin",
      "Stern-Gerlach Experiment",
      "Correlated particles",
      "Bell States",
      "Einstein-Podolsky-Rosen Paradox",
      "Hadamard gate",
      "Cirq",
      "Pauli gate",
      "Phase kickback",
      "Eigenstates",
      "Swap gate",
      "Toffoli gate",
      "CNOT gates",
      "Rϕ Gate",
      "Rx and Ry gates",
      "Equal superposition state",
      "Entangled state",
      "bit-flip error",
      "phase flip error",
      "Quantum Error Correction (QEC)",
      "Shor Code",
      "Variational Quantum Circuits",
      "classical oracle",
      "phase oracle",
      "quantum oracle",
      "Quantum phase estimation",
      "Amplitude Amplification",
      "quantum Fourier transform",
      "Grover’s Algorithm",
      "Deutsch-Jozsa Algorithm"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Course StructurePreview01:32",
          "Tools used in this course (IMPORTANT)Preview01:35",
          "How to make the most out of this coursePreview01:52",
          "What is quantum computing and why is it the future technologyPreview03:57",
          "What is a Qubit and why are Qubits Important?Preview02:35",
          "What is qubit state and what are Key Properties of a Qubit State?Preview02:42",
          "Introduction to superposition state03:42",
          "Introduction to quantum state03:45",
          "Visual Explanation & Real-World Analogy for Qubits and quantum state03:20",
          "Introduction to quantum gates05:44",
          "Introduction to quantum circuits05:24",
          "Introduction to quantum mechanics06:25",
          "Introduction to multi-qubit state08:02",
          "How to measure a quantum state?05:54",
          "Introduction to Wave theory?06:32",
          "Introduction to Qubit interference03:39",
          "Why interfere with qubits?03:38",
          "Quantum Algorithm That Uses Interference: Grover’s Algorithm03:34",
          "Introduction to Quantum spin05:21",
          "Introduction to Stern-Gerlach Experiment04:20"
        ]
      },
      {
        "title": "Basic quantum computing concept and implementation",
        "subsections": [
          "Introduction to Correlated particles03:39",
          "Introduction to Bell States03:25",
          "Introduction to Einstein-Podolsky-Rosen Paradox?05:05",
          "Introduction to Hadamard gate03:18",
          "Introduction to Cirq02:29",
          "Introduction to Pauli gate02:25",
          "Fix the error from the library03:16",
          "How to implement a simple Hadamard gate in Python05:51",
          "Simple implementation of Pauli gate in Python06:08",
          "How to implement a advanced Hadamard gate in Python08:46",
          "Introduction to  Phase kickback?03:29",
          "How to implement Phase kickback in Python08:02",
          "Introduction to Eigenstates03:17",
          "How to implement Eigenstates in Python14:04",
          "Introduction to the Swap gate02:45",
          "Introduction to Toffoli gate04:19",
          "Introduction to CNOT gates03:00",
          "Implementation of CNOT gates07:11",
          "Introduction to Rϕ Gate03:14",
          "Implementation of Rϕ Gate03:16",
          "The Rx and Ry Gates04:33",
          "Implementation of Rx and Ry gates06:38",
          "Introduction to Equal superposition state03:17",
          "Introduction to Entangled state03:29",
          "Bell state implementation06:54",
          "SWAP gate implementation06:15"
        ]
      },
      {
        "title": "Intermediate quantum computing",
        "subsections": [
          "How to create a quantum states in python12:08",
          "How to create a superposition state in python12:34",
          "How to create complex entries in the state vector using python11:41",
          "Advanced Complex entries in the vector state in puthon09:52",
          "Creating a quantum state with complex amplitudes13:35",
          "How to create Multi-Qubit States18:31",
          "How to extract the state in python08:38",
          "How to resize single-qubit gates in python09:58",
          "Introduction to bit-flip error02:53",
          "Implementation of bit-flip error05:51",
          "Introduction to phase-flip error03:53",
          "Implementation of phase flip error05:00",
          "Introduction to Quantum Error Correction (QEC)04:52",
          "Implementation of quantum Error Correction09:46",
          "Introduction to Shor Code01:56",
          "Shor code implementation15:31",
          "Introduction to Quantum Fault Tolerance02:44",
          "Introduction to Variational Quantum Circuits02:55"
        ]
      },
      {
        "title": "Advanced quantum computing",
        "subsections": [
          "Introduction to Classical oracle in quantum computing02:45",
          "implementation of a classical oracle05:18",
          "Introduction to phase oracle03:11",
          "Implementation of phase oracle02:42",
          "Introduction to quantum oracle02:19",
          "Implementation of quantum oracle03:17",
          "Why Quantum Oracles?04:27",
          "Introduction to Quantum phase estimation04:41",
          "Implementation of quantum phase estimation09:32",
          "Introduction to Amplitude Amplification02:48",
          "Implementation of Amplitude Amplification05:44",
          "Introduction to Deutsch-Jozsa Algorithm03:09",
          "Introduction to  Grover’s Algorithm02:47",
          "Introduction to quantum Fourier transform?03:09",
          "Implementation of Quantum Fourier Transform07:55",
          "Implementation of Deutsch-Jozsa Algorithm12:07",
          "Implementation of Grover's algorithm09:17"
        ]
      },
      {
        "title": "Thank you",
        "subsections": [
          "Thank you01:16"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6483743_7417.jpg"
  },
  {
    "title": "ChatGPT Unveiling the Basics, Advancement, Inner Workings",
    "price": "Current priceE£399.99",
    "description": "Welcome to \"ChatGPT Unveiling the Basics, Advancement, Inner Workings\" In this comprehensive course, you will dive deep into the inner workings of ChatGPT, explore the transformative power of Transformers, and unlock the secrets of effective prompt engineering. Whether you're a developer, data scientist, or AI enthusiast, this course will equip you with the knowledge and skills to harness the full potential of ChatGPT.Throughout this course, you will embark on an exciting journey through the fundamentals and advanced concepts of ChatGPT, gaining a thorough understanding of its architecture, capabilities, and limitations. You will explore the underlying principles of Transformers, the revolutionary models that have revolutionized natural language processing, and discover how they enable ChatGPT to process and generate human-like text.With a strong foundation in place, you will delve into the art of prompt engineering—a critical skill for fine-tuning ChatGPT to perform specific tasks or generate desired responses. You will learn proven techniques for crafting prompts that yield accurate, coherent, and contextually relevant outputs, ensuring that ChatGPT becomes a powerful tool in your AI arsenal.Key Topics Covered:Introduction to ChatGPT: Understanding the fundamentals and key concepts behind ChatGPT, including its architecture, pre-training, and fine-tuning processes.Transformers in Natural Language Processing: Exploring the transformative power of Transformers and their role in language modeling, attention mechanisms, and self-attention.Dive into ChatGPT's Inner Workings: Understanding the internal mechanisms of ChatGPTPrompt Engineering Techniques: Mastering the art of prompt engineering to effectively guide and control the outputs of ChatGPT, including context setting, system messages, and user instructions.",
    "instructor": "Lets LearnAI",
    "requirements": [
      "Little bit knowledge of ML will help"
    ],
    "whatYouWillLearn": [
      "By completing the course, learners will develop a solid grasp of the underlying concepts and techniques that power ChatGPT which helps them to crack interviews",
      "Acquire practical skills for deploying and integrating ChatGPT in real-world NLP applications",
      "How to write efficient prompts(Prompt Engineering) for various NLP tasks",
      "Understand the internal workings and limitations of ChatGPT: Through an in-depth exploration of the inner workings and architecture of ChatGPT"
    ],
    "content": [
      {
        "title": "Covering the Basics",
        "subsections": [
          "Introduction to AI,ML,DLPreview05:35",
          "Generative AI vs Discriminative AI07:06",
          "Large Language ModelsPreview05:30",
          "ML Development vs LLM development07:21"
        ]
      },
      {
        "title": "Transformers Architecture",
        "subsections": [
          "Transformers Architecture Explained34:10"
        ]
      },
      {
        "title": "ChatGPT Architecture",
        "subsections": [
          "Pretraining LLM For Completion05:27",
          "Supervised Fine Tuning of LLM (SFT)06:32",
          "Reinforcement Learning from Human Feedback (RLHF)07:31"
        ]
      },
      {
        "title": "Prompt Engineering",
        "subsections": [
          "Prompt Engineering with various NLP tasks15:50",
          "Different Prompt Techniques07:25",
          "Token Limit03:03"
        ]
      },
      {
        "title": "Materials",
        "subsections": [
          "Course Materials00:00"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5420098_4ec2.jpg"
  },
  {
    "title": "Fundamentals of image smoothing",
    "price": "Current priceE£399.99",
    "description": "Course DescriptionLearn to process images by learning fundamentals of image smoothing using opencv and popular programming language Python.Build a strong foundation in Image Processing with this tutorial for beginners.Understanding of how images are processed as array of RGB pixel intensitiesLearn basics of smoothing using kernels and convolutionLeverage OpenCV and Python to perform smoothing to create effects like bilateral blur, gaussian blur, median blurUser Jupyter Notebook for programmingUse step by step instructions along with plenty of examplesA Powerful Skill at Your Fingertips  Learning the fundamentals of image smoothing puts a powerful and very useful tool at your fingertips. Python, opencv and Jupyter are free, easy to learn, has excellent documentation.Image smoothing is ubiquitous in everyday applications such as edge detection, advertisement image quality improvements. Its also pre-requisite for computer vision applications using machine learning.Jobs in image processing area are plentiful, and being able to learn opencv and python will give you a strong edge.Image smoothing tasks are becoming very popular. Amazon, Walmart, Google eCommerce websites are few famous example of image smoothing in action. Convolutional neural network (CNN) uses these techniques to find edges. Deep neural network inside CNN learns these patterns by trying out various kernels to match image with target image.Image processing tasks are vital in information retrieval and computer vision applications .  Big advertising companies and Hollywood studios already using image smoothing in improving image quality. Content and Overview  This course teaches you on how to smooth images using opencv, python and Jupyter framework.  You will work along with me step by step to build following answersIntroduction to image smoothingLearn how to apply kernel to image using smoothingBuild an jupyter notebook step by step using opencv and python and learn effects like bilateral smoothing, gaussian blur, median blur and average blur.What am I going to get from this course?Learn fundamentals of image smoothing and build image smoothing tasks from professional trainer from your own desk.Over 10 lectures teaching you how to perform image convolution using opencv and pythonSuitable for beginner programmers and ideal for users who learn faster when shown.Visual training method, offering users increased retention and accelerated learning.Breaks even the most complex applications down into simplistic steps.Offers challenges to students to enable reinforcement of concepts. Also solutions are described to validate the challenges.",
    "instructor": "Evergreen Technologies",
    "requirements": [
      "None"
    ],
    "whatYouWillLearn": [
      "Apply image smoothing effects like bilateral smoothing, gaussian blur, median blur and average blur to remove noise in the image",
      "Understanding of how images are processed as array of RGB pixel intensities",
      "Learn basics of smoothing using kernels and convolution",
      "Leverage OpenCV and Python to perform smoothing to create effects like bilateral blur, gaussian blur, median blur"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview04:04",
          "Introduction to image convolutionPreview05:12",
          "Why study image convolution?08:25",
          "About AuthorPreview07:05"
        ]
      },
      {
        "title": "Setup",
        "subsections": [
          "Install AnacondaPreview10:56",
          "Install OpenCV Part I14:13",
          "Install OpenCV Part IIPreview03:26"
        ]
      },
      {
        "title": "Image fundamentals",
        "subsections": [
          "Math Intro01:10",
          "Anatomy of an image08:28",
          "Basic operations on image28:57",
          "Math operation on images04:30"
        ]
      },
      {
        "title": "Basics of convolution",
        "subsections": [
          "Convolution math basics07:39",
          "Show me the code05:23",
          "Convolution in action20:31"
        ]
      },
      {
        "title": "Leveraging convolution for smoothing and blurring operation",
        "subsections": [
          "Average smoothing10:12",
          "Gaussian blur07:24",
          "Median Blur04:13",
          "Bilateral Blur06:13",
          "Next Steps03:30"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/2704756_9543_3.jpg"
  },
  {
    "title": "Data Manipulation in Python: A Pandas Crash Course 2025",
    "price": "Current priceE£399.99",
    "description": "n the real-world, data is anything but clean, which is why Python libraries like Pandas are so valuable.If data manipulation is setting your data analysis workflow behind then this course is the key to taking your power back.Own your data, don’t let your data own you!When data manipulation and preparation accounts for up to 80% of your work as a data scientist, learning data munging techniques that take raw data to a final product for analysis as efficiently as possible is essential for success.Data analysis with Python library Pandas makes it easier for you to achieve better results, increase your productivity, spend more time problem-solving and less time data-wrangling, and communicate your insights more effectively.This course prepares you to do just that!With Pandas DataFrame, prepare to learn advanced data manipulation, preparation, sorting, blending, and data cleaning approaches to turn chaotic bits of data into a final pre-analysis product. This is exactly why Pandas is the most popular Python library in data science and why data scientists at Google, Facebook, JP Morgan, and nearly every other major company that analyzes data use Pandas.If you want to learn how to efficiently utilize Pandas to manipulate, transform, pivot, stack, merge and aggregate your data for preparation of visualization, statistical analysis, or machine learning, then this course is for you.Here’s what you can expect when you enrolled with your instructor, Ph.D. Samuel Hinton:Learn common and advanced Pandas data manipulation techniques to take raw data to a final product for analysis as efficiently as possible.Achieve better results by spending more time problem-solving and less time data-wrangling.Learn how to shape and manipulate data to make statistical analysis and machine learning as simple as possible.Utilize the latest version of Python and the industry-standard Pandas library.Performing data analysis with Python’s Pandas library can help you do a lot, but it does have its downsides. And this course helps you beat them head-on:",
    "instructor": "Asim Noaman Lodhi",
    "requirements": [
      "Basic knowledge of Python"
    ],
    "whatYouWillLearn": [
      "Learn how to use Python and Pandas for data analysis and data manipulation. Transform, clean and merge data with Python.",
      "Data Visualization with Python",
      "Create, save and serialise data frames in and out of multiple formats.",
      "Detect and intelligently fill missing values.",
      "Merge data sources into a beautiful whole.",
      "Seamlessly work with data from different time zones.",
      "Learn the common pitfalls and traps that ensnare beginners and how to avoid them."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview02:18",
          "Introduction to Data AnalysisPreview00:46",
          "Real Time Business Intelligence ProblemsPreview00:52",
          "Introduction to Pandas LibraryPreview01:22",
          "Python & Jupyter NoteBook InstallationPreview04:38"
        ]
      },
      {
        "title": "Data Manipulation with Pandas",
        "subsections": [
          "Importing Libraries in JupyterNote BookPreview02:06",
          "How to View Dataset01:09",
          "How to fetch Columns01:09",
          "How to Perform Descriptive Analysis03:25",
          "How to Identify Unique Values03:17",
          "How to Filter the dataset01:51",
          "How to filter Specific Numbers of Records01:52",
          "How to Apply Logical Condition00:45",
          "How to Replace Null Values01:28",
          "Series in python hands on01:38",
          "How to create data frame03:51",
          "How to inspect the data in detail06:40",
          "search records with loc function04:37",
          "Search records with iloc function02:33"
        ]
      },
      {
        "title": "Exploratory Data Analysis for Titanic Data Set",
        "subsections": [
          "Exploratory Data Analysis with Pandas library03:43",
          "Exploratory Data Analysis II04:30",
          "Dealing with Missing Values03:12",
          "Data Visualization for Titanic Dataset04:37",
          "Data Visualization II02:19"
        ]
      },
      {
        "title": "Data Visualization with Pandas",
        "subsections": [
          "How to Create Count plot01:50",
          "How to Create Histogram02:38",
          "How to Create Bar Plot01:57",
          "How to create Bar Plot Example00:45",
          "How to Create Scatter Plot01:52",
          "How to Create Box Plot01:30",
          "Pandas Library chearsheet07:35",
          "What is Data Cleaning06:23",
          "Data Cleaning with Examples01:28"
        ]
      },
      {
        "title": "EDA with AIPRM Chat GPT Hands on Tasks",
        "subsections": [
          "EDA Analysis with Chat GPT14:24"
        ]
      },
      {
        "title": "Final Assignment",
        "subsections": [
          "Final Assignment05:45"
        ]
      },
      {
        "title": "Data Analysis with Power Query",
        "subsections": [
          "Live Data Analysis with Power Query ( Ms Excel)55:18",
          "How to Append Multiple Excel Sheets04:45"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5615262_3a71_2.jpg"
  },
  {
    "title": "Mastering Classification Metrics: Beyond Accuracy",
    "price": "Current priceE£799.99",
    "description": "Master Classification Metrics with a Visual, Intuitive ApproachChoosing the right classification metric can make or break your machine learning model. Yet, many data professionals default to accuracy—when better options like precision, recall, F1-score, and ROC-AUC might be the smarter choice.This course is designed to help you visually learn, remember, and apply the most important classification metrics—so you can confidently select the right one for any problem.What You’ll Learn:Define and compare key classification metrics like precision, recall, F1-score, and ROC-AUCVisually understand how each metric works and when to use itAvoid common pitfalls in metric selection for imbalanced datasetsGain confidence in choosing the best metric for real-world machine learning problemsWhy Take This Course?Intuitive – Learn metric definitions in a highly relatable, easy-to-digest wayVisual – Tap into your natural learning style with engaging visuals that SHOW rather than tellApplicable – Master not just the definitions, but also how to choose the right metric for any ML projectWho Should Enroll?Data science students, analysts, and professionals looking to strengthen their understanding of classification metricsMachine learning practitioners who want to improve model evaluation and decision-makingJoin now and stop second-guessing your metric choices—start optimizing your models with confidence!",
    "instructor": "Kimberly Fessel",
    "requirements": [
      "Basic math skills (fractions, percentages, and weighted averages) to follow metric calculations.",
      "Familiarity with machine learning concepts is helpful but not necessary. Beginners can follow along as long as they have an interest in classification metrics.",
      "No programming experience required! This course focuses on conceptual understanding with visual explanations—no coding needed."
    ],
    "whatYouWillLearn": [
      "Define common classification metrics, including accuracy, precision, recall, F1-score, and ROC-AUC.",
      "Visualize classification metrics using intuitive, real-world examples to reinforce learning and recall.",
      "Compare and contrast different metrics to evaluate their strengths, weaknesses, and ideal use cases.",
      "Select the most effective metric for a given classification problem based on data distribution and project goals.",
      "Analyze confusion matrices to gain deeper insights into model performance.",
      "Identify when accuracy is misleading and how to use alternative metrics for imbalanced datasets.",
      "Optimize machine learning models by prioritizing the right metric for your specific use case."
    ],
    "content": [
      {
        "title": "Getting Started with Classification Metrics",
        "subsections": [
          "Welcome to the Course: Master Classification MetricsPreview01:15",
          "Introduction to Classification Metrics: What You’ll LearnPreview03:46"
        ]
      },
      {
        "title": "Evaluating Hard Classifications: Accuracy, Precision, Recall, and More",
        "subsections": [
          "Hard Classifications: How Models Make Definitive Predictions00:41",
          "Confusion Matrix for Classification Models: A Critical Tool in Model Evaluation04:55",
          "Accuracy, Precision, and Recall: Understanding Key Classification MetricsPreview06:01",
          "F1-Score & F-Beta: Balancing Precision and Recall in Classification11:28",
          "Different Names, Same Metrics: Understanding Classification Terms03:01",
          "Hard Classification Metrics: Test Your Knowledge5 questions"
        ]
      },
      {
        "title": "Evaluating Soft Classifications: ROC AUC and Log Loss",
        "subsections": [
          "Soft Classifications: Understanding Class Probabilities01:00",
          "ROC Curve & AUC: Step-by-Step Guide10:35",
          "Log Loss: Evaluating Probability Predictions in Classification08:34",
          "Metrics for Multiclass Classification07:31",
          "Soft Classification Metrics: Test Your Knowledge5 questions"
        ]
      },
      {
        "title": "Choosing the Best Metrics",
        "subsections": [
          "Choosing the Right Metric for the Job00:55",
          "Beyond Accuracy: Advanced Metrics for Machine Learning Models04:42",
          "Classification Metric Selection Guide00:25",
          "Machine Learning Case Studies: Selecting the Best Classification Metric04:45",
          "ML Case Studies: Selecting the Best Classification Metric [SOLUTION]08:07"
        ]
      },
      {
        "title": "Mastering Classification Metrics with a Final Review",
        "subsections": [
          "Congratulations!00:27",
          "Your Go-To Cheat Sheet and Course Recap12:21",
          "Final Quiz: Mastering Classification Metrics25 questions",
          "Course Completion Certificate00:12"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5141392_8584_4.jpg"
  },
  {
    "title": "Mastering Pandas: 300 Practice MCQs for Data Analysis",
    "price": "Current priceE£399.99",
    "description": "Unlock the full potential of the Pandas library with \"Mastering Pandas: 300 Practice MCQs for Data Analysis.\" This comprehensive practice test course is designed to help you solidify your understanding of Pandas, a crucial tool for data manipulation and analysis in Python. The course includes 6 practice tests, each containing 50 questions.Practice MCQs covers below Topics in Pandas Library Summarizing dataLoading dataHandling missing dataWorking with text dataSorting and copying dataIndexing and selecting dataGroupby operations: Split, apply, combineMerging, joining, and concatenating dataReshaping data and pivot tablesWorking with time series dataMultiIndex operationsWindowing functionsVisualization functionsBy the end of completing this practice test, participants will gain:A thorough understanding of Pandas' core functionalities for data manipulation and analysis.Enhanced skills in data summarization, loading, cleaning, and preprocessing.Proficiency in advanced indexing, selection techniques, and handling missing data.Improved ability to work with text data, perform sorting, and manage data copying.Expertise in groupby operations, merging, joining, and concatenating datasets.Competence in reshaping data, creating pivot tables, and working with time series data.Mastery of MultiIndex operations, windowing functions, and data visualization techniques.Increased confidence in applying Pandas to real-world data analysis tasks.The ability to solve complex data problems efficiently using Pandas.",
    "instructor": "Vinay Babu Ulli",
    "requirements": [],
    "whatYouWillLearn": [],
    "content": [
      {
        "title": "Practice Tests",
        "subsections": [
          "Pandas Practice MCQs(1-50)50 questions",
          "Pandas Practice MCQs(51-100)50 questions",
          "Pandas Practice MCQs(101-150)50 questions",
          "Pandas Practice MCQs(151-200)50 questions",
          "Pandas Practice MCQs(201-250)50 questions",
          "Pandas Practice MCQs(251-300)50 questions"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5971304_306b_4.jpg"
  },
  {
    "title": "Mastering Statistics: Fundamentals to Data Analysis",
    "price": "Current priceE£649.99",
    "description": "Are you ready to elevate your data analysis skills and unveil the untold stories within your datasets? Dive into the captivating universe of \"Mastering Statistics: Fundamentals to Data Analysis.\" This course isn't just about crunching numbers; it's your portal to deciphering the language of statistical inference and relationships.From deciphering samples and appraising relationships to grasping confidence intervals and significance testing, you'll build a robust toolkit for dynamic data analysis. Explore strategies for handling binary and categorical data, dive into correlation and regression analysis, and command ANOVA for advanced inference.By steering clear of pitfalls and comprehending the risks of data manipulation, you'll emerge armed with the precision to draw sound conclusions and fuel data-driven choices. Whether your playground is business, research, or any data-centric realm, this course empowers you to extract the insights that transform success.By the course's end, you'll wield advanced statistical techniques that metamorphose your approach to data analysis. Uncover concealed relationships, drive data-fueled decisions, and unlock pathways to unparalleled growth.Ready to embark on the journey to mastery? Enroll now and harness the formidable prowess of statistical inference and relationships, guiding your stride towards informed decision-making. Your voyage to mastery commences here; seize the moment and transform your career!",
    "instructor": "Enterprise DNA",
    "requirements": [
      "Basic understanding of variable types, descriptive statistics, and inferential statistics (recommended)",
      "Familiarity with statistical software such as R or Python (beneficial but not required)",
      "Open to beginners and individuals with prior data analysis experience",
      "No specific prerequisites or prior knowledge necessary"
    ],
    "whatYouWillLearn": [
      "Gain expertise in advanced statistical techniques to uncover meaningful relationships within data.",
      "Develop the skills to make informed decisions based on robust statistical inference.",
      "Master the application of statistical tools for analyzing categorical and quantitative variables.",
      "Avoid common pitfalls and confidently draw accurate conclusions from complex data analysis."
    ],
    "content": [
      {
        "title": "Foundations of Statistical Analysis and Confidence Intervals",
        "subsections": [
          "Learning Tips From Enterprise DNA01:33",
          "Course Overview - Let's get Started!00:14",
          "Facts and Fallacies: Outliers in Data00:31",
          "Course Overview and WelcomePreview09:15",
          "Reproducing Work in R: Setting up Your EnvironmentPreview01:52",
          "Understanding the Challenge of Inference14:32",
          "Addressing Bias and Variability in Data AnalysisPreview05:37",
          "Introduction to Confidence Intervals: Concepts and Importance12:30",
          "Calculating Confidence Intervals: Step-by-Step Guide10:01",
          "Interpreting Confidence Intervals: Practical Examples and Applications04:17",
          "Foundations of Statistical Analysis and Confidence Intervals - Review01:04",
          "Foundations of Statistical Analysis and Confidence Intervals - Quiz5 questions",
          "Your Feedback Matters!00:40",
          "Data Analysis and Confidence Intervals Insights00:54"
        ]
      },
      {
        "title": "Significance Testing and Proportional Analysis Techniques",
        "subsections": [
          "Quick Facts: Behind Data Statistics00:27",
          "Introduction to Significance Testing: Fundamentals and Hypothesis Testing10:44",
          "Common Errors in Significance Testing: Type I and Type II Errors06:21",
          "Practice with Significance Testing: Case Studies and Exercises08:34",
          "Understanding Statistical Usage: Avoiding Misuse and Abuse09:53",
          "Confidence Intervals for Proportion: Estimating and Interpreting Proportions09:44",
          "Significance Testing for Proportions: Hypothesis Testing with Categorical Data04:44",
          "Proportions Practice: Applying Proportional Analysis Techniques07:26",
          "Significance Testing and Proportional Analysis Techniques - Review01:04",
          "Significance Testing and Proportional Analysis Techniques - Quiz5 questions",
          "Navigating the Nuances of Significance Testing and Proportional Analysis00:46"
        ]
      },
      {
        "title": "Goodness of Fit, Sample Size, and Two-Sample Analysis",
        "subsections": [
          "By the Numbers: Little-Known Facts in Statistics00:23",
          "Understanding Goodness of Fit: Assessing Model Fit and Distributional Assumption14:20",
          "Goodness of Fit Practice: Analyzing and Interpreting Model Fit07:07",
          "Sample Size and Power: Determining Sample Size Requirements and Power Analysis08:36",
          "Fundamentals of Statistics: Key Concepts09:37",
          "Introduction to Two-Sample Testing04:44",
          "Confidence Intervals for Two-Sample Comparison12:50",
          "Significance Testing for Two-Sample Comparison12:47",
          "Goodness of Fit, Sample Size, and Two-Sample Analysis - Review01:16",
          "Goodness of Fit, Sample Size, and Two-Sample Analysis - Quiz5 questions",
          "The Art of Model Fitting, Sample Dynamics, and Two-Sample Analysis00:50"
        ]
      },
      {
        "title": "Two-Sample Analysis: Binary and Categorical Data",
        "subsections": [
          "Fact Trek: Navigating Data Statistics00:25",
          "Practice: Performing the Welch Test07:53",
          "Analyzing Two-Sample Binary Data14:46",
          "Pitfalls to Avoid: The Dangers of Data Dredging06:15",
          "Analyzing Two-Sample Categorical Data06:56",
          "Practice: Analyzing Categorical Data04:57",
          "Two-Sample Analysis: Binary and Categorical Data - Review01:13",
          "Two-Sample Analysis: Binary and Categorical Data - Quiz5 questions",
          "Decoding Binary and Categorical Data: Two-Sample Analyses Unraveled00:53"
        ]
      },
      {
        "title": "Statistical Relationships and Analysis",
        "subsections": [
          "Data Dispatch: Good to Know Quick Facts00:20",
          "Introduction to Sample Correlation11:47",
          "Hypothesis Testing and Significance of Correlation11:41",
          "Linear Regression: Modeling Relationships14:36",
          "Practice: Correlation and Regression Analysis05:36",
          "Introduction to ANOVA (Analysis of Variance)11:13",
          "Advanced ANOVA Techniques10:01",
          "Independence Testing of Categorical Variables07:20",
          "Practice: Analyzing Categorical Variables06:31",
          "Statistical Relationships and Analysis - Review00:59",
          "Statistical Relationships and Analysis - Quiz5 questions",
          "Navigating Statistical Relationships: Correlation, Regression, and Beyond00:49"
        ]
      },
      {
        "title": "Additional Resources - Complimentary guides for your data career",
        "subsections": [
          "2024 Data Career Guide - Enterprise DNA00:18",
          "Congratulations and Next Steps01:10"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5450206_c1a8_2.jpg"
  },
  {
    "title": "Web scraping and data analysis with Python",
    "price": "Current priceE£399.99",
    "description": "Have you ever wondered how web scraping works and what added value you can gain from the extracted data? Plus the opportunity to get more information by analyzing data in an end-to-end project in Python? Then this is the right course for you!In this course “Web Scraping and Data Analysis with Python – A Practical Introduction Applied to ESG Rating and Stock Market Data,” I will provide you a comprehensive introduction on how to apply web scraping and data analysis approaches in Python using financial data from Yahoo Finance as a test-bed. After a brief insight into HTML, we will cover the essentials of web scraping using BeautifulSoup, a well-known library in Python, in order to extract a series of ESG (Environmental, Social, and Governance) scores along with their underlying stock prices. In turn, we will move to the data analysis part, where we will conduct portfolio optimizations based on the Markowitz model. There, you will get familiar with the approaches on how to perform a classic portfolio optimization and then enhance it by incorporating the ESG scores obtained from the web scraping part. This will help you gaining an understanding on how to make data-driven decisions in finance, and to assess the effect between the risk/return profile and sustainability factors.By the end of this course, you will obtain the skills to build your own web scraping and data analysis projects in Python, enabling you to extract valuable information from the web and turn it into actionable insights.",
    "instructor": "Dimitrios Koulialias PhD",
    "requirements": [
      "Some basic knowledge in Python as well as finance would be helpful, but is not mandatory"
    ],
    "whatYouWillLearn": [
      "Get an insight on data acquisition and data analysis processes using financial data from yahoo finance as a test-bed",
      "Get an introduction into HTML and its main tags/elements for understanding a webpage structure",
      "Obtain a first understanding of BeautifulSoup as a means for scraping data from a webpage",
      "Preprocess data in Python using Pandas",
      "Manage and extract further information out of the scraped ESG rating score data",
      "Get an introduction into Markowitz portfolio theory for data analysis based on a (constrained) optimization approach",
      "Incorporate the ESG rating score data into Markowitz' portfolio theory and assess the effect on the risk and return"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Course introductionPreview05:22",
          "Installation / setup of the development environmentPreview00:18"
        ]
      },
      {
        "title": "Web Scraping with Python",
        "subsections": [
          "General considerationsPreview03:16",
          "Introduction to HTML - I06:05",
          "Introduction to HTML - II06:46",
          "Introduction to HTML - III08:58",
          "Introduction to BeautifulSoup03:56",
          "Scraping the 'test.html' file13:31",
          "Scraping a webpage16:26"
        ]
      },
      {
        "title": "ESG Data",
        "subsections": [
          "General considerationsPreview08:14",
          "Scraping an ESG score from one stock of the Swiss Market Index (SMI)07:30",
          "Scraping all ESG scores of the SMI stocks12:00",
          "ESG score distribution across company sectors19:32"
        ]
      },
      {
        "title": "Data analysis using the ESG scores",
        "subsections": [
          "Portfolio selection - The Markowitz modelPreview06:56",
          "Example - Minimum variance portfolio of two stocks19:19",
          "Implementation: Minimum variance portfolio of SMI20:24",
          "Markowitz goes green - The portfolio selection model extended with ESG01:47",
          "Implementation: Minimum variance portfolio of SMI with ESG26:39",
          "Efficient frontier calculation as function of ESG score11:47"
        ]
      },
      {
        "title": "Summary and outlook",
        "subsections": [
          "Summary and outlook03:28"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5683508_58f7.jpg"
  },
  {
    "title": "Build Powerful SAAS Business with OpenAI API and Formwise",
    "price": "Current priceE£399.99",
    "description": "Welcome to the \"Build Powerful SAAS Business with OpenAI API and Formwise\" course! In the rapidly evolving digital landscape, Software as a Service (SAAS) businesses are gaining immense traction due to their scalability, accessibility, and cost-effectiveness. If you've ever dreamed of creating your own SAAS platform but felt daunted by the technical challenges, this course is designed specifically for you. Leveraging the power of OpenAI's API and Formwise, this course will guide you step-by-step through the process of building a robust, efficient, and scalable SAAS application.Imagine being able to create intelligent, AI-driven applications that can revolutionize industries, automate tasks, and provide unprecedented value to users. With OpenAI's powerful capabilities at your disposal, the potential is limitless. However, the key to unlocking this potential lies in understanding how to effectively harness and integrate these technologies into a seamless SAAS product. This course breaks down complex concepts into easy-to-follow modules, ensuring that you gain both the theoretical knowledge and practical skills necessary to succeed.The curriculum covers everything from the basics of setting up your development environment to advanced techniques for integrating AI functionalities. You'll learn how to brainstorm and validate your SAAS ideas, set up and manage your project using Formwise, and incorporate AI tools to enhance your product's capabilities. Whether you're looking to create a tool for content generation, data analysis, customer support, or any other application, this course will equip you with the skills to bring your vision to life.By the end of this course, you'll have a comprehensive understanding of how to build and scale a SAAS business from scratch. You'll learn the intricacies of working with APIs, managing data, and creating user-friendly interfaces. More importantly, you'll understand how to leverage AI to create products that stand out in the market. Don't miss out on this opportunity to stay ahead of the curve in the digital economy. Enroll now and take the first step towards becoming a successful SAAS entrepreneur.",
    "instructor": "Being Commerce",
    "requirements": [
      "Basic understanding of programming concepts.",
      "Familiarity with web development.",
      "Access to a computer with an internet connection.",
      "Willingness to learn and experiment with new technologies.",
      "Basic knowledge of APIs (helpful but not mandatory)."
    ],
    "whatYouWillLearn": [
      "Understand the basics and advanced concepts of SAAS business models.",
      "Set up and manage projects using Formwise.",
      "Integrate OpenAI API into your SAAS applications.",
      "Brainstorm and validate SAAS ideas.",
      "Create and manage AI-driven tools.",
      "Develop user-friendly interfaces for SAAS products.",
      "Implement data management strategies.",
      "Scale and deploy SAAS applications.",
      "Leverage AI to enhance product functionalities."
    ],
    "content": [
      {
        "title": "Build Powerful SAAS Business with OpenAI API and Formwise",
        "subsections": [
          "Build Powerful SAAS Business with OpenAI API and Formwise (Promo)Preview02:53",
          "Introduction to AI Tools & APIPreview19:43",
          "Brain Storming Idea with ChatGPT32:38",
          "Testing AI Tool & Customization11:42"
        ]
      },
      {
        "title": "Tools Creation Step by Step Guide",
        "subsections": [
          "Starting with Assistant API26:00",
          "Toolsets, Share & Embed27:10"
        ]
      },
      {
        "title": "Building SAAS Website on WordPress",
        "subsections": [
          "Setting Up WordPress54:25",
          "Setting Up Configuration55:44",
          "Backend Membership Setup01:14:33",
          "(Important) ChatGPT & AI Content Update11:29",
          "Bonus01:00"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/5784866_f76c_2.jpg"
  },
  {
    "title": "Data Analyst Portfolio Creation to Build Practical Skills",
    "price": "Price not found",
    "description": "Data Analyst Portfolio Creation Course - Enroll Now & Build Your Professional Portfolio!Showcase Your Data Analyst Skills & Stand Out to EmployersAre you an aspiring data analyst looking to demonstrate your skills and enhance your job prospects? This course provides a step-by-step guide to building a professional portfolio that highlights your data analysis abilities, helping you gain visibility among recruiters and potential clients.Why This Course Was CreatedMany aspiring data analysts face the challenge of proving their capabilities without prior work experience. A well-structured portfolio can effectively showcase your skills, increasing your chances of catching the attention of employers and freelance clients. This course is designed to equip you with the practical knowledge and tools needed to create an impactful data analyst portfolio.What You’ll Learn in This CourseDevelop a professional data analyst portfolio that highlights your skills. Structure and document real-world projects to showcase your expertise. Master data visualization techniques to enhance your presentations. Build and host your portfolio using platforms like GitHub, Notion, or Tableau Public. Optimize your LinkedIn and social media presence to increase visibility. Improve your confidence in presenting your work during interviews.Introducing Data Analyst Portfolio CreationA step-by-step, hands-on course designed to help you create a structured, well-documented portfolio that demonstrates your data analysis skills.Course Modules:Understanding the Value of a Portfolio Selecting and Executing Portfolio Projects Creating and Presenting Your Work Setting Up Your Portfolio Website Increasing Portfolio Visibility & Networking Showcasing Your Portfolio in Interviews & Freelancing Capstone Project: Complete & Publish Your PortfolioExclusive Resources to Enhance Your LearningData Analyst Portfolio Templates – Streamline your workflow. Insider Tips – Learn how to optimize your portfolio for recruiters.What Students Are Saying:This course gave me a clear roadmap to build my portfolio. Now I feel more confident showcasing my skills! – John D. The real-world project examples helped me demonstrate my abilities effectively. – Sarah K. After applying the LinkedIn strategies from this course, I started getting more recruiter interactions. – Michael B.Frequently Asked QuestionsQ: Is this course suitable for beginners?A: Yes! Even if you're just starting, this course will guide you through building a professional portfolio from scratch.Q: How much time will this course require?A: The course is self-paced, allowing you to complete it at your convenience with lifetime access.Get Started Today!Enroll now and take the first step toward creating a compelling data analyst portfolio that showcases your skills and expertise.ENROLL NOW",
    "instructor": "Lasisi Akeem",
    "requirements": [
      "Basic Understanding of Data Analysis",
      "Experience with Spreadsheet Tools (Excel/Google Sheets)",
      "Familiarity with Any Data Analysis Tool",
      "Access to a Computer with Internet Connection",
      "Willingness to Learn & Apply Knowledge – No prior portfolio-building experience is needed! If you're eager to learn, apply practical insights, and put in the work, you’ll walk away with a strong portfolio.",
      "No coding or web development experience required! The course provides beginner-friendly methods to create and showcase your portfolio without coding."
    ],
    "whatYouWillLearn": [
      "Understand the Purpose of a Data Analyst Portfolio – Recognize the value of a portfolio in showcasing skills and experience in data analysis.",
      "Curate Meaningful Projects – Learn how to select and present projects that highlight analytical and problem-solving skills.",
      "Develop Data Visualization and Storytelling Techniques – Use visual storytelling to present data-driven insights effectively.",
      "Gain Practical Experience with Portfolio Tools – Explore GitHub, Tableau Public, and personal websites as platforms to showcase projects.",
      "Apply a Structured Approach to Data Projects – Follow best practices for defining business problems, analyzing data, and drawing conclusions.",
      "Create a Professional Portfolio Website – Learn how to organize and present projects using platforms like GitHub Pages, Notion, or WordPress.",
      "Optimize Portfolio for Visibility – Understand how to present work professionally and make it accessible to industry professionals.",
      "Enhance Professional Profiles with a Portfolio – Learn strategies to integrate portfolio projects into LinkedIn and resumes to strengthen professional presence.",
      "Explore Methods to Share and Promote Work – Use social media, blogs, and networking to showcase projects and engage with industry professionals.",
      "Develop Confidence in Presenting Work – Learn techniques to effectively communicate portfolio projects in professional settings."
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/6524143_8fe3_2.jpg"
  },
  {
    "title": "Applied Machine Learning With Python",
    "price": "Price not found",
    "description": "Interested in the field of Machine Learning? Then this course is for you! This course has been designed by two professional Data Scientists so that we can share our knowledge and help you learn complex theories, algorithms, and coding libraries in a simple way. We will walk you step-by-step into the World of Machine Learning. With every tutorial, you will develop new skills and improve your understanding of this challenging yet lucrative sub-field of Data Science. This course is fun and exciting, but at the same time, we dive deep into Machine Learning. It is structured the following way:Part 1 - Data PreprocessingPart 2 - Regression: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, SVR, Decision Tree Regression, Random Forest RegressionPart 3 - Classification: Logistic Regression, K-NN, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest ClassificationPart 4 - Clustering: K-Means, Hierarchical ClusteringPart 5 - Association Rule Learning: Apriori, EclatPart 6 - Reinforcement Learning: Upper Confidence Bound, Thompson SamplingPart 7 - Natural Language Processing: Bag-of-words model and algorithms for NLPPart 8 - Deep Learning: Artificial Neural Networks, Convolutional Neural NetworksPart 9 - Dimensionality Reduction: PCA, LDA, Kernel PCAPart 10 - Model Selection & Boosting: k-fold Cross Validation, Parameter Tuning, Grid Search, XGBoostMoreover, the course is packed with practical exercises that are based on real-life examples. So not only will you learn the theory, but you will also get some hands-on practice building your own models.And as a bonus, this course includes both Python and R code templates which you can download and use on your own projects.Important updates (June 2020):CODES ALL UP TO DATEDEEP LEARNING CODED IN TENSORFLOW 2.0TOP GRADIENT BOOSTING MODELS INCLUDING XGBOOST AND EVEN CATBOOST!",
    "instructor": "Anand Kumar",
    "requirements": [
      "Basic knowledge of computer programming"
    ],
    "whatYouWillLearn": [
      "Regression: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, SVR, Decision Tree Regression, Random Forest Regression",
      "Classification: Logistic Regression, K-NN, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification",
      "Clustering: K-Means, Hierarchical Clustering",
      "Deep Learning: Artificial Neural Networks, Convolutional Neural Networks"
    ],
    "content": [],
    "image": "https://img-c.udemycdn.com/course/240x135/4666234_f9cf_3.jpg"
  },
  {
    "title": "Customer Analytics with R and Tableau",
    "price": "Current priceE£799.99",
    "description": "Course IntroductionUnderstanding customers is vital for any business aiming to thrive in today’s competitive market. This course introduces you to customer analytics, teaching you how to leverage R and Tableau to conduct market research, segment audiences, analyze customer churn, and make data-driven decisions. Through hands-on case studies, you'll master key techniques in descriptive, predictive, and prescriptive analytics to drive customer-centric strategies.Section-wise WriteupSection 1: IntroductionBegin your journey into customer analytics by understanding its significance and applications across industries. This section provides an overview of how R and Tableau can be used to derive insights from customer data and transform them into actionable strategies.Section 2: Market Research and AnalyticsDive into market research with practical examples, such as analyzing Net Promoter Scores (NPS) of banks. Learn to differentiate between customer exceptions and perceptions and explore market segmentation techniques, specifically for the airline industry. The section concludes with a summary of cluster groups and their relevance, along with insights into company performance metrics through descriptive and predictive analytics.Section 3: Telecom Churn and Case StudiesExplore a real-world application of customer analytics by analyzing telecom customer churn. Understand sensitivity and specificity in predictive modeling and leverage prescriptive analytics to address churn issues. This section culminates with engaging case studies that solidify your understanding of applying analytics to solve customer-related challenges.ConclusionThis course equips you with the skills and tools necessary to excel in customer analytics using R and Tableau. By the end of the course, you’ll be capable of conducting in-depth customer analyses, uncovering trends, and developing strategies to improve customer satisfaction and retention.",
    "instructor": "EDUCBA Bridging the Gap",
    "requirements": [
      "Basic understanding of R and Tableau. Familiarity with fundamental concepts in statistics and data analysis. An interest in customer behavior and data-driven decision-making."
    ],
    "whatYouWillLearn": [
      "The fundamentals of customer analytics and its practical applications.",
      "Conducting market research and segmenting customers effectively.",
      "Applying descriptive, predictive, and prescriptive analytics to real-world scenarios.",
      "Tools and techniques for analyzing customer churn.",
      "Creating visualizations and dashboards using Tableau to communicate insights."
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "Introduction to Customer Analytics using R and TableauPreview11:33"
        ]
      },
      {
        "title": "Market Research and Analytics",
        "subsections": [
          "Market Research NPS of BanksPreview08:13",
          "Exception Vs Perception07:59",
          "Market Segmentation for Airlines05:54",
          "Summary of Each Cluster Group07:40",
          "Descriptive Analytics05:12",
          "Company Performance - Key Matrices08:14",
          "Predictive Analytics07:13"
        ]
      },
      {
        "title": "Telecom Churn and Case Studies",
        "subsections": [
          "Telecom Churn08:37",
          "Telecom Churn Continues07:25",
          "Sensitivity and Specificity08:49",
          "Prescriptive Analytics12:17",
          "Case Studies03:38"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6332583_f5e5.jpg"
  },
  {
    "title": "AI Made Simple: A Beginner’s Guide For Everyone",
    "price": "Current priceE£799.99",
    "description": "Welcome to AI Made Simple: A Beginner’s Guide For Everyone On Using Artificial Intelligence. In this 1 hour course we will break down the world of Artificial Intelligence in a way that’s simple, engaging, and easy to grasp! This course is designed for beginners who want to understand AI, how it works, and how it’s shaping our everyday lives. You'll learn:  What AI really is and how it works  Everyday examples of AI (like smart assistants and recommendation systems)  How AI is used in different industries, from healthcare to entertainment The ethical challenges of AI and why responsible AI development matters  Fun, hands-on projects to explore AI conceptsThe Course is broken into 8 main sections and an extra learning module which is an introduction to ProgramingModule 1: What is Artificial Intelligence?Module 2 Busting MythsModule 3: Types of AI and Its ApplicationsModule 4: Exploring Popular AI ToolsModule 5: Using AI in Everyday LifeModule 6: Ethical Challenges in AIModule 7: Hands-On Workshop*Extra Learning*Introduction to AI programing with PythonModule 8: The Future of AI & Closing ThoughtsWhether you’re a student, professional, or just curious about AI, this course will give you a strong foundation without requiring any technical background.",
    "instructor": "Dr. Oluwasanu J. , STEM Instructor .",
    "requirements": [
      "No experience needed"
    ],
    "whatYouWillLearn": [
      "Understand AI fundamentals and applications",
      "Gain practical experience with AI tools.",
      "How to Use AI to improve daily life and work",
      "Types of Artificial Intelligence",
      "Industries where AI Thrive",
      "Popular AI Tools",
      "How to Use AI in Daily Life",
      "What is Artificial Intelligence",
      "Ethical Use of AI",
      "Hands on workshop"
    ],
    "content": [
      {
        "title": "Module1",
        "subsections": [
          "IntroductionPreview02:00"
        ]
      },
      {
        "title": "Course Objective/Syllabus",
        "subsections": [
          "Course Objective& SyllabusPreview02:30"
        ]
      },
      {
        "title": "Module 1: What is Artificial Intelligence",
        "subsections": [
          "Module1: What is Artificial IntelligencePreview03:47"
        ]
      },
      {
        "title": "Module 2: Busting Myths",
        "subsections": [
          "Module2: Busting Myths About Artificial Intelligence02:08"
        ]
      },
      {
        "title": "Module3: Types of AI and Its Applications",
        "subsections": [
          "Module 3: Types of AI and Its Applications03:55"
        ]
      },
      {
        "title": "Module 4: Exploring Popular AI Tools",
        "subsections": [
          "Module4: Exploring Popular AI Tools01:30"
        ]
      },
      {
        "title": "Module5: Using AI in Everyday Life",
        "subsections": [
          "Module 5: Using AI in Everyday Life06:18"
        ]
      },
      {
        "title": "Module 6: Ethical Challenges in AI",
        "subsections": [
          "Module 6: Ethical Challenges in AI04:01"
        ]
      },
      {
        "title": "Module 7: Hands-On Workshop",
        "subsections": [
          "Module 7aPreview00:55",
          "Module 7B: Chat GPT, Notion AI, and Avatar Creation08:00"
        ]
      },
      {
        "title": "More Learning. Introduction to programming AI using Python",
        "subsections": [
          "Python IntroductionPreview03:08",
          "Python Download00:14",
          "Python Module 118:26"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/6548533_cf07_3.jpg"
  },
  {
    "title": "Advanced course- Data Science, Machine Learning, Java",
    "price": "Current priceE£399.99",
    "description": "Java Server Pages (JSP) is a server-side programming technology that enables the creation of dynamic, platform-independent method for building Web-based applications. JSP have access to the entire family of Java APIs, including the JDBC API to access enterprise databases. This tutorial will teach you how to use Java Server Pages to develop your web applications in simple and easy steps.Why to Learn JSP?JavaServer Pages often serve the same purpose as programs implemented using the Common Gateway Interface (CGI). But JSP offers several advantages in comparison with the CGI.Performance is significantly better because JSP allows embedding Dynamic Elements in HTML Pages itself instead of having separate CGI files.JSP are always compiled before they are processed by the server unlike CGI/Perl which requires the server to load an interpreter and the target script each time the page is requested.JavaServer Pages are built on top of the Java Servlets API, so like Servlets, JSP also has access to all the powerful Enterprise Java APIs, including JDBC, JNDI, EJB, JAXP, etc.JSP pages can be used in combination with servlets that handle the business logic, the model supported by Java servlet template engines.Finally, JSP is an integral part of Java EE, a complete platform for enterprise class applications. This means that JSP can play a part in the simplest applications to the most complex and demanding.AudienceThis tutorial has been prepared for the beginners to help them understand basic functionality of Java Server Pages (JSP) to develop your web applications. After completing this tutorial you will find yourself at a moderate level of expertise in using JSP from where you can take yourself to next levels.",
    "instructor": "Arun M",
    "requirements": [
      "Learn everything you need to know"
    ],
    "whatYouWillLearn": [
      "Learn Machine Learning",
      "Learn Data Science",
      "Learn Java",
      "Learn Artificial Intelligence"
    ],
    "content": [
      {
        "title": "Introduction",
        "subsections": [
          "IntroductionPreview03:32",
          "Data Science  LifecyclePreview02:35",
          "Machine LearningPreview01:55",
          "Supervised Learning, Unsupervised LearningPreview02:19",
          "Reinforcement Learning02:18",
          "Python for Data Science03:04",
          "Data Science Tools for Data Storage-Apache Hadoop03:05",
          "Data Modelling-Data Robot02:04",
          "Framework-Sci Kit Learn02:25",
          "Spark  Data Science01:44",
          "Algorithm Machine Learning  Model  Predictor variable02:15",
          "Python Fundamentals02:03",
          "Python Pandas Operations01:43",
          "Supervised Learning03:03"
        ]
      }
    ],
    "image": "https://img-c.udemycdn.com/course/240x135/4547354_5dea_3.jpg"
  }
]